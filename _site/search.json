[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "pacman::p_load(maptools, sf, raster, spatstat, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-the-spatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-the-spatial-data",
    "title": "Hands-on Exercise 3",
    "section": "4.4.1 Importing the spatial data",
    "text": "4.4.1 Importing the spatial data\n\nchildcare_sf <- st_read(\"data/child-care-services-geojson.geojson\") %>% st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Hands-on_Ex/Hands-on_Ex03/data/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Hands-on_Ex/Hands-on_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf <- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Hands-on_Ex/Hands-on_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#mapping-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#mapping-the-geospatial-data-sets",
    "title": "Hands-on Exercise 3",
    "section": "4.4.2 Mapping the geospatial data sets",
    "text": "4.4.2 Mapping the geospatial data sets\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "Hands-on Exercise 3",
    "section": "4.5.1 Converting sf data frames to sp’s Spatial class",
    "text": "4.5.1 Converting sf data frames to sp’s Spatial class\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "Hands-on Exercise 3",
    "section": "4.5.2 Converting the Spatial class into generic sp format",
    "text": "4.5.2 Converting the Spatial class into generic sp format\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 3",
    "section": "4.5.3 Converting the generic sp format into spatstat’s ppp format",
    "text": "4.5.3 Converting the generic sp format into spatstat’s ppp format\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\n\nplot(childcare_ppp)\n\n\n\n\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#handling-duplicated-points",
    "title": "Hands-on Exercise 3",
    "section": "4.5.4 Handling duplicated points",
    "text": "4.5.4 Handling duplicated points\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\n\nsum(multiplicity(childcare_ppp) > 1)\n\n[1] 128\n\n\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\nchildcare_ppp_jit <- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "title": "Hands-on Exercise 3",
    "section": "4.5.5 Creating owin object",
    "text": "4.5.5 Creating owin object\n\nsg_owin <- as(sg_sp, \"owin\")\n\n\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 3",
    "section": "4.5.6 Combining point events object and owin object",
    "text": "4.5.6 Combining point events object and owin object\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.063463e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#kernel-density-estimation",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#kernel-density-estimation",
    "title": "Hands-on Exercise 3",
    "section": "4.6.1 Kernel Density Estimation",
    "text": "4.6.1 Kernel Density Estimation"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kernel-density-estimation-using-automatic-bandwidth-selection-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kernel-density-estimation-using-automatic-bandwidth-selection-method",
    "title": "Hands-on Exercise 3",
    "section": "4.6.1.1 Computing kernel density estimation using automatic bandwidth selection method",
    "text": "4.6.1.1 Computing kernel density estimation using automatic bandwidth selection method\n\nkde_childcareSG_bw <- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\n\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\nbw <- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#rescalling-kde-values",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#rescalling-kde-values",
    "title": "Hands-on Exercise 3",
    "section": "4.6.1.2 Rescalling KDE values",
    "text": "4.6.1.2 Rescalling KDE values\n\nchildcareSG_ppp.km <- rescale(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG.bw <- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nplot(kde_childcareSG.bw)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-different-automatic-badwidth-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-different-automatic-badwidth-methods",
    "title": "Hands-on Exercise 3",
    "section": "4.6.2 Working with different automatic badwidth methods",
    "text": "4.6.2 Working with different automatic badwidth methods\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\n\nkde_childcareSG.ppl <- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-different-kernel-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-different-kernel-methods",
    "title": "Hands-on Exercise 3",
    "section": "4.6.3 Working with different kernel methods",
    "text": "4.6.3 Working with different kernel methods\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kde-by-using-fixed-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kde-by-using-fixed-bandwidth",
    "title": "Hands-on Exercise 3",
    "section": "4.7.1 Computing KDE by using fixed bandwidth",
    "text": "4.7.1 Computing KDE by using fixed bandwidth\n\nkde_childcareSG_600 <- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nplot(kde_childcareSG_600)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kde-by-using-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kde-by-using-adaptive-bandwidth",
    "title": "Hands-on Exercise 3",
    "section": "4.7.2 Computing KDE by using adaptive bandwidth",
    "text": "4.7.2 Computing KDE by using adaptive bandwidth\n\nkde_childcareSG_adaptive <- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-kde-output-into-grid-object.",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-kde-output-into-grid-object.",
    "title": "Hands-on Exercise 3",
    "section": "4.7.3 Converting KDE output into grid object.",
    "text": "4.7.3 Converting KDE output into grid object.\n\ngridded_kde_childcareSG_bw <- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-gridded-output-into-raster",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-gridded-output-into-raster",
    "title": "Hands-on Exercise 3",
    "section": "4.7.3.1 Converting gridded output into raster",
    "text": "4.7.3.1 Converting gridded output into raster\n\nkde_childcareSG_bw_raster <- raster(gridded_kde_childcareSG_bw)\n\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -1.005814e-14, 28.51831  (min, max)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#assigning-projection-systems",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#assigning-projection-systems",
    "title": "Hands-on Exercise 3",
    "section": "4.7.3.2 Assigning projection systems",
    "text": "4.7.3.2 Assigning projection systems\n\nprojection(kde_childcareSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.005814e-14, 28.51831  (min, max)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-the-output-in-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-the-output-in-tmap",
    "title": "Hands-on Exercise 3",
    "section": "4.7.4 Visualising the output in tmap",
    "text": "4.7.4 Visualising the output in tmap\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nVariable(s) \"v\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#comparing-spatial-point-patterns-using-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#comparing-spatial-point-patterns-using-kde",
    "title": "Hands-on Exercise 3",
    "section": "4.7.5 Comparing Spatial Point Patterns using KDE",
    "text": "4.7.5 Comparing Spatial Point Patterns using KDE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#extracting-study-area",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#extracting-study-area",
    "title": "Hands-on Exercise 3",
    "section": "4.7.5.1 Extracting study area",
    "text": "4.7.5.1 Extracting study area\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-spatial-point-data-frame-into-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-spatial-point-data-frame-into-generic-sp-format",
    "title": "Hands-on Exercise 3",
    "section": "4.7.5.2 Converting the spatial point data frame into generic sp format",
    "text": "4.7.5.2 Converting the spatial point data frame into generic sp format\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object-1",
    "title": "Hands-on Exercise 3",
    "section": "4.7.5.3 Creating owin object",
    "text": "4.7.5.3 Creating owin object\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-childcare-points-and-the-study-area",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-childcare-points-and-the-study-area",
    "title": "Hands-on Exercise 3",
    "section": "4.7.5.4 Combining childcare points and the study area",
    "text": "4.7.5.4 Combining childcare points and the study area\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kde",
    "title": "Hands-on Exercise 3",
    "section": "4.7.5.5 Computing KDE",
    "text": "4.7.5.5 Computing KDE\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-fixed-bandwidth-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-fixed-bandwidth-kde",
    "title": "Hands-on Exercise 3",
    "section": "4.7.5.6 Computing fixed bandwidth KDE",
    "text": "4.7.5.6 Computing fixed bandwidth KDE\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "title": "Hands-on Exercise 3",
    "section": "4.8.1 Testing spatial point patterns using Clark and Evans Test",
    "text": "4.8.1 Testing spatial point patterns using Clark and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 33 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 10 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 29 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 30 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 30 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 30 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 29 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 29 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 33 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 30 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 29 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 33 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.54756, p-value = 0.01\nalternative hypothesis: clustered (R < 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#clark-and-evans-test-choa-chu-kang-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#clark-and-evans-test-choa-chu-kang-planning-area",
    "title": "Hands-on Exercise 3",
    "section": "4.8.2 Clark and Evans Test: Choa Chu Kang planning area",
    "text": "4.8.2 Clark and Evans Test: Choa Chu Kang planning area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_ck_ppp\nR = 0.93085, p-value = 0.078\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#clark-and-evans-test-tampines-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#clark-and-evans-test-tampines-planning-area",
    "title": "Hands-on Exercise 3",
    "section": "4.8.3 Clark and Evans Test: Tampines planning area",
    "text": "4.8.3 Clark and Evans Test: Tampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_tm_ppp\nR = 0.79577, p-value = 0.002\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Getting Started\nLoad packages\n\npacman::p_load(tmap, tidyverse, sf)\n\n\n\nImporting Geospatial Data into R\n\nmpsz <- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Hands-on_Ex/Hands-on_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\nImporting Attribute Data into R\n\npopdata <- read_csv(\"data/aspatial/respopagesexfa2011to2020.csv\")\n\nRows: 738492 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, FA\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nData Preparation\nContext: Before a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\nYOUNG: age group 0 to 4 until age groyup 20 to 24, ECONOMY ACTIVE: age group 25-29 until age group 60-64, AGED: age group 65 and above, TOTAL: all age group, and DEPENDENCY: the ratio between young and aged against economy active group\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup() %>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12]), \n         ECONOMY_ACTIVE = rowSums(.[7:11]) +\n           rowSums(.[13:15]), \n         AGED = rowSums(.[16:21]),\n  #Column 3 to 6 and column 12 are under 24 yrs old\n  #Column 7 to 11 and 13 - 15 are between 25 - 64\n  #Column 16 to 21 are 65 and above\n         TOTAL = rowSums(.[3:21]),\n         DEPENDENCY = (YOUNG + AGED)\n         /ECONOMY_ACTIVE) %>%\n  select(PA, SZ, \n         YOUNG, ECONOMY_ACTIVE, AGED,\n         TOTAL, DEPENDENCY)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n#rowSums() tallies the sum of values in the columns specified\n\nQuestion : |> causes an error at rowSums(.[3:6]) while %>% has no issues\nJoining the attribute data and geospatial data\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA,SZ),\n            .funs = funs(toupper)) |>\n  filter(ECONOMY_ACTIVE > 0)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\npopdata2020\n\n# A tibble: 234 × 7\n   PA         SZ                     YOUNG ECONOMY_ACTIVE  AGED TOTAL DEPENDENCY\n   <chr>      <chr>                  <dbl>          <dbl> <dbl> <dbl>      <dbl>\n 1 ANG MO KIO ANG MO KIO TOWN CENTRE  1440           2640   770  4850      0.837\n 2 ANG MO KIO CHENG SAN               6660          15380  6080 28120      0.828\n 3 ANG MO KIO CHONG BOON              6150          13970  6450 26570      0.902\n 4 ANG MO KIO KEBUN BAHRU             5500          12040  5080 22620      0.879\n 5 ANG MO KIO SEMBAWANG HILLS         2130           3390  1270  6790      1.00 \n 6 ANG MO KIO SHANGRI-LA              3970           8430  3540 15940      0.891\n 7 ANG MO KIO TAGORE                  2220           4160  1520  7900      0.899\n 8 ANG MO KIO TOWNSVILLE              4720          11430  5050 21200      0.855\n 9 ANG MO KIO YIO CHU KANG EAST       1190           2230   740  4160      0.865\n10 ANG MO KIO YIO CHU KANG WEST       6610          12810  4680 24100      0.881\n# … with 224 more rows\n\n# mutate_at(.vars = , .funs =) : vars() selects columns. funs() applies a function on all records\n#toupper converts from lower case to uppercase as a default\n\nUse left_join() to combine geospatial data and attribute table by mpsz.SUBZONE_N and popdata2020.SZ as common identifier\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020, by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020\")\n\n\n\nChoropleth Mapping Geospatial Data Using tmap\nPlotting a choropleth map quickly using qtm()\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020,\n    fill = \"DEPENDENCY\")\n\n\n\n\nNotes:\n\ntmap_mode() with “plot” produces a static map whereas “view” produces an interactive mode\nfill maps the variable attribute\n\nCreating a choropleth map by using tmaps element: Similar to ggplot2, use “+” as its adding on layers to the plot\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n        style = \"quantile\",\n        palette = \"Blues\",\n        title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "title": "Hands-On Exercise 9: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this hands-on exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication technology (ICT) measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home.\n\n\n\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries) : This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\nBoth data sets are download from Myanmar Information Management Unit (MIMU)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational.\n\n\n\nTwo data sets will be used in this model building exercise, they are:\n\nURA Master Plan subzone boundary in shapefile format (i.e. MP14_SUBZONE_WEB_PL)\ncondo_resale_2015 in csv format (i.e. condo_resale_2015.csv)\n\n\n\n\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nR package for building OLS and performing diagnostics tests\n\nolsrr\n\nR package for calibrating geographical weighted family of models\n\nGWmodel\n\nR package for multivariate data visualisation and analysis\n\ncorrplot\n\nSpatial data handling\n\nsf\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary, sfdep)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#convert-aspatial-data-frame-into-sf-object",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#convert-aspatial-data-frame-into-sf-object",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "3.1 Convert aspatial data frame into sf object",
    "text": "3.1 Convert aspatial data frame into sf object\nAs condo_resale is aspatial, we need to convert it to a sf object.\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\n\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs = 4326) %>%\n  st_transform(crs = 3414)\n\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLI…¹ AREA_…²   AGE PROX_…³ PROX_…⁴ PROX_…⁵ PROX_…⁶ PROX_…⁷ PROX_…⁸\n     <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1   118635 3000000     309    30    7.94   0.166   2.52     6.62   1.77   0.0584\n2   288420 3880000     290    32    6.61   0.280   1.93     7.51   0.545  0.616 \n3   267833 3325000     248    33    6.90   0.429   0.502    6.46   0.378  0.141 \n4   258380 4250000     127     7    4.04   0.395   1.99     4.91   1.68   0.382 \n5   467169 1400000     145    28   11.8    0.119   1.12     6.41   0.565  0.461 \n6   466472 1320000     139    22   10.3    0.125   0.789    5.09   0.781  0.0994\n# … with 12 more variables: PROX_MRT <dbl>, PROX_PARK <dbl>,\n#   PROX_PRIMARY_SCH <dbl>, PROX_TOP_PRIMARY_SCH <dbl>,\n#   PROX_SHOPPING_MALL <dbl>, PROX_SUPERMARKET <dbl>, PROX_BUS_STOP <dbl>,\n#   NO_Of_UNITS <dbl>, FAMILY_FRIENDLY <dbl>, FREEHOLD <dbl>,\n#   LEASEHOLD_99YR <dbl>, geometry <POINT [m]>, and abbreviated variable names\n#   ¹​SELLING_PRICE, ²​AREA_SQM, ³​PROX_CBD, ⁴​PROX_CHILDCARE, ⁵​PROX_ELDERLYCARE,\n#   ⁶​PROX_URA_GROWTH_AREA, ⁷​PROX_HAWKER_MARKET, ⁸​PROX_KINDERGARTEN"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#eda-using-statistical-graph",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#eda-using-statistical-graph",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "4.1 EDA using statistical graph",
    "text": "4.1 EDA using statistical graph\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed distribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\ncondo_resale.sf <- condo_resale.sf %>%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow we can plot out to see the change\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "4.2 Multiple Histogram Plots distribution of variables",
    "text": "4.2 Multiple Histogram Plots distribution of variables\n\nAREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,\n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-statistical-point-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-statistical-point-map",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "4.3 Drawing Statistical Point Map",
    "text": "4.3 Drawing Statistical Point Map\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(10,14))\n\n\n\n\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#simple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#simple-linear-regression-method",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "5.1 Simple Linear Regression Method",
    "text": "5.1 Simple Linear Regression Method\n\ncondo.slr <- lm(SELLING_PRICE ~ AREA_SQM,\n                data = condo_resale.sf)\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: < 2.2e-16\n\n\nWe will notice that the formula is:\nSELLING_PRICE = -258121.1 + 14719*AREA_SQM\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nWe will now visualize the plot\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-linear-regression-method",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "5.2 Multiple Linear Regression Method",
    "text": "5.2 Multiple Linear Regression Method\n\n5.2.1 Visualising relationships of independent variables\nThis is an important step as multicollinearity will create bias and inaccuracy in the model.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\nAs we can see, Freehold is highly correlated to LEASE_99YEAR and thus we can just exclude one out of the model building."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "5.3 Building a hedonic pricing model using multiple linear regression method",
    "text": "5.3 Building a hedonic pricing model using multiple linear regression method\nThe code chunk below uses lm() to calibrate the multiple linear regression model.\nWe will exclude out POSTCODE, LEASEHOLD_99YR and LOG_SELLING_PRICE and geometry from the model.\n\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  < 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  < 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  < 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  < 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#preparing-publication-quality-table-olsrr-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#preparing-publication-quality-table-olsrr-method",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "5.4 Preparing Publication Quality Table: olsrr method",
    "text": "5.4 Preparing Publication Quality Table: olsrr method\nIt is important to revise the model after looking at which variables are significant and which are not.\nThe code chunk below showcases the adjusted linear regression model:\n\ncondo.mlr1 <- lm(formula = SELLING_PRICE ~ \n                   AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n                   PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n                   PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\n                   PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.592 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.592                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#preparing-publication-quality-table-gtsummary",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#preparing-publication-quality-table-gtsummary",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "5.5 Preparing Publication Quality Table: gtsummary",
    "text": "5.5 Preparing Publication Quality Table: gtsummary\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %>% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = <0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nFor more customisation options, refer to Tutorial: tbl_regression\n\n5.5.1 Checking for multicolinearity\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\n\n\n5.5.2 Test for Non-Linearity\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\nThe figure above reveals that most of the data points are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n5.5.3 Test for Normality Assumption\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nA more formal way is to test normality is by refering to the code chunk below\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\n5.5.4 Testing for Spatial Autocorrelation\nStep 1: We will export the residual of the hedonic pricing model and save it as a dataframe.\n\nmlr.output <- as.data.frame(condo.mlr1$residuals)\n\nStep 2: Join the newly created dataframe with the condo_resale.sf object\n\ncondo_resale.res.sf <- cbind(condo_resale.sf, \n                             condo.mlr1$residuals) %>%\n  rename(`MLR_RES` = `condo.mlr1.residuals`)\n\nStep 3: Convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\n\ncondo_resale.sp <- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nThe figure above reveal that there is some signs of spatial autocorrelation\nFirst, compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\nnb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep package will be used to convert output neighbours lists into spatial weights\n\nnb_lw <- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, we can perform the Moran’s I test for residual spatial autocorrelation.\n\nlm.morantest(condo.mlr1,nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-fixed-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-fixed-bandwidth-gwr-model",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "6.1 Building Fixed Bandwidth GWR Model",
    "text": "6.1 Building Fixed Bandwidth GWR Model\n\n6.1.1 Computing fixed bandwidth\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach argeement.\n\nbw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.379526e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3396 CV score: 4.721292e+14 \nFixed bandwidth: 971.3402 CV score: 4.721292e+14 \nFixed bandwidth: 971.3398 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3399 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 metres. We notice that the CV score is the smallest and thus it is recommended that we use the corresponding fixed bandwidth.\n\n\n6.1.2 GWModel method - fixed bandwidth\n\ngwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-03-06 11:38:03 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.34 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3599e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7426e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5001e+06 -1.5970e+05  3.1970e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8074e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112794435\n   AREA_SQM                 21575\n   AGE                     434203\n   PROX_CBD               2704604\n   PROX_CHILDCARE         1654086\n   PROX_ELDERLYCARE      38867861\n   PROX_URA_GROWTH_AREA  78515805\n   PROX_MRT               3124325\n   PROX_PARK             18122439\n   PROX_PRIMARY_SCH       4637517\n   PROX_SHOPPING_MALL     1529953\n   PROX_BUS_STOP         11342209\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720745\n   FREEHOLD               6073642\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3807 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6193 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.534069e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430418 \n\n   ***********************************************************************\n   Program stops at: 2023-03-06 11:38:04 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-adaptive-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-adaptive-bandwidth-gwr-model",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "6.2 Building Adaptive Bandwidth GWR Model",
    "text": "6.2 Building Adaptive Bandwidth GWR Model\nSimilar approach to the fixed bandwidth method, just that the adaptive argument has changed to TRUE.\n\nbw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n6.2.1 Constructing adaptive bandwidth GWR Model\n\ngwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-03-06 11:38:11 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2023-03-06 11:38:12 \n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-gwr-output",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-gwr-output",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "6.3 Visualising GWR Output",
    "text": "6.3 Visualising GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#converting-sdf-into-sf-data.frame",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#converting-sdf-into-sf-data.frame",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "6.4 Converting SDF into sf data.frame",
    "text": "6.4 Converting SDF into sf data.frame\n\ncondo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.95        0   -0.72065801   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\ngwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                <dbl> 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       <dbl> 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 <dbl> -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               <dbl> 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              <dbl> 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   <dbl> -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              <dbl> -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        <dbl> 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      <dbl> -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  <dbl> -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              <dbl> -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             <dbl> -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      <dbl> 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    <dbl> 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         <dbl> 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           <dbl> 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       <dbl> -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              <dbl> 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    <dbl> 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                <dbl> 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           <dbl> 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            <dbl> 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             <dbl> 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  <dbl> 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             <dbl> 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       <dbl> 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     <dbl> 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE <dbl> 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             <dbl> 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            <dbl> 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     <dbl> 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   <dbl> 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        <dbl> 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          <dbl> 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      <dbl> 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             <dbl> 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            <dbl> 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             <dbl> 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  <dbl> -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             <dbl> -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       <dbl> 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     <dbl> -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV <dbl> -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             <dbl> -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            <dbl> -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     <dbl> 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   <dbl> 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        <dbl> 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          <dbl> 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      <dbl> -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             <dbl> 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                <dbl> 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               <dbl> 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               <dbl> 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                <POINT [m]> POINT (22085.12 29951.54), POINT (25656.…\n\n\n\nsummary(gwr.adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-local-r2",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-local-r2",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "6.5 Visualising local R2",
    "text": "6.5 Visualising local R2\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-coefficient-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-coefficient-estimates",
    "title": "Hands-On Exercise 8: Geographically Weighted Regression",
    "section": "6.6 Visualising coefficient estimates",
    "text": "6.6 Visualising coefficient estimates\n\ntmap_mode(\"view\")\nAREA_SQM_SE <- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV <- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\n6.6.1 Plotting by URA Planning Region\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "",
    "text": "1.3 Getting Started\nInstalling and loading R packages\n\npacman::p_load(sf, tidyverse)\n\n1.4.1 Importing Geospatial Data\n\nmpsz <- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n1.4.2 Importing polyline feature data in shapefile\n\ncyclingpath = st_read(dsn = \"data/geospatial\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2248 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n1.4.3 Importing GIS data in kml format\n\npreschool = st_read(\"data/geospatial/preschools-location.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial/preschools-location.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n1.5 Checking the content of a simple feature dataframe\n1.5.1 Working with st_geometry() The function will give you basic information of the feature class.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n1.5.2 Working with glimpse() glimpse showcases the rows and column and their respective data types and values\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n1.5.3 Working with head() Function shows the first n values\n\nhead(mpsz, n = 5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n1.6 Plotting Geospatial Data\n\nplot(mpsz)\n\n\n\n\nChoose to plot only the geometry\n\nplot(st_geometry(mpsz))\n\n\n\n\nChoose to plot a specific attribute\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n1.7 Working with Projection\n1.7.1 Assigning EPSG code to a simple feature data frame\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nEPSG is 9001 which is wrong as it should be 3414. Therefore we need to set EPSG to 3414\n\nmpsz3414 <- st_set_crs(mpsz, 3414)\n\nCheck CSR again\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n1.7.2 Transforming the projection of preschool from wgs84 to svy21\n\nst_geometry(preschool)\n\nGeometry set for 1925 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nChangge Geodetic CRS: WGS 84 to svy21_EPSG 3414\n\npreschool3414 <- st_transform(preschool, crs = 3414)\npreschool3414\n\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11203.01 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     Name\n1   kml_1\n2   kml_2\n3   kml_3\n4   kml_4\n5   kml_5\n6   kml_6\n7   kml_7\n8   kml_8\n9   kml_9\n10 kml_10\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Description\n1             <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BRILLIANT TOTS PTE. LTD.</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9334</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>610, JURONG WEST STREET 65, #01 - 534, S 640610</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>640610</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>0523C7904478A63D</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n2             <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUBBLESLAND PLAYHOUSE PTE LTD</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT7680</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>238, COMPASSVALE WALK, #01 - 542, S 540238</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>540238</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>18BED05A501AA168</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n3       <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUCKET HOUSE PRESCHOOL</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9527</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>39, WOODLANDS CLOSE, #01 - 62, MEGA@WOODLANDS, S 737856</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>737856</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>C88B9AC31EE71BF6</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n4            <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUMBLE BEE CHILD CARE CENTRE</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT3150</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>369, WOODLANDS AVENUE 1, #01 - 853, S 730369</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>730369</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>64AB8FACA8F60129</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n5               <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUSY BEES SINGAPORE PTE LTD</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9117</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>327B, ANCHORVALE ROAD, #01 - 322, S 542327</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>542327</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>E1B55AC65B9059E8</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n6                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUSY BEES SINGAPORE PTE LTD</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9066</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>211A, PUNGGOL WALK, #01 - 623, S 821211</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>821211</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>3B5A4AF2696592AA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n7       <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUSY BEES SINGAPORE PTE LTD</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9479</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>2, GAMBAS CRESCENT,  - 01-03, NORDCOM II, S 757044</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>757044</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>5F5452B568838620</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n8          <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUSY BEES SINGAPORE PTE.LTD</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9127</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>6, SERANGOON NORTH AVENUE 5, #02 - 01, S 554910</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>554910</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>3AD4173BBB057D89</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n9             <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUSY BEES SINGAPORE PTE.LTD.</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9067</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>348A, YISHUN AVENUE 11, #01 - 557, S 761348</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>761348</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>F4D7A4BDA3CBB15F</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n10 <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>CAELUM JUNIOR @ BENDEMEER PTE. LTD.</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9053</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>70, BENDEMEER ROAD, #02 - 01, LUZERNE, S 339940</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>339940</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>D55FC7583E8CCBA7</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n                        geometry\n1  POINT Z (13258.34 35611.04 0)\n2  POINT Z (35272.09 41373.42 0)\n3  POINT Z (25050.54 46634.14 0)\n4  POINT Z (22892.48 46127.66 0)\n5  POINT Z (34155.79 41949.13 0)\n6   POINT Z (35414.54 42625.1 0)\n7  POINT Z (26046.98 47205.62 0)\n8  POINT Z (31980.09 39607.05 0)\n9  POINT Z (28879.22 45454.97 0)\n10 POINT Z (31250.89 33171.55 0)\n\n\n1.8 Importing and Converting an Aspatial data\n\nlistings <- read_csv(\"data/aspatial/listings.csv\")\n\n#Imports into a tibble data frame\nlist(listings)\n\n[[1]]\n# A tibble: 3,037 × 75\n       id listing_url    scrap…¹ last_scr…² source name  descr…³ neigh…⁴ pictu…⁵\n    <dbl> <chr>            <dbl> <date>     <chr>  <chr> <chr>   <chr>   <chr>  \n 1  71609 https://www.a… 2.02e13 2022-12-29 city … Ensu… For 3 … <NA>    https:…\n 2  71896 https://www.a… 2.02e13 2022-12-29 city … B&B … <b>The… <NA>    https:…\n 3  71903 https://www.a… 2.02e13 2022-12-29 city … Room… Like y… Quiet … https:…\n 4 275343 https://www.a… 2.02e13 2022-12-29 city … Amaz… Awesom… <NA>    https:…\n 5 275344 https://www.a… 2.02e13 2022-12-29 city … 15 m… Lovely… Bus st… https:…\n 6 289234 https://www.a… 2.02e13 2022-12-29 city … Book… This w… A quie… https:…\n 7 294281 https://www.a… 2.02e13 2022-12-29 city … 5 mi… I have… <NA>    https:…\n 8 324945 https://www.a… 2.02e13 2022-12-29 city … Cozy… Cozy, … <NA>    https:…\n 9 330089 https://www.a… 2.02e13 2022-12-29 city … Cozy… A unit… <NA>    https:…\n10 330095 https://www.a… 2.02e13 2022-12-29 city … 10 m… Cosy, … Near I… https:…\n# … with 3,027 more rows, 66 more variables: host_id <dbl>, host_url <chr>,\n#   host_name <chr>, host_since <date>, host_location <chr>, host_about <chr>,\n#   host_response_time <chr>, host_response_rate <chr>,\n#   host_acceptance_rate <chr>, host_is_superhost <lgl>,\n#   host_thumbnail_url <chr>, host_picture_url <chr>, host_neighbourhood <chr>,\n#   host_listings_count <dbl>, host_total_listings_count <dbl>,\n#   host_verifications <chr>, host_has_profile_pic <lgl>, …\n\n\n1.8.2 Creating a simple feature data frame from an aspatial data frame\n\nlistings_sf <- st_as_sf(listings, coords = c(\"longitude\", \"latitude\"), crs = 4326) |>\n  st_transform(crs = 3414)\n\nglimpse(listings_sf)\n\nRows: 3,037\nColumns: 74\n$ id                                           <dbl> 71609, 71896, 71903, 2753…\n$ listing_url                                  <chr> \"https://www.airbnb.com/r…\n$ scrape_id                                    <dbl> 2.022123e+13, 2.022123e+1…\n$ last_scraped                                 <date> 2022-12-29, 2022-12-29, …\n$ source                                       <chr> \"city scrape\", \"city scra…\n$ name                                         <chr> \"Ensuite Room (Room 1 & 2…\n$ description                                  <chr> \"For 3 rooms.Book room 1&…\n$ neighborhood_overview                        <chr> NA, NA, \"Quiet and view o…\n$ picture_url                                  <chr> \"https://a0.muscache.com/…\n$ host_id                                      <dbl> 367042, 367042, 367042, 1…\n$ host_url                                     <chr> \"https://www.airbnb.com/u…\n$ host_name                                    <chr> \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   <date> 2011-01-29, 2011-01-29, …\n$ host_location                                <chr> \"Singapore\", \"Singapore\",…\n$ host_about                                   <chr> \"Hi My name is Belinda -H…\n$ host_response_time                           <chr> \"within a few hours\", \"wi…\n$ host_response_rate                           <chr> \"90%\", \"90%\", \"90%\", \"100…\n$ host_acceptance_rate                         <chr> \"100%\", \"100%\", \"100%\", \"…\n$ host_is_superhost                            <lgl> FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           <chr> \"https://a0.muscache.com/…\n$ host_picture_url                             <chr> \"https://a0.muscache.com/…\n$ host_neighbourhood                           <chr> \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          <dbl> 6, 6, 6, 46, 46, 6, 7, 46…\n$ host_total_listings_count                    <dbl> 15, 15, 15, 59, 59, 15, 8…\n$ host_verifications                           <chr> \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         <lgl> TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       <lgl> TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                <chr> NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       <chr> \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 <chr> \"East Region\", \"East Regi…\n$ property_type                                <chr> \"Private room in villa\", …\n$ room_type                                    <chr> \"Private room\", \"Private …\n$ accommodates                                 <dbl> 6, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    <lgl> NA, NA, NA, NA, NA, NA, N…\n$ bathrooms_text                               <chr> \"1 private bath\", \"Shared…\n$ bedrooms                                     <dbl> 2, 1, 1, 1, 1, 3, 1, 1, N…\n$ beds                                         <dbl> 3, 1, 2, 1, 1, 5, 1, 1, 1…\n$ amenities                                    <chr> \"[\\\"Cooking basics\\\", \\\"R…\n$ price                                        <chr> \"$46,437.00\", \"$81.00\", \"…\n$ minimum_nights                               <dbl> 92, 92, 92, 60, 60, 92, 9…\n$ maximum_nights                               <dbl> 1125, 1125, 1125, 999, 99…\n$ minimum_minimum_nights                       <dbl> 92, 92, 92, 60, 60, 92, 9…\n$ maximum_minimum_nights                       <dbl> 92, 92, 92, 60, 60, 92, 9…\n$ minimum_maximum_nights                       <dbl> 1125, 1125, 1125, 999, 99…\n$ maximum_maximum_nights                       <dbl> 1125, 1125, 1125, 999, 99…\n$ minimum_nights_avg_ntm                       <dbl> 92, 92, 92, 60, 60, 92, 9…\n$ maximum_nights_avg_ntm                       <dbl> 1125, 1125, 1125, 999, 99…\n$ calendar_updated                             <lgl> NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             <lgl> TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              <dbl> 0, 0, 30, 0, 0, 0, 30, 0,…\n$ availability_60                              <dbl> 0, 0, 33, 0, 0, 0, 60, 0,…\n$ availability_90                              <dbl> 0, 0, 33, 0, 6, 0, 90, 0,…\n$ availability_365                             <dbl> 242, 242, 305, 273, 281, …\n$ calendar_last_scraped                        <date> 2022-12-29, 2022-12-29, …\n$ number_of_reviews                            <dbl> 20, 24, 47, 22, 14, 12, 1…\n$ number_of_reviews_ltm                        <dbl> 0, 0, 0, 2, 1, 0, 0, 3, 2…\n$ number_of_reviews_l30d                       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ first_review                                 <date> 2011-12-19, 2011-07-30, …\n$ last_review                                  <date> 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         <dbl> 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       <dbl> 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    <dbl> 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        <dbl> 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  <dbl> 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       <dbl> 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          <dbl> 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      <chr> NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             <lgl> FALSE, TRUE, FALSE, FALSE…\n$ calculated_host_listings_count               <dbl> 6, 6, 6, 46, 46, 6, 7, 46…\n$ calculated_host_listings_count_entire_homes  <dbl> 0, 0, 0, 2, 2, 0, 1, 2, 2…\n$ calculated_host_listings_count_private_rooms <dbl> 6, 6, 6, 44, 44, 6, 6, 44…\n$ calculated_host_listings_count_shared_rooms  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            <dbl> 0.15, 0.17, 0.33, 0.19, 0…\n$ geometry                                     <POINT [m]> POINT (41972.5 3639…\n\n\n1.9 Geoprocessing with sf package\n1.9.1 Buffering Scenario: The authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nSolution:\nFirstly, st_buffer() is used to compute the 5 meter buffers around cycling paths\n\nbuffer_cycling <- st_buffer(cyclingpath, dist = 5, nQuadSegs = 30) \n\nThen calculate the area of buffers\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\nLastly sum() is used to rerive total land involved\n\nsum(buffer_cycling$AREA)\n\n1556978 [m^2]\n\n\n1.9.2 Point-in-polygon count Scenario: A pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nSolution: Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count` <- lengths(st_intersects(mpsz3414, preschool3414)) \n\nShow the summary statistics\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    3.00    5.96    9.00   58.00 \n\n\nShow the planning subzone with the most number of school\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           58\n\n\nFind the density\n\nmpsz3414$Area <- mpsz3414 |>\n  st_area()\n\nmpsz3414 <- mpsz3414 |>\n  mutate(`PreSch Density` = `PreSch Count`/Area *1000000)\n\nmpsz3414\n\nSimple feature collection with 323 features and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...            0\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...            5\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...            0\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...            4\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...            2\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...           10\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...            4\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...            2\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...            6\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...            1\n              Area   PreSch Density\n1  1630379.3 [m^2] 0.000000 [1/m^2]\n2   559816.2 [m^2] 8.931502 [1/m^2]\n3   160807.5 [m^2] 0.000000 [1/m^2]\n4   595428.9 [m^2] 6.717847 [1/m^2]\n5   387429.4 [m^2] 5.162230 [1/m^2]\n6  1030378.8 [m^2] 9.705169 [1/m^2]\n7   551732.0 [m^2] 7.249896 [1/m^2]\n8   290184.7 [m^2] 6.892163 [1/m^2]\n9  1084792.3 [m^2] 5.531013 [1/m^2]\n10  631644.3 [m^2] 1.583170 [1/m^2]\n\n\n1.10 Exploratory Data Analysis\nCreate a histogram\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\nUsing ggplot2\n\nmpsz3414 |>\n  ggplot(aes(x = as.numeric(`PreSch Density`))) + \n  geom_histogram(bins=20,color=\"black\",fill = \"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore\",\n       subtitle = \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\", \n       x = \"Pre-school density (per km sq)\",\n       y = \"Frequency\")\n\n\n\n\nUsing ggplot for scatterplot\n\nmpsz3414 |>\n  ggplot(aes(x = as.numeric(`PreSch Density`), y = `PreSch Count`)) + \n  geom_point(color=\"black\",fill = \"light blue\") +\n  xlim(0,40) +\n  ylim(0,40) +\n  labs(title = \"\",\n       x = \"Pre-school density (per km sq)\",\n       y = \"Frequency\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "IS415-GAA\nWelcome to IS415 Geospatial Analytics and Applications.\nThis is the course website of IS415 I study this term. You will find my course work on this website."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Locally, we are all blessed with clean and accessible water. However, this is not the case for less developed countries, especially in the rural regions of Africa. In this Take Home Assignment, we will be putting spatial data into good use, by looking at the number of functional and non functional water points to better understand the needs and the situation of Osun, which is a rural state in Nigeria.\n\n\nThese will be the packages that will be used in this assignment.\n\npacman::p_load(sf, funModeling,maptools,raster, spatstat, tmap , tidyverse, sfdep) \n\n\n\n\nWe will be using data from the state boundary GIS data, that can be found on geoBoundaries\n\ngeoNGA <- st_read(\"data/geospatial/\",\n               layer = \"nga_admbnda_adm2_osgof_20190417\")\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n\n\n\nWe will be using data from the WPdx Global Data Repositories, while we narrow down to the state of Osun using the filter function.\n\nwp_nga <- read_csv(\"data/aspatial/WPdx.csv\") %>%\n  filter(`#clean_adm1`==\"Osun\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-data",
    "title": "Take-home Exercise 1",
    "section": "2.1 Geospatial Data",
    "text": "2.1 Geospatial Data\n\n2.1.1 Checking for Duplicates\nBefore continuing, we will check for duplicates and replace them if necessary. From running this code, we found out that there are a few duplicates.\n\ngeoNGA$ADM2_EN[duplicated(geoNGA$ADM2_EN) == TRUE]\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\n\nWe will now be replacing the duplicates.\n\ngeoNGA$ADM2_EN[94] <- \"Bassa, Kogi\"\ngeoNGA$ADM2_EN[95] <- \"Bassa, Plateau\"\ngeoNGA$ADM2_EN[304] <- \"Ifelodun, Kwara\"\ngeoNGA$ADM2_EN[305] <- \"Ifelodun, Osun\"\ngeoNGA$ADM2_EN[355] <- \"Irepodun, Kwara\"\ngeoNGA$ADM2_EN[356] <- \"Irepodun, Osun\"\ngeoNGA$ADM2_EN[519] <- \"Nasarawa, Kano\"\ngeoNGA$ADM2_EN[520] <- \"Nasarawa, Nasarawa\"\ngeoNGA$ADM2_EN[546] <- \"Obi, Benue\"\ngeoNGA$ADM2_EN[547] <- \"Obi, Nasarawa\"\ngeoNGA$ADM2_EN[693] <- \"Surulere, Lagos\"\ngeoNGA$ADM2_EN[694] <- \"Surulere, Oyo\"\n\nWe will now run the same code again to check for duplicates. Since character(0), we are good to go.\n\ngeoNGA$ADM2_EN[duplicated(geoNGA$ADM2_EN) == TRUE]\n\ncharacter(0)\n\n\n\n\n2.1.2 Grouping Different Osun States Together\nAs there are different governed states in Osun, we will then group them into osun_state. This will be useful for our visualisation.\n\nosun_state <- c(\"Aiyedade\",\"Aiyedire\",\"Atakumosa East\",   \"Atakumosa West\", \"Ede North\",  \"Ede South\", \"Egbedore\", \"Ejigbo\", \"Ife Central\", \"Ife East\", \"Ife North\", \"Ife South\", \"Ifedayo\",  \"Ila\", \"Ifelodun, Osun\",\"Irepodun, Osun\",\"Ilesha East\",  \"Ilesha West\", \"Irewole\", \"Isokan\",   \"Iwo\", \"Obokun\", \"Odo-Otin\", \"Ola-oluwa\", \"Olorunda\", \"Oriade\", \"Orolu\",    \"Osogbo\", \"Boripe\", \"Boluwaduro\")\n\nosun <- geoNGA %>%\n  filter(ADM2_EN %in% osun_state)\n\n\n\n2.1.3 Transforming Projection for Osun\nAs EPSG:4326 is the global projection, we would want to transform it into the state of Nigeria. We are able to find that 26392 is projected at Nigeria through epsg.io.\n\nst_crs(osun)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\nosun <- osun %>% st_transform(crs = 26392)\n\n\n\n2.1.4 Plotting Osun\nThis will help us visualise the shape of Osun.\n\nplot(osun)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#aspatial-data",
    "title": "Take-home Exercise 1",
    "section": "2.2 Aspatial Data",
    "text": "2.2 Aspatial Data\n\n2.2.1 Converting Data of Water Points into SF Point Features\nAs mentioned in class, we will need to match the CRS to the EPSG. Before that, we will converting the WKT (well known text) data.\n\nwp_nga$Geometry = st_as_sfc(wp_nga$`New Georeferenced Column`)\nwp_nga\n\n# A tibble: 5,557 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429123 GRID3             8.02    5.06 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2  70566 Federal Minis…    7.32    4.79 05/11/… No      Protec… Well    Mechan…\n 3  70578 Federal Minis…    7.76    4.56 05/11/… No      Boreho… Well    Mechan…\n 4  66401 Federal Minis…    8.03    4.64 04/30/… No      Boreho… Well    Mechan…\n 5 422190 GRID3             7.87    4.88 08/29/… Unknown <NA>    <NA>    Tapsta…\n 6 422064 GRID3             7.7     4.89 08/29/… Unknown <NA>    <NA>    Tapsta…\n 7  65607 Federal Minis…    7.89    4.71 05/12/… No      Boreho… Well    Mechan…\n 8  68989 Federal Minis…    7.51    4.27 05/07/… No      Boreho… Well    <NA>   \n 9  67708 Federal Minis…    7.48    4.35 04/29/… Yes     Boreho… Well    Mechan…\n10  66419 Federal Minis…    7.63    4.50 05/08/… Yes     Boreho… Well    Hand P…\n# … with 5,547 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\nwp_sf <- st_sf(wp_nga, crs = 4326)\nwp_sf\n\nSimple feature collection with 5557 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 4.032004 ymin: 7.060309 xmax: 5.06 ymax: 8.061898\nGeodetic CRS:  WGS 84\n# A tibble: 5,557 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429123 GRID3             8.02    5.06 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2  70566 Federal Minis…    7.32    4.79 05/11/… No      Protec… Well    Mechan…\n 3  70578 Federal Minis…    7.76    4.56 05/11/… No      Boreho… Well    Mechan…\n 4  66401 Federal Minis…    8.03    4.64 04/30/… No      Boreho… Well    Mechan…\n 5 422190 GRID3             7.87    4.88 08/29/… Unknown <NA>    <NA>    Tapsta…\n 6 422064 GRID3             7.7     4.89 08/29/… Unknown <NA>    <NA>    Tapsta…\n 7  65607 Federal Minis…    7.89    4.71 05/12/… No      Boreho… Well    Mechan…\n 8  68989 Federal Minis…    7.51    4.27 05/07/… No      Boreho… Well    <NA>   \n 9  67708 Federal Minis…    7.48    4.35 04/29/… Yes     Boreho… Well    Mechan…\n10  66419 Federal Minis…    7.63    4.50 05/08/… Yes     Boreho… Well    Hand P…\n# … with 5,547 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\n\n\n2.2.2 Transforming Projection\nSimilarly, we will have to change the projection of the Aspatial data to 26392.\n\nwp_sf <- wp_sf %>%\n  st_transform(crs = 26392)\n\n\n\n2.2.3 Plotting Frequency Data to Spot NA Values\nFrom this bar graph, we can see that there are NA values.\n\nstatus_cleam_graph <- funModeling::freq(data = wp_sf,\n     input = '#status_clean')\n\n\n\n\n\n\n2.2.4 Replacing NA Values\nWe will then replace the NA values to ‘unknown’.\n\nwp_sf_nga <- wp_sf %>% \n  rename(status_clean = '#status_clean') %>%\n dplyr::select(status_clean) %>%\n  mutate(status_clean = replace_na(\n    status_clean, \"unknown\"))\n\n\n\n2.2.5 Grouping data into Functional and Non-Functional Water Point\nFrom the graph above, we are able to group the different data into functional and non functional.\nWe will begin with functional Water Point.\n\nwp_functional <- wp_sf_nga %>% \n  filter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\nNext, for Non-Functional Water Point.\n\nwp_nonfunctional <- wp_sf_nga %>% \n  filter(status_clean %in% \n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\", \"Non-Functional due to dry season\", \"Non-Functional\", \"Non functional due to dry season\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conversion-of-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conversion-of-data",
    "title": "Take-home Exercise 1",
    "section": "3.1 Conversion of Data",
    "text": "3.1 Conversion of Data\n\n3.1.1 sf to sc\nIn this section, we will be mainly converting our data into spatial data, so that we can use it later on. The sf files earlier on will be now converted into sc (spatial class).\n\nosun_sc<-as_Spatial(osun)\nosun_sc\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 30 \nextent      : 176503.2, 291043.8, 331434.7, 454520.1  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 16\nnames       :    Shape_Leng,       Shape_Area,  ADM2_EN, ADM2_PCODE, ADM2_REF, ADM2ALT1EN, ADM2ALT2EN, ADM1_EN, ADM1_PCODE, ADM0_EN, ADM0_PCODE,  date, validOn, validTo,        SD_EN, ... \nmin values  : 0.26445678806, 0.00248649736648, Aiyedade,   NG030001, Aiyedade,         NA,         NA,    Osun,      NG030, Nigeria,         NG, 17134,   18003,      NA, Osun Central, ... \nmax values  :  1.8470166597,  0.0737271661922,   Osogbo,   NG030030,   Osogbo,         NA,         NA,    Osun,      NG030, Nigeria,         NG, 17134,   18003,      NA,    Osun West, ... \n\nfunc_wp_sc <- as_Spatial(wp_functional)\nfunc_wp_sc \n\nclass       : SpatialPointsDataFrame \nfeatures    : 2630 \nextent      : 177285.9, 290751, 343128.1, 450859.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 1\nnames       :              status_clean \nmin values  :                Functional \nmax values  : Functional but not in use \n\nnonfunc_wp_sc <-as_Spatial(wp_nonfunctional)\nnonfunc_wp_sc\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2179 \nextent      : 180539, 290616, 340054.1, 450780.1  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 1\nnames       :                     status_clean \nmin values  :                        Abandoned \nmax values  : Non-Functional due to dry season \n\n\n\n\n3.1.2 sc to sp\nNext, we will be converting the sc (spatial class) into sp format.\n\nosun_sp <- as(osun_sc, \"SpatialPolygons\")\n\nfunc_wp_sp <-as(func_wp_sc, \"SpatialPoints\")\n\nnonfunc_wp_sp <-as(nonfunc_wp_sc, \"SpatialPoints\")\n\n\n\n3.1.3 sp to ppp\nFinally, we will be converting generic sp format into spatstat’s ppp format.\n\nfunc_wp_ppp <- as(func_wp_sp, \"ppp\")\n\nnonfunc_wp_ppp <- as(nonfunc_wp_sp,\"ppp\")\n\n\n\n3.1.4 Check for Duplicates\nLet us check for duplicate points to be safe. Since there are no duplicates, we can move on.\n\nany(duplicated(func_wp_ppp))\n\n[1] FALSE\n\nany(duplicated(nonfunc_wp_ppp))\n\n[1] FALSE"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-an-owin-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-an-owin-object",
    "title": "Take-home Exercise 1",
    "section": "3.2 Creating an Owin object",
    "text": "3.2 Creating an Owin object\nFrom the sp conversion earlier, we are able to create the owin object.\n\nowin_osun <- as(osun_sp, \"owin\")\n\n\n3.2.1 Combine Points and Owin Object\nWe can combine the points with the owin object. This will show us the points layered with the owin object for functional and non-functional water point respectively.\n\nowin_func_wp_ppp <- func_wp_ppp[owin_osun]\nplot(owin_func_wp_ppp)\n\n\n\nowin_nonfunc_wp_ppp <- nonfunc_wp_ppp[owin_osun]\nplot(owin_nonfunc_wp_ppp)\n\n\n\n\n\n\n3.2.2 Scaling of KDE Value to Kilometer\nScaling the data to km will enable us to visualise the data better.\n\nkde_func_wp_bw.km <- rescale(owin_func_wp_ppp, 1000, \"km\")\nkde_nonfunc_wp_bw.km <- rescale(owin_nonfunc_wp_ppp, 1000, \"km\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#st-order-point-spatial-patterns",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#st-order-point-spatial-patterns",
    "title": "Take-home Exercise 1",
    "section": "4.1 1st Order Point Spatial Patterns",
    "text": "4.1 1st Order Point Spatial Patterns\nWe will be computing the kernel density estimate with non-functional and functional water point side by side.\n\nkde_nonfunc_wp_bw <- density(kde_nonfunc_wp_bw.km,\n                  sigma = bw.diggle,\n                  edge = TRUE,\n                  kernel = \"gaussian\")\n\nkde_func_wp_bw <- density(kde_func_wp_bw.km,\n                  sigma = bw.diggle,\n                  edge = TRUE,\n                  kernel = \"gaussian\")\n\npar(mfrow = c(1,2))\nplot(kde_nonfunc_wp_bw, main = \"Non-Functional Water Points\")\nplot(kde_func_wp_bw, main = \"Functional Water Points\")\n\n\n\n\n\n4.1.2 Converting KDE output into grid object\nWe convert it so that it is suitable for mapping purposes.\n\ngridded_kde_func_wp_bw <- as.SpatialGridDataFrame.im(kde_func_wp_bw)\nspplot(gridded_kde_func_wp_bw)\n\n\n\ngridded_kde_nonfunc_wp_bw <- as.SpatialGridDataFrame.im(kde_nonfunc_wp_bw)\nspplot(gridded_kde_nonfunc_wp_bw)\n\n\n\n\n\n\n4.1.3 Converting Gridded output into Raster\nBy using raster(), we are able to converted the gridded object.\n\nkde_func_wp_bw_raster <- raster(gridded_kde_func_wp_bw)\n\nkde_nonfunc_wp_bw_raster <- raster(gridded_kde_nonfunc_wp_bw)\n\nkde_func_wp_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -4.734822e-15, 25.49435  (min, max)\n\nkde_nonfunc_wp_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -4.082312e-15, 20.49412  (min, max)\n\n\n\n\n4.1.4 Assigning projection systems for Raster\nImportant that the projection is set to 26392, so let us change that.\n\nprojection(kde_func_wp_bw_raster) <- CRS(\"+init=EPSG:26392 +units=km\")\nkde_func_wp_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +units=km +no_defs \nsource     : memory\nnames      : v \nvalues     : -4.734822e-15, 25.49435  (min, max)\n\nprojection(kde_nonfunc_wp_bw_raster) <- CRS(\"+init=EPSG:26392 +units=km\")\nkde_nonfunc_wp_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +units=km +no_defs \nsource     : memory\nnames      : v \nvalues     : -4.082312e-15, 20.49412  (min, max)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-the-output-in-tmap",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-the-output-in-tmap",
    "title": "Take-home Exercise 1",
    "section": "4.2 Visualising the Output in Tmap",
    "text": "4.2 Visualising the Output in Tmap\nBy using the OpenStreetMap together with the raster layer, we are able to visualise Osun. A zoom limit is also fixed so that we will not lose sight of the state.\n\ntmap_mode(\"view\") \ntm_basemap(server =\"OpenStreetMap\") + \ntm_shape(kde_func_wp_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE) +\n   tm_view(set.zoom.limits =c(9, 14))\n\n\n\n\n\n\ntmap_mode(\"view\") \ntm_basemap(server =\"OpenStreetMap\") + \ntm_shape(kde_nonfunc_wp_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE) +\n  tm_view(set.zoom.limits =c(9, 14)) +\n  tm_basemap(server =\"OpenStreetMap\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#l-function",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#l-function",
    "title": "Take-home Exercise 1",
    "section": "5.1 L Function",
    "text": "5.1 L Function\nWe will be using the L-function to calculate an estimate for a spatial point pattern. The Lest function is usable for any ppp object. More information can be found here.\nWe will start with Functional Water Point\n\nL_fun = Lest(owin_func_wp_ppp, correction = \"Ripley\")\nplot(L_fun, . -r ~ r, ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\nNext, Non-Functional Water Point\n\nL_nonfun = Lest(owin_nonfunc_wp_ppp, correction = \"Ripley\")\nplot(L_nonfun, . -r ~ r, ylab= \"L(d)-r\", xlab = \"d(m)\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-complete-spatial-randomness-test",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-complete-spatial-randomness-test",
    "title": "Take-home Exercise 1",
    "section": "5.1.2 Performing Complete Spatial Randomness Test",
    "text": "5.1.2 Performing Complete Spatial Randomness Test\nWe will be creating an envelop to run a stimulation at 39, which is equivalent to 95% confidence interval. If P value falls below 0.005, we reject H0.\nThe H0 and H1 are as follows:\nH0 : The distribution of functional/non-functional water points in Osun State are randomly distributed\nH1 : The distribution of functional/non-functional water points in Osun State are not randomly distributed\n\nL_FWP_test <- envelope(owin_func_wp_ppp, Lest, nsim = 39, rank = 1, glocal=TRUE)\n\nplot(L_fun.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))\n\n\n\nL_NFWP_test <- envelope(owin_nonfunc_wp_ppp, Lest, nsim = 39, rank = 1, glocal=TRUE)\n\nplot(L_nonfun.csr, . - r ~ r,  xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))\n\n\nFrom running the simulations, we can therefore conclude that as both black lines for functional and non-functional water point falls outside the 95% confidence interval, we reject H0, and accept that the water points in Osun states are not randomly distributed, which also implies that there is a reason for the placement of water points around the Osun state and in this case, based on the population density."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#combining-ppp-value-together",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#combining-ppp-value-together",
    "title": "Take-home Exercise 1",
    "section": "6.1 Combining ppp value together",
    "text": "6.1 Combining ppp value together\nAs there are many categories that are classified under functional and non-functional data, let us\n\nwp_functional$status_clean[1:length(wp_functional$status_clean)] <- \"Functional\"\n\nwp_nonfunctional$status_clean[1:length(wp_nonfunctional$status_clean)] <- \"Non-Functional\"\n\nLet us combine both functional and non-functional water points together\n\nwp_tgt <- bind_rows(wp_functional, wp_nonfunctional)\n\nwp_tgt\n\nSimple feature collection with 4809 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 177285.9 ymin: 340054.1 xmax: 290751 ymax: 450859.7\nProjected CRS: Minna / Nigeria Mid Belt\n# A tibble: 4,809 × 2\n   status_clean            Geometry\n * <chr>                <POINT [m]>\n 1 Functional     (212810 386707.6)\n 2 Functional   (228798.9 403822.5)\n 3 Functional   (270497.9 377476.9)\n 4 Functional     (212202 349210.1)\n 5 Functional   (259331.9 399591.4)\n 6 Functional     (195484 404733.2)\n 7 Functional   (221302.3 389473.6)\n 8 Functional   (263254.1 382692.9)\n 9 Functional     (192484.1 405113)\n10 Functional       (252736 373593)\n# … with 4,799 more rows"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#transforming-of-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#transforming-of-object",
    "title": "Take-home Exercise 1",
    "section": "6.2 Transforming of Object",
    "text": "6.2 Transforming of Object\nTo visualise the data, we will be converting sf to sp, sp to sfdf, df to ppp, and ppp to owin object.\n\nwp_tgt_sp <- as(wp_tgt, \"Spatial\")\nwp_tgt_spdf <- as(wp_tgt_sp, \"SpatialPointsDataFrame\")\nwp_tgt_ppp <- as(wp_tgt_spdf, \"ppp\")\nwp_tgt_owin_ppp <- wp_tgt_ppp[owin_osun]\n\nPlotting the Data\n\nplot(wp_tgt_owin_ppp, main = \"Water Points By Functionality\", which.marks = \"status_clean\")\n\n\n\n\nSimilarly, we can get a better view on it on tmap\n\ntmap_mode(\"view\")\ntm_shape(osun)+\n  tm_polygons()+\n  tm_shape(wp_tgt)+\n  tm_dots(col=\"status_clean\") +\n   tm_view(set.zoom.limits =c(9, 14))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#cross-l-function-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#cross-l-function-analysis",
    "title": "Take-home Exercise 1",
    "section": "6.3 Cross L-Function Analysis",
    "text": "6.3 Cross L-Function Analysis\nAs we have already derived that the water points are not random, we will now be testing the independence between functional and non-functional water point to see the dependence, if there is.\nH0 : The location of functional and non-functional water points in Osun State are independent from each other.\nH1 : The location of functional and non-functional water points in Osun State are not independent from each other.\nSimilarly, we will using the 95% confidence level.\n\nLcross_wp <- envelope(wp_tgt_owin_ppp,\n                      Lcross,\n                      i = \"Functional\",\n                      j = \"Non-Functional\",\n                      correction = \"border\",\n                      nsim = 39)\nplot(Lcross_wp, xlim = c(0,10000))\n\n\nFrom the plot, we can see that there is spatial dependence for 5500 < r < 6800 as it is within the confidence level of 95%."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#local-colocation-quotients-lclq",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#local-colocation-quotients-lclq",
    "title": "Take-home Exercise 1",
    "section": "6.4 Local Colocation Quotients (LCLQ)",
    "text": "6.4 Local Colocation Quotients (LCLQ)\n\n6.4.1 Preperation\nPreparing nearest neighbours list\n\nnb <- include_self(\n  st_knn(st_geometry(wp_sf_nga),6))\n\nComputing the Kernel weights\n\nwt <- st_kernel_weights(nb, wp_sf_nga, \"gaussian\", adaptive = TRUE)\n\n\n\n6.4.2 Calculating Local Colocation Quotient\n\nA <- wp_functional$status_clean\n\nB <- wp_nonfunctional$status_clean\n\nLCLQ <- local_colocation(A,B, nb, wt, 39)\n\n\n\n6.4.3 Joining output Table\n\nLCLQ_WP <- cbind(wp_sf_nga, LCLQ) %>%\n  na.exclude()\n\n\n\n6.4.4 Plotting LCLQ using tmap\n\ntmap_mode(\"view\")\ntm_shape(osun) +\n  tm_polygons() +\ntm_shape(LCLQ_WP) +\n  tm_dots(col = \"Non.Functional\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) +\ntm_shape(LCLQ_WP) +\n  tm_dots(col = \"p_sim_Non.Functional\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) +\n   tm_view(set.zoom.limits =c(9, 14))\n\n\n\n\n\n\nFrom the p value 0.025 < 0.05, we can see that the result is significant. Since this is the case, we can reject H0 and accept H1, which tells us that functional and non-functional water points are dependant on each other.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "",
    "text": "We will be exploring vaccination rates in DKI Jarkarta, while identifying sub-districts with how the vaccination rate changes over time.\nWe will be mainly using Choropleth Mapping and Analysis, Local Gi analysis, and Emerging Hot Spot Analysis (EHSA) with the aim of discovering Spatio-Temporal trends.\nThis is useful as we are able to then use the trends to help predict the geographic expansion of vaccination rates, and the data can be utilised by the government to bring about positive change in society."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-sets",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-sets",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "1.1 Data Sets",
    "text": "1.1 Data Sets\nWe will be using 2 primary sets of data.\n\n\n\nData set\nSource\nDescription\n\n\n\n\nGeospatial\nINDONESIA GEOSPASIAL\nSub-district of Indonesia\n\n\nAspatial\nRiwayat File Vaksinasi DKI Jakarta\nMonthly numbers of vaccinated people from July 2021 to June 2022 (sub-district level)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#geospatial-data",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "1.2 Geospatial Data",
    "text": "1.2 Geospatial Data\nWe will be loading the Geospatial data while converting it to the proper crs format.\n\ngeoJKT <- st_read(dsn = \"data/geospatial/\", layer = \"BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA\") %>%   st_transform(crs=23878)\n\nReading layer `BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 269 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.3831 ymin: -6.370815 xmax: 106.9728 ymax: -5.184322\nGeodetic CRS:  WGS 84\n\n\n\n1.2.1 Checking Missing Values\nWe should never assume that the data set provided has no missing values. We check the values in this code chunk and realise that there are actually 14 na values. We will change it in the later portions.\n\n  which((is.na(geoJKT)) == TRUE) %>%\n  length()\n\n[1] 14\n\n\n\n\n1.2.2 Filling up NA values\nFrom looking at View(geoJKT), we see that the 14 NA values are associated with rows 243 and 244. Let us insert the necessary values.\n\ngeoJKT$KAB_KOTA[243]<-\"JAKARTA UTARA\"\ngeoJKT$KAB_KOTA[244]<-\"JAKARTA UTARA\"\n\ngeoJKT$KODE_DESA[243]<-\"3188888801\"\ngeoJKT$KODE_DESA[244]<-\"3188888802\"\n\n\n\n1.2.3 Trimming Outer Island\nLet us visualise the original polygon. Notice that there are several island that we do not want, as we are only focusing on the main sub-districts of Jakarta, or mainland for short.\n\nqtm(geoJKT)\n\n\n\n\nFrom using the View() function, we can see the different columns of geoJKT. With the help of Google translate, we can see that KAB KOTA means city district.\n\nFrom there, we can further derive that KEPULAUAN SERIBU means outer island, which is something that we do not want for the scope of this assignment. We will use filter() to remove it.\n\ngeoJKT <- filter(geoJKT, KAB_KOTA != \"KEPULAUAN SERIBU\") \ngeoJKT\n\nSimple feature collection with 263 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 686587.9 ymin: 9295420 xmax: 718314.5 ymax: 9326648\nProjected CRS: DGN95 / UTM zone 48S\nFirst 10 features:\n   OBJECT_ID  KODE_DESA               DESA   KODE    PROVINSI      KAB_KOTA\n1      25477 3173031006          KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT\n2      25478 3173031007             GLODOK 317303 DKI JAKARTA JAKARTA BARAT\n3      25397 3171031003      HARAPAN MULIA 317103 DKI JAKARTA JAKARTA PUSAT\n4      25400 3171031006       CEMPAKA BARU 317103 DKI JAKARTA JAKARTA PUSAT\n5      25390 3171021001         PASAR BARU 317102 DKI JAKARTA JAKARTA PUSAT\n6      25391 3171021002       KARANG ANYAR 317102 DKI JAKARTA JAKARTA PUSAT\n7      25394 3171021005 MANGGA DUA SELATAN 317102 DKI JAKARTA JAKARTA PUSAT\n8      25386 3171011003       PETOJO UTARA 317101 DKI JAKARTA JAKARTA PUSAT\n9      25403 3171041001              SENEN 317104 DKI JAKARTA JAKARTA PUSAT\n10     25408 3171041006             BUNGUR 317104 DKI JAKARTA JAKARTA PUSAT\n     KECAMATAN         DESA_KELUR JUMLAH_PEN JUMLAH_KK LUAS_WILAY KEPADATAN\n1   TAMAN SARI          KEAGUNGAN      21609      7255       0.36     60504\n2   TAMAN SARI             GLODOK       9069      3273       0.37     24527\n3    KEMAYORAN      HARAPAN MULIA      29085      9217       0.53     54465\n4    KEMAYORAN       CEMPAKA BARU      41913     13766       0.97     42993\n5  SAWAH BESAR         PASAR BARU      15793      5599       1.76      8971\n6  SAWAH BESAR       KARANG ANYAR      33383     11276       0.47     71628\n7  SAWAH BESAR MANGGA DUA SELATAN      35906     12817       1.31     27463\n8       GAMBIR       PETOJO UTARA      21828      7328       1.14     19144\n9        SENEN              SENEN       8643      3049       0.82     10594\n10       SENEN             BUNGUR      23001      7944       0.67     34418\n   PERPINDAHA JUMLAH_MEN PERUBAHAN WAJIB_KTP SILAM KRISTEN KHATOLIK HINDU BUDHA\n1         102         68     20464     16027 15735    2042      927    15  2888\n2          25         52      8724      7375  1842    2041     1460     9  3716\n3         131        104     27497     20926 26328    1710      531    42   469\n4         170        151     38323     30264 36813    3392     1082   127   495\n5          58         36     15006     12559  7401    3696     1602   622  2462\n6         113         60     31014     24784 23057    4058     2100    25  4134\n7         178         92     33021     26730 23424    5130     2575    27  4740\n8          87         83     19275     16478 15355    3061     1838     9  1559\n9          56         21      8306      6298  5450    1991      705   115   381\n10        128         70     21652     16987 17431    3099     1258    47  1143\n   KONGHUCU KEPERCAYAA  PRIA WANITA BELUM_KAWI KAWIN CERAI_HIDU CERAI_MATI   U0\n1         2          0 11049  10560      10193 10652        255        509 1572\n2         1          0  4404   4665       4240  4364        136        329  438\n3         5          0 14696  14389      14022 13450        430       1183 2232\n4         1          3 21063  20850      20336 19487        523       1567 3092\n5        10          0  7833   7960       7578  7321        217        677  802\n6         9          0 16887  16496      15860 15945        381       1197 2220\n7        10          0 18338  17568      17239 17198        476        993 2399\n8         4          2 10955  10873      10551 10070        305        902 1406\n9         1          0  4446   4197       4360  3915        101        267  585\n10        1         22 11679  11322      11010 11231        206        554 1679\n     U5  U10  U15  U20  U25  U30  U35  U40  U45  U50  U55  U60 U65 U70 U75\n1  1751 1703 1493 1542 1665 1819 1932 1828 1600 1408 1146  836 587 312 415\n2   545  524  521  543  628  691  782  675  607  619  602  614 555 311 414\n3  2515 2461 2318 2113 2170 2363 2595 2371 2250 1779 1379 1054 654 411 420\n4  3657 3501 3486 3098 3024 3188 3662 3507 3391 2696 1909 1397 970 631 704\n5   995 1016 1106 1081 1002 1236 1422 1200 1163 1099  979  880 747 488 577\n6  2687 2653 2549 2313 2446 2735 3034 2689 2470 2129 1843 1386 958 554 717\n7  2953 2754 2666 2515 2725 3122 3385 3037 2597 2282 1930 1394 932 573 642\n8  1625 1625 1718 1612 1612 1707 1806 1746 1672 1427 1258  968 706 412 528\n9   758  714  672  583  670  797  796  740  577  495  437  331 234 129 125\n10 1794 1797 1789 1667 1773 1957 1952 1785 1667 1489 1219  941 647 386 459\n   TIDAK_BELU BELUM_TAMA TAMAT_SD SLTP  SLTA DIPLOMA_I DIPLOMA_II DIPLOMA_IV\n1        3426       1964     2265 3660  8463        81        428       1244\n2        1200        481      655 1414  3734        23        273       1241\n3        4935       2610     2346 3167 12172        84       1121       2477\n4        7328       3763     2950 5138 16320       179       1718       4181\n5        2121       1278     1169 2236  5993        43        573       2199\n6        5075       3241     4424 5858 12448        85        604       1582\n7        6089       3184     3620 6159 14080        83        740       1850\n8        3290       1951     1660 3008  8743        63        734       2189\n9        1401        768      877 1417  2936        27        280        804\n10       3506       2065     1609 2918 10155        79        708       1832\n   STRATA_II STRATA_III BELUM_TIDA APARATUR_P TENAGA_PEN WIRASWASTA PERTANIAN\n1         74          4       3927         81         70       8974         1\n2         46          2       1388         10         43       3832         0\n3        166          7       5335        513        288      10662         1\n4        315         21       8105        931        402      14925         3\n5        168         13       2676        156         81       6145         1\n6         63          3       5985        132        123      12968         2\n7         92          9       6820         79         73      14714         5\n8        174         16       3809        145        109       8549         1\n9        125          8       1574        369         30       3175         0\n10       122          7       3948        609        137       8284         0\n   NELAYAN AGAMA_DAN PELAJAR_MA TENAGA_KES PENSIUNAN LAINNYA    GENERATED\n1        0         6       4018         28        57    4447 30 Juni 2019\n2        0         6       1701         29        50    2010 30 Juni 2019\n3        2         5       6214         80       276    5709 30 Juni 2019\n4        0        40       9068        142       498    7799 30 Juni 2019\n5        1        49       3135         60        59    3430 30 Juni 2019\n6        1        10       6823         48        56    7235 30 Juni 2019\n7        2        11       6866         55        75    7206 30 Juni 2019\n8        0        54       4731         68        97    4265 30 Juni 2019\n9        0        15       1779         89        53    1559 30 Juni 2019\n10       0        16       5063         93       146    4705 30 Juni 2019\n   KODE_DES_1 BELUM_ MENGUR_ PELAJAR_ PENSIUNA_1 PEGAWAI_ TENTARA KEPOLISIAN\n1  3173031006   3099    4447     3254         80       48       4         10\n2  3173031007   1032    2026     1506         65        5       0          1\n3  3171031003   4830    5692     6429        322      366      41         16\n4  3171031006   7355    7692     8957        603      612      57         42\n5  3171021001   2390    3500     3185         70       65      74          2\n6  3171021002   5330    7306     6993         75       73      20         17\n7  3171021005   5605    7042     6858         97       48      12          7\n8  3171011003   3365    4357     4719        132       89      11          9\n9  3171041001   1553    1627     1701         67       91      90        165\n10 3171041006   3924    4731     4885        165      174     340         15\n   PERDAG_ PETANI PETERN_ NELAYAN_1 INDUSTR_ KONSTR_ TRANSP_ KARYAW_ KARYAW1\n1       31      0       0         1        7       3       2    6735       9\n2        5      0       0         0        3       0       0    3034       2\n3        1      1       0         1        4       2       7    7347      74\n4        3      2       0         0        3       6       4   10185     231\n5        2      1       0         0        0       1       0    4319      16\n6        3      1       0         0        1       1       0    9405      13\n7        1      1       0         1        7       5       3   10844      10\n8        0      2       0         0        0       0       0    6909      24\n9        1      0       0         0        2       2       0    1959      17\n10       2      0       0         0        2       5       0    5661      29\n   KARYAW1_1 KARYAW1_12 BURUH BURUH_ BURUH1 BURUH1_1 PEMBANT_ TUKANG TUKANG_1\n1          0         23   515      1      0        0        1      0        1\n2          0          4   155      0      0        0        1      0        0\n3          5         25   971      0      1        0        4      0        0\n4         15         35   636      0      0        0        1      0        0\n5          0         16   265      1      0        0        7      0        0\n6          0          6  1085      0      0        0        5      0        0\n7          1          9   652      1      1        0        1      1        0\n8          0         11   357      0      0        0        6      0        0\n9          2         11   226      0      0        0        1      0        0\n10         4         15   542      0      0        0       10      0        0\n   TUKANG_12 TUKANG__13 TUKANG__14 TUKANG__15 TUKANG__16 TUKANG__17 PENATA\n1          0          1          0          1          7          1      0\n2          0          1          0          0          4          0      0\n3          0          0          0          0         10          0      0\n4          0          1          0          1         14          0      0\n5          0          0          0          0          2          0      1\n6          0          0          0          0          7          0      0\n7          0          1          0          1          8          1      0\n8          0          0          0          0          8          0      0\n9          0          0          0          0          1          0      1\n10         0          1          0          0          0          0      0\n   PENATA_ PENATA1_1 MEKANIK SENIMAN_ TABIB PARAJI_ PERANCA_ PENTER_ IMAM_M\n1        0         0      11        4     1       0        0       1      0\n2        0         0       1        0     0       0        0       0      0\n3        0         0      10       12     0       0        0       0      0\n4        0         1       8       28     0       0        0       0      0\n5        0         0       4        2     1       0        0       1      0\n6        0         0       7        3     0       0        0       0      0\n7        0         1       8        4     1       0        0       0      0\n8        0         2       9        9     0       0        1       0      0\n9        0         0       0        6     0       0        0       0      0\n10       0         1      15        7     0       0        2       0      0\n   PENDETA PASTOR WARTAWAN USTADZ JURU_M PROMOT ANGGOTA_ ANGGOTA1 ANGGOTA1_1\n1        2      0        7      6      0      0        0        0          0\n2        4      1        1      1      0      0        1        0          0\n3        5      0       16      1      0      0        0        0          0\n4       33      1       27      5      0      0        0        0          0\n5       20      8        4      0      0      0        0        0          0\n6       10      0        8      0      0      0        1        0          0\n7        8      0        6      1      0      0        0        0          0\n8       30     23        9      0      0      0        1        0          0\n9       14      0        5      0      0      0        0        0          0\n10      14      0        9      1      0      0        0        0          0\n   PRESIDEN WAKIL_PRES ANGGOTA1_2 ANGGOTA1_3 DUTA_B GUBERNUR WAKIL_GUBE BUPATI\n1         0          0          0          0      0        0          0      0\n2         0          0          0          0      0        0          0      0\n3         0          0          0          0      0        0          0      0\n4         0          0          0          0      0        0          0      0\n5         0          0          0          0      0        0          0      0\n6         0          0          0          0      0        0          0      0\n7         0          0          0          0      0        0          0      0\n8         0          0          0          0      0        0          0      0\n9         0          0          0          0      0        0          0      0\n10        0          0          0          0      0        0          0      0\n   WAKIL_BUPA WALIKOTA WAKIL_WALI ANGGOTA1_4 ANGGOTA1_5 DOSEN GURU PILOT\n1           0        0          0          0          0     3   72     1\n2           0        0          0          0          0     2   40     0\n3           0        0          0          0          0    23  272     2\n4           0        0          0          0          0    36  378     3\n5           0        0          0          0          0    11   69     0\n6           0        0          0          0          0     3  126     0\n7           0        0          0          0          0     5   71     0\n8           0        0          0          0          0    14   97     0\n9           0        0          0          0          0     6   23     0\n10          0        0          0          0          0    28  106     0\n   PENGACARA_ NOTARIS ARSITEK AKUNTA_ KONSUL_ DOKTER BIDAN PERAWAT APOTEK_\n1           4       0       1       1       1     16     3       7       0\n2           1       0       0       0       0     32     1       0       0\n3           8       3       2       0       2     35     9      25       2\n4          22       5       3       0      11     68    18      44       3\n5           5       4       2       0       4     63     1       3       0\n6           5       0       0       0       0     27     3      12       1\n7           4       0       0       0       0     32     3      20       2\n8           4       5       4       2       6     63     3       7       1\n9           3       0       1       0       2     48    10      26       2\n10         12       5       2       1       3     60    10      16       3\n   PSIKIATER PENYIA_ PENYIA1 PELAUT PENELITI SOPIR PIALAN PARANORMAL PEDAGA_\n1          0       0       0      0        0    65      0          0     379\n2          0       0       0      0        1     3      0          0     126\n3          1       0       0      6        0    94      0          0     321\n4          0       0       0     16        0   123      0          0     562\n5          0       0       0      0        1    61      0          0     412\n6          0       0       0      2        0    76      0          0     202\n7          0       0       0      4        0    79      0          1     225\n8          0       0       0      2        0    63      0          0     271\n9          1       0       0      4        0    44      0          0     212\n10         0       0       0      2        0   101      0          0     331\n   PERANG_ KEPALA_ BIARAW_ WIRASWAST_ LAINNYA_12 LUAS_DESA KODE_DES_3\n1        0       0       0       1370         94     25476 3173031006\n2        0       0       1        611         57     25477 3173031007\n3        0       0       0       1723         82     25396 3171031003\n4        0       0       0       3099        122     25399 3171031006\n5        0       0      22       1128         41     25389 3171021001\n6        0       0       3       2321         89     25390 3171021002\n7        0       0       0       2677        158     25393 3171021005\n8        0       0       2       1018         37     25385 3171011003\n9        0       0       1        871         15     25402 3171041001\n10       0       0       0       1749         94     25407 3171041006\n           DESA_KEL_1 KODE_12                       geometry\n1           KEAGUNGAN  317303 MULTIPOLYGON (((700997 9320...\n2              GLODOK  317303 MULTIPOLYGON (((700826.4 93...\n3       HARAPAN MULIA  317103 MULTIPOLYGON (((705543.4 93...\n4        CEMPAKA BARU  317103 MULTIPOLYGON (((706164.3 93...\n5          PASAR BARU  317102 MULTIPOLYGON (((703261.2 93...\n6        KARANG ANYAR  317102 MULTIPOLYGON (((702680.1 93...\n7  MANGGA DUA SELATAN  317102 MULTIPOLYGON (((702843.6 93...\n8        PETOJO UTARA  317101 MULTIPOLYGON (((701480.2 93...\n9               SENEN  317104 MULTIPOLYGON (((703947.8 93...\n10             BUNGUR  317104 MULTIPOLYGON (((704573.6 93...\n\n\n\n\n1.2.4 Visualising of Map\nAs shown in the plot, there are no NA values, or outer island. that means that we have successfully removed the outer island and NA values.\n\ntmap_mode(\"plot\")\ntm_shape(geoJKT) + \n  tm_polygons(\"KAB_KOTA\")\n\n\n\n\n\n\n1.2.5 Choosing relavent fields\nFor the scope of this assignment, let us retain the first 9 columns from geoJKT using select().\n\ngeoJKT <- geoJKT %>%\n  select(1:9)\n\n\n\n1.2.6 Translating columns\nAs the columns are not in English, let us translate and change the name using rename().\n\ngeoJKT <- geoJKT %>% \n  dplyr::rename(\n    'village_code' = 'KODE_DESA',\n    'subdistrict' = 'KECAMATAN')"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aspatial-data",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "1.3 Aspatial Data",
    "text": "1.3 Aspatial Data\nAs mentioned earlier, we will be using data from Riwayat File Vaksinasi DKI Jakarta. We will be looking at data from the start of July 2021 till the end of June 2022.\n\n1.3.1 Loading Aspatial data\n\nsetwd(\"data/aspatial/\") \n\naspatial <- list.files(pattern = \".xlsx\")\n\nfor (file in aspatial) {\n  assign(gsub(\".xlsx\", \"\", file), read_excel(file))\n}\n\n\n\n1.3.2 Columns in each data set\nWe can use names() to view the true nature of each name as it is sometimes hidden when we view the table alone.\n\nnames(`Data Vaksinasi Berbasis Kelurahan (01 Desember 2021)`)\n\n [1] \"KODE KELURAHAN\"                            \n [2] \"WILAYAH KOTA\"                              \n [3] \"KECAMATAN\"                                 \n [4] \"KELURAHAN\"                                 \n [5] \"SASARAN\"                                   \n [6] \"BELUM VAKSIN\"                              \n [7] \"JUMLAH\\r\\nDOSIS 1\"                         \n [8] \"JUMLAH\\r\\nDOSIS 2\"                         \n [9] \"TOTAL VAKSIN\\r\\nDIBERIKAN\"                 \n[10] \"LANSIA\\r\\nDOSIS 1\"                         \n[11] \"LANSIA\\r\\nDOSIS 2\"                         \n[12] \"LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN\"         \n[13] \"PELAYAN PUBLIK\\r\\nDOSIS 1\"                 \n[14] \"PELAYAN PUBLIK\\r\\nDOSIS 2\"                 \n[15] \"PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN\"  \n[16] \"GOTONG ROYONG\\r\\nDOSIS 1\"                  \n[17] \"GOTONG ROYONG\\r\\nDOSIS 2\"                  \n[18] \"GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN\"   \n[19] \"TENAGA KESEHATAN\\r\\nDOSIS 1\"               \n[20] \"TENAGA KESEHATAN\\r\\nDOSIS 2\"               \n[21] \"TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN\"\n[22] \"TAHAPAN 3\\r\\nDOSIS 1\"                      \n[23] \"TAHAPAN 3\\r\\nDOSIS 2\"                      \n[24] \"TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN\"       \n[25] \"REMAJA\\r\\nDOSIS 1\"                         \n[26] \"REMAJA\\r\\nDOSIS 2\"                         \n[27] \"REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN\"          \n\n\n\n\n1.3.3 Crafting a function for wrangling\nAs there are 12 different data sets, data wrangling is not as simple.\n\nwe will have to combine them together using a list\nselect relevant columns\ntranslating to English\nmutate a new column for total population & vaccination rate\ncreate a date column for each data set.\n\nLet us manually input the month according to chronological order, and run the data frames through the function we just created. We will also be using as.Date() to ensure the date format.\n\nmonth_list <- list(`Data Vaksinasi Berbasis Kelurahan (01 Juli 2021)`, `Data Vaksinasi Berbasis Kelurahan (1 Agustus 2021)`, `Data Vaksinasi Berbasis Kelurahan (01 September 2021)`, `Data Vaksinasi Berbasis Kelurahan (01 Oktober 2021)`, `Data Vaksinasi Berbasis Kelurahan (01 November 2021)`, `Data Vaksinasi Berbasis Kelurahan (01 Desember 2021)`, `Data Vaksinasi Berbasis Kelurahan (01 Januari 2022)`, `Data Vaksinasi Berbasis Kelurahan (01 Februari 2022)`, `Data Vaksinasi Berbasis Kelurahan (02 Maret 2022)`, `Data Vaksinasi Berbasis Kelurahan (01 April 2022)`, `Data Vaksinasi Berbasis Kelurahan (01 Mei 2022)`, `Data Vaksinasi Berbasis Kelurahan (01 Juni 2022)`)\n\ndate <- c(\"2021-7-1\", \"2021-8-1\", \"2021-9-1\", \"2021-10-1\", \"2021-11-1\", \"2021-12-1\", \"2022-1-1\", \"2022-2-1\", \"2022-3-1\", \"2022-4-1\", \"2022-5-1\", \"2022-6-1\")\n\nlists <- list()\nfor (i in c(1:12)){\n  lists[[i]] <- month_list[[i]] %>% \n    rename(village_code =`KODE KELURAHAN`,\n           city_region =`WILAYAH KOTA`,\n           targeted = `SASARAN`, \n           not_vaccinated =`BELUM VAKSIN`) %>%\n    select(village_code, city_region, not_vaccinated, targeted) %>%\n    mutate(date = as.Date(date[i]),\n           .before = 1)\n}\n\n\n\n1.3.4 Combination of Aspatial Data\nWe will combine them into a single data frame using Reduce()\n\naspatial <- Reduce(rbind, lists)\nglimpse(aspatial)\n\nRows: 3,216\nColumns: 5\n$ date           <date> 2021-07-01, 2021-07-01, 2021-07-01, 2021-07-01, 2021-0…\n$ village_code   <chr> NA, \"3172051003\", \"3173041007\", \"3175041005\", \"31750310…\n$ city_region    <chr> NA, \"JAKARTA UTARA\", \"JAKARTA BARAT\", \"JAKARTA TIMUR\", …\n$ not_vaccinated <dbl> 5041111, 13272, 16477, 18849, 5743, 15407, 12503, 11268…\n$ targeted       <dbl> 7739060, 20393, 25785, 25158, 8683, 22768, 18930, 20267…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#merging-geospatial-and-aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#merging-geospatial-and-aspatial-data",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "1.4 Merging Geospatial and Aspatial Data",
    "text": "1.4 Merging Geospatial and Aspatial Data\nWe will be merging both data sets by village codes, as it is present in both. Similarly to Geospatial data, we will have to filter out the outer island in Aspatial data, categorised by KAB.ADM.KEP.SERIBU as it is not present in the Geospatial data.\n\nunique(aspatial$city_region)\n\n[1] NA                   \"JAKARTA UTARA\"      \"JAKARTA BARAT\"     \n[4] \"JAKARTA TIMUR\"      \"JAKARTA SELATAN\"    \"JAKARTA PUSAT\"     \n[7] \"KAB.ADM.KEP.SERIBU\"\n\n\nWe will remove it through filter(), and make a new column which shows the vaccination rate, and select the rows needed\n\naspatial <- aspatial %>% \n   filter(city_region != \"KAB.ADM.KEP.SERIBU\") %>%\n  mutate(vaccination_rate = as.numeric((targeted-not_vaccinated)/targeted)) %>%\n  select(date, village_code, vaccination_rate)\n\nWe use setdiff() to see what is present in geoJKT which is not in aspatial.\n\nsetdiff(geoJKT$village_code, aspatial$village_code)\n\n[1] \"3188888801\" \"3188888802\"\n\n\nWe will manually add the two sub districts so that both data frames will match after joining.\n\naspatial <- rbind(aspatial, c(\"2021-07-01\", 3188888801,NA),\n                       c(\"2021-08-01\", 3188888801,NA),\n                       c(\"2021-09-01\", 3188888801,NA),\n                       c(\"2021-10-01\", 3188888801,NA),\n                       c(\"2021-11-01\", 3188888801,NA),\n                       c(\"2021-12-01\", 3188888801,NA),\n                       c(\"2022-01-01\", 3188888801,NA),\n                       c(\"2022-02-01\", 3188888801,NA),\n                       c(\"2022-03-01\", 3188888801,NA),\n                       c(\"2022-04-01\", 3188888801,NA),\n                       c(\"2022-05-01\", 3188888801,NA),\n                       c(\"2022-06-01\", 3188888801,NA),\n                       c(\"2021-07-01\", 3188888802,NA),\n                       c(\"2021-08-01\", 3188888802,NA),\n                       c(\"2021-09-01\", 3188888802,NA),\n                       c(\"2021-10-01\", 3188888802,NA),\n                       c(\"2021-11-01\", 3188888802,NA),\n                       c(\"2021-12-01\", 3188888802,NA),\n                       c(\"2022-01-01\", 3188888802,NA),\n                       c(\"2022-02-01\", 3188888802,NA),\n                       c(\"2022-03-01\", 3188888802,NA),\n                       c(\"2022-04-01\", 3188888802,NA),\n                       c(\"2022-05-01\", 3188888802,NA),\n                       c(\"2022-06-01\", 3188888802,NA))\n\nLet us finally join both data sets using left_join() by village code\n\nvaccinationJKT <- left_join(aspatial, geoJKT, \n                         by = c(\"village_code\")) %>%\n  mutate(vaccination_rate = as.numeric(vaccination_rate)) %>%\n   na.exclude() %>%\n   st_as_sf() \n\nWe will then select the important columns\n\nvaccinationJKT %>%\n  select(date, village_code, vaccination_rate)\n\nSimple feature collection with 3132 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 686587.9 ymin: 9295420 xmax: 718314.5 ymax: 9326648\nProjected CRS: DGN95 / UTM zone 48S\n# A tibble: 3,132 × 4\n   date       village_code vaccination_rate                             geometry\n   <date>     <chr>                   <dbl>                   <MULTIPOLYGON [m]>\n 1 2021-07-01 3172051003              0.349 (((706161.9 9323032, 706107.6 93230…\n 2 2021-07-01 3173041007              0.361 (((699268 9320073, 699277.9 9320051…\n 3 2021-07-01 3175041005              0.251 (((705677.8 9306675, 705674.5 93066…\n 4 2021-07-01 3175031003              0.339 (((706070 9313044, 706078.8 9313035…\n 5 2021-07-01 3175101006              0.323 (((711830 9302993, 711816.7 9302969…\n 6 2021-07-01 3174031002              0.340 (((700371 9308387, 700383 9308383, …\n 7 2021-07-01 3175051002              0.444 (((704532.3 9301182, 704545.6 93011…\n 8 2021-07-01 3175041004              0.267 (((706784.6 9305766, 706753.6 93057…\n 9 2021-07-01 3171071002              0.395 (((700406 9314413, 700408.6 9314356…\n10 2021-07-01 3175031002              0.276 (((706499.5 9311596, 706506.5 93115…\n# … with 3,122 more rows"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#creating-a-tmap-function",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#creating-a-tmap-function",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "2.1 Creating a tmap function",
    "text": "2.1 Creating a tmap function\nCreating a function will help us greatly, as there are 12 months of tmap plot to visualise.\n\nplotting <- function(i){\n  vac <- vaccinationJKT %>%\n    filter(date == i)\n  tm_shape(vac) +\n  tm_fill(\"vaccination_rate\",\n          n = 10,\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = paste(i),\n            main.title.position = \"left\",\n            legend.height = 0.7, \n            legend.width = 0.9,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_grid(alpha = 0.3)\n}\n\nWe will be splitting them into groups of 4, into 3 different section in chronological order so that we can visualise it easier\n\ntmap_mode(\"plot\")\ntmap_arrange(plotting(\"2021-07-01\"),\n             plotting(\"2021-08-01\"),\n             plotting(\"2021-09-01\"),\n             plotting(\"2021-10-01\"),\n             ncol = 2)\n\n\n\n\n\ntmap_arrange(plotting(\"2021-11-01\"),\n             plotting(\"2021-12-01\"),\n             plotting(\"2022-01-01\"),\n             plotting(\"2022-02-01\"),\n             ncol = 2)\n\n\n\n\n\ntmap_arrange(plotting(\"2022-03-01\"),\n             plotting(\"2022-04-01\"),\n             plotting(\"2022-05-01\"),\n             plotting(\"2022-06-01\"),\n             ncol = 2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#spatial-patterns-from-chloropleth-map-not-more-than-200-words",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#spatial-patterns-from-chloropleth-map-not-more-than-200-words",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "2.2 Spatial Patterns from chloropleth map (not more than 200 words)",
    "text": "2.2 Spatial Patterns from chloropleth map (not more than 200 words)\nWe can tell that the vaccination rate in the southern area is now comparable to the rest of the area, as it was initially much lower as compared to the other sub districts.\nOverall, The choropleth map shows that vaccination rates in Jakarta have been increasing over time. This is seen from the way the bins have developed, where the lower limit has increased with time. This shows that the vaccination rate is increasing.\nFrom the span of 12 months (July 2021 to June 2022), we can see that the lower bound is 0.227 to 0.781, further proving the accuracy of the pattern."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#function-to-generate-gstar-values",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#function-to-generate-gstar-values",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "3.1 Function to generate gstar values",
    "text": "3.1 Function to generate gstar values\nWe will need a function to generate from all 12 months.\n\n3.1.1 Computing Contiguity Spatial Weights\n\nmonth <- vaccinationJKT %>%\n  filter(date == \"2021-07-01\")\nwm_q <- month %>%\n  na.exclude() %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n                                  .before = 1)\nwm_q\n\nSimple feature collection with 261 features and 13 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 686587.9 ymin: 9295420 xmax: 718314.5 ymax: 9326648\nProjected CRS: DGN95 / UTM zone 48S\n# A tibble: 261 × 14\n   nb    wt     date       villag…¹ vacci…² OBJEC…³ DESA    KODE PROVI…⁴ KAB_K…⁵\n * <nb>  <list> <date>     <chr>      <dbl>   <dbl> <chr>  <dbl> <chr>   <chr>  \n 1 <int> <dbl>  2021-07-01 3172051…   0.349   25455 ANCOL 317205 DKI JA… JAKART…\n 2 <int> <dbl>  2021-07-01 3173041…   0.361   25486 ANGKE 317304 DKI JA… JAKART…\n 3 <int> <dbl>  2021-07-01 3175041…   0.251   25605 BALE… 317504 DKI JA… JAKART…\n 4 <int> <dbl>  2021-07-01 3175031…   0.339   25595 BALI… 317503 DKI JA… JAKART…\n 5 <int> <dbl>  2021-07-01 3175101…   0.323   25642 BAMB… 317510 DKI JA… JAKART…\n 6 <int> <dbl>  2021-07-01 3174031…   0.340   25531 BANG… 317403 DKI JA… JAKART…\n 7 <int> <dbl>  2021-07-01 3175051…   0.444   25609 BARU  317505 DKI JA… JAKART…\n 8 <int> <dbl>  2021-07-01 3175041…   0.267   25604 BATU… 317504 DKI JA… JAKART…\n 9 <int> <dbl>  2021-07-01 3171071…   0.395   25418 BEND… 317107 DKI JA… JAKART…\n10 <int> <dbl>  2021-07-01 3175031…   0.276   25594 BIDA… 317503 DKI JA… JAKART…\n# … with 251 more rows, 4 more variables: subdistrict <chr>, DESA_KELUR <chr>,\n#   JUMLAH_PEN <dbl>, geometry <MULTIPOLYGON [m]>, and abbreviated variable\n#   names ¹​village_code, ²​vaccination_rate, ³​OBJECT_ID, ⁴​PROVINSI, ⁵​KAB_KOTA\n\n\n\n\n3.1.2 Computing local GI\nWe will be using set.seed() to ensure that the output will be the same\n\nset.seed(1234)\njuly_LGI <- wm_q %>%\n  mutate(local_Gi = local_gstar_perm(vaccination_rate, nb, wt, nsim = 99), .before = 1) %>%\n  unnest(local_Gi)\n\n\n\n3.1.3 Visualizing p-value of local Gi\n\ntmap_mode(\"plot\")\ntm_shape(july_LGI) +\n    tm_polygons() +\n    tm_shape(july_LGI %>% filter(p_sim < 0.05)) +\n    tm_fill(\"gi_star\") +\n    tm_borders(alpha = 0.5) +\n    tm_layout(main.title = paste(\"local Gi Significance\", \"(\", july_LGI$date[1],\")\"),\n              main.title.size = 0.8)\n\n\n\n\n\n\n3.1.4 local GI computation function\nAgain, we add set.seed() to ensure that the output will always be the same\n\nlocal_gi <- function(x){\n  set.seed(1234)\n  month <- vaccinationJKT %>%\n    filter(date == x)\n  wm_q <- month %>%\n    na.exclude() %>%\n    mutate(nb = st_contiguity(geometry),\n           wt = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1))\n  result <- wm_q %>%\n    mutate(local_gi = local_gstar_perm(vaccination_rate,\n                                   nb,\n                                   wt,\n                                   nsim = 99),\n           .before = 1) %>% \n    unnest(local_gi)\n  return(result)\n}\n\n\ndate <- c(\"2021-07-01\", \"2021-08-01\", \"2021-09-01\", \"2021-10-01\", \"2021-11-01\", \"2021-12-01\",\n          \"2022-01-01\", \"2022-02-01\", \"2022-03-01\",\"2022-04-01\", \"2022-05-01\", \"2022-06-01\")\nmonth_GI <- list()\nfor (i in 1:12){\n  month_GI[[i]] <- local_gi(date[i])\n}\n\n\n\n3.1.5 Tmap Function\n\ngi_graph <- function(x){\n  HCSA_sig <- x %>%\n    filter(p_sim < 0.05)\n  HCSA_plots <- tm_shape(x) +\n    tm_polygons() +\n    tm_borders(alpha = 0.5) +\n    tm_shape(HCSA_sig) +\n      tm_fill(\"gi_star\",\n              palette = \"Reds\",\n              midpoint = 0) +\n      tm_borders(alpha = 0.4) +\n    tm_layout(main.title = paste(\"significant local Gi\", \"(\",x$date[1],\")\"),\n              main.title.size = 0.8)\n  return(HCSA_plots)\n}\n\nWe will now plot it according to chronological order.\n\ntmap_mode(\"plot\")\ntmap_arrange(gi_graph(month_GI[[1]]),\n             gi_graph(month_GI[[2]]),\n             gi_graph(month_GI[[3]]),\n             gi_graph(month_GI[[4]]),\n             ncol = 2)\n\n\n\n\n\ntmap_arrange(gi_graph(month_GI[[5]]),\n             gi_graph(month_GI[[6]]),\n             gi_graph(month_GI[[7]]),\n             gi_graph(month_GI[[8]]),\n             ncol = 2)\n\n\n\n\n\ntmap_arrange(gi_graph(month_GI[[9]]),\n             gi_graph(month_GI[[10]]),\n             gi_graph(month_GI[[11]]),\n             gi_graph(month_GI[[12]]),\n             ncol = 2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#statistical-conclusions-not-more-than-250-words",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#statistical-conclusions-not-more-than-250-words",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "3.2 Statistical conclusions (not more than 250 words)",
    "text": "3.2 Statistical conclusions (not more than 250 words)\nWe understand that a Gi value that has a significant and positive z-score is a hot spot, representing clustering of high values, and the opposite for cold spots as it has a significant negative z-score which represent clustering of low values.\nThe cold areas at the center have persisted for quite a while, which may suggest that the sub district wide lack of vaccination knowledge or a shortage of medical resources. Should the Indonesian government choose to focus on where to increase vaccination rate, they can opt to invest more time into the targeted area of concern, with the help of this Gi map. However, overall vaccination rates have risen."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#time-series-cube",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#time-series-cube",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "4.1 Time series cube",
    "text": "4.1 Time series cube\nWe can use spacetime() to create the time series cube, with reference to in-class Exercise 7\n\nvacc_rate_st <- as_spacetime(vaccinationJKT,\n                                .loc_col = \"village_code\",\n                                .time_col = \"date\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#spatial-weights",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#spatial-weights",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "4.2 Spatial weights",
    "text": "4.2 Spatial weights\n\nvacc_rate_nb <- vacc_rate_st %>%\n  activate(\"geometry\") %>%\n  mutate(\n    nb = include_self(st_contiguity(geometry)),\n    wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n                                 .before = 1) %>%\n                                set_nbs(\"nb\") %>%\n                                set_wts(\"wt\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-the-gi",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-the-gi",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "4.3 Computing the GI",
    "text": "4.3 Computing the GI\nwe will now use local_gstar_perm() to compute the Gi\n\ngi_s <- vacc_rate_nb %>%\n  group_by(date) %>%\n  mutate(vaccination_rate = as.numeric(vaccination_rate),\n         gi_star = local_gstar_perm(vaccination_rate, \n                                    nb, \n                                    wt, \n                                    nsim = 99)) %>%\n                                    tidyr::unnest(gi_star)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#mann-kendall-test",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#mann-kendall-test",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "4.4 Mann-Kendall Test",
    "text": "4.4 Mann-Kendall Test\nWe will now select 3 sub districts and describe the trends using the Mann-Kendall test\n1) 3175061001\n2) 3173011006\n3) 3174071005\n\n4.4.1 First district (3175061001)\n\ndis_1 <- gi_s %>%\n  ungroup() %>%\n  filter(village_code == \"3175061001\") %>%\n  select(date, village_code, gi_star)\n\n\nggplot(data = dis_1, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\nWe will be mainly focusing on two outputs which are:\ntau : A measure of the strength and direction of the trend in the data. It ranges from -1 to 1, where a tau value of -1 indicates a strong negative trend, a tau value of 0 indicates no trend, and a tau value of 1 indicates a strong positive trend.\nsl : This is the p value and for it to be significant, it has to be less than significance level, 0.05.\n\nstat1 <- dis_1 %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\nglimpse(stat1)\n\nRows: 1\nColumns: 5\n$ tau  <dbl> 0.9090908\n$ sl   <dbl> 5.209446e-05\n$ S    <dbl> 60\n$ D    <dbl> 66.00001\n$ varS <dbl> 212.6667\n\n\nConclusion for sub district 3175061001\nWe see a positive tau value and an signifiant sl value as it is < 0.05. This means that there is a slight positive association in gi* values and date and it is statistically significant. It also implies that the vaccination rate has been increasing, and also greater clustering (hot spot).\n\n\n4.4.2 Second district (3173011006)\nWe will be repeating the steps above for the second district as well.\n\ndis_2 <- gi_s %>%\n  ungroup() %>%\n  filter(village_code == \"3173011006\") %>%\n  select(date, village_code, gi_star)\n\n\nggplot(data = dis_2, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\nstat2 <- dis_2 %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\nglimpse(stat2)\n\nRows: 1\nColumns: 5\n$ tau  <dbl> -0.4848484\n$ sl   <dbl> 0.03352417\n$ S    <dbl> -32\n$ D    <dbl> 66.00001\n$ varS <dbl> 212.6667\n\n\nConclusion for sub district 3173011006 We see a slight negative tau value and an significant sl value as it is < 0.05. This means that there is a slight negative association in gi* values and date and it is statistically significant. This means that the vaccination rate in this sub district is decreasing (cold spot), and it is statistically significant.\n\n\n4.4.3 Third district (3174071005)\n\ndis_3 <- gi_s %>%\n  ungroup() %>%\n  filter(village_code == \"3174071005\") %>%\n  select(date, village_code, gi_star)\n\n\nggplot(data = dis_3, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\nstat3 <- dis_3 %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\nglimpse(stat3)\n\nRows: 1\nColumns: 5\n$ tau  <dbl> -0.8484848\n$ sl   <dbl> 0.0001622756\n$ S    <dbl> -56\n$ D    <dbl> 66.00001\n$ varS <dbl> 212.6667\n\n\nConclusion for sub district 3174071005 We see a negative tau value and an significant sl value as it is < 0.05. This means that there is a negative association in gi* values and date and it is statistically significant. This also means that the vaccination rate in this sub district is decreasing (cold spot)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hotspot-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hotspot-analysis",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "4.5 Emerging Hotspot Analysis",
    "text": "4.5 Emerging Hotspot Analysis\nWe will now run the analysis using MannKendall() again, while filtering by significant sl values\n\nehsa <- gi_s %>%\n  group_by(date) %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>%\n  tidyr::unnest_wider(mk) %>%\n  filter(sl < 0.05)\n\nWe will further arrange it here\n\nemerging <- ehsa %>% \n  arrange(sl, abs(tau)) %>% \n  slice(1:5)\n\nWe will be using emerging_hotspot_analysis(), where x takes in a space-time object, .var takes in the variable of vaccination_rate, and k refers to the number of time lags. We will be using set.seed() again to ensure the same output.\n\nset.seed(1234)\nehsa <- emerging_hotspot_analysis(\n  x = vacc_rate_st,\n  .var = \"vaccination_rate\",\n  k = 1,\n  nsim = 99\n)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-the-distribution-of-ehsa",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-the-distribution-of-ehsa",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "4.6 Visualising the distribution of EHSA",
    "text": "4.6 Visualising the distribution of EHSA\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-ehsa-using-tmap",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-ehsa-using-tmap",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "4.7 Visualising EHSA using tmap",
    "text": "4.7 Visualising EHSA using tmap\nWe will be using left_join() by village_code and location to join ESHA with classification\n\nvacc_ehsa <- left_join(geoJKT, ehsa, by = c(\"village_code\" = \"location\"))\n\n\nehsa_sig <- vacc_ehsa  %>%\n  filter(p_value < 0.05)\ntmap_mode(\"view\")\ntm_shape(vacc_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4) +\n  tm_view(set.zoom.limits =c(10, 16))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#statistical-conclusion",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#statistical-conclusion",
    "title": "Take-home Exercise 2: Spatio-Temporal Analysis",
    "section": "4.8 Statistical conclusion",
    "text": "4.8 Statistical conclusion\nFrom this link, we are able to derive some useful insights from the table.\n\n\n\n\n\n\n\nPattern name\nDefinition\n\n\n\n\nSporadic cold spot\nA statistically significant cold spot for the final time-step interval with a history of also being an on-again and off-again cold spot. Less than 90 percent of the time-step intervals have been statistically significant cold spots and none of the time-step intervals have been statistically significant hot spots.\n\n\nOscillating coldspot\nA statistically significant cold spot for the final time-step interval that has a history of also being a statistically significant hot spot during a prior time step. Less than 90 percent of the time-step intervals have been statistically significant cold spots.\n\n\nOscillating hotspot\nA statistically significant hot spot for the final time-step interval that has a history of also being a statistically significant cold spot during a prior time step. Less than 90 percent of the time-step intervals have been statistically significant hot spots.\n\n\n\nBy understanding this table, This could imply that the presence of some areas in which vaccination rate often switch between insignificant levels of clustering and significant levels of clustering of low vaccination rates is present.\nAdditionally, with the vaccination programme by the government, we can also imply that more states are moving from the clustering of low to high vaccination rates, as the presence of oscillating hot spot implies that the initial cold spots became hot spots."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In Class Exercise 3: Analytical Mapping",
    "section": "",
    "text": "#Installing and loading packages"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-distribution-of-non-functional-water-point",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-distribution-of-non-functional-water-point",
    "title": "In Class Exercise 3: Analytical Mapping",
    "section": "1.1 Visualising distribution of non-functional water point",
    "text": "1.1 Visualising distribution of non-functional water point\n\n\nShow code\np1 <- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\", \n          n= 10,\n          style = \"equal\",\n          palette =\"Blues\") +\n  tm_borders(lwd = 0.1, \n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water\",\n            legend.outside = FALSE)\n\n# n = 10 indicates 10 range of colors\n# style = equal indicates the distribution of data, in this case, equal refers to equal difference per range as per seen in the plot\n\n\n\n\nShow code\np2 <- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\", \n          n= 10,\n          style = \"equal\",\n          palette =\"Blues\") +\n  tm_borders(lwd = 0.1, \n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total water point\",\n            legend.outside = FALSE)\n\n\nArrange both maps into 1 visualisation\n\n\nShow code\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#deriving-proportion-of-functional-water-points-and-non-functional-waterpoints",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#deriving-proportion-of-functional-water-points-and-non-functional-waterpoints",
    "title": "In Class Exercise 3: Analytical Mapping",
    "section": "2.1 Deriving Proportion of Functional Water Points and Non-Functional WaterPoints",
    "text": "2.1 Deriving Proportion of Functional Water Points and Non-Functional WaterPoints\n\n\nShow code\nNGA_wp <- NGA_wp %>%\n  mutate(pct_functional = wp_functional/total_wp) %>%\n  mutate(pct_non_functional = wp_nonfunctional/total_wp)\n\n\n\n\nShow code\np3 <- tm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd= 0.1, \n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of Proportion of\\nFunctional WaterPoints\",\n            legend.outside = FALSE)\n\np4 <- tm_shape(NGA_wp) +\n  tm_fill(\"pct_non_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd= 0.1, \n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of Proportion of\\nNon_Functional WaterPoints\",\n            legend.outside = FALSE)\n\ntmap_arrange(p4, p3, nrow = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#percentile-map",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#percentile-map",
    "title": "In Class Exercise 3: Analytical Mapping",
    "section": "3.1 Percentile Map",
    "text": "3.1 Percentile Map\nStep 1: Exclude records with NA\n\n\nShow code\nNGA_wp <- NGA_wp %>%\n  drop_na()\n\n\nStep 2: Creating customised classification\n\n\nShow code\npercent <- c(0,.01,.1,.5,.9,.99,1)\nvar <- NGA_wp[\"pct_functional\"] %>%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n\n        0%         1%        10%        50%        90%        99%       100% \n0.00000000 0.01818182 0.18181818 0.41666667 0.76086957 1.00000000 1.00000000 \n\n\nShow code\n# NULL forces NGA_wp[\"pct_functional\"] into var (dataframe)\n\n\n\n\nShow code\nget.var <- function(vname, df) {\n  v <- df[vname] %>%\n    st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\n\n\nShow code\npercentmap <- function(vnam, df, legtitle=NA, mtitle = \"Percentile Map\"){\n  percent <- c(0,.01,.1,.5,.9,.99,1)\n  var <- get.var(vnam, df)\n  bperc <- quantile(var, percent)\n  tm_shape(df) + \n    tm_polygons() + \n    tm_shape(df) +\n    tm_fill(vnam,\n            title = legtitle,\n            breaks=bperc,\n            palette=\"Blues\",\n            labels = c(\"< 1%\",\"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \">99%\")) +\n    tm_borders() +\n    tm_layout(main.title = mtitle, \n              title.position = c(\"right\", \"bottom\"))\n}\n\npercentmap(\"pct_functional\", NGA_wp,)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#box-map",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#box-map",
    "title": "In Class Exercise 3: Analytical Mapping",
    "section": "3.2 Box map",
    "text": "3.2 Box map"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In class exercise 4",
    "section": "",
    "text": "Getting started\n\npacman::p_load(maptools, sf, raster, spatstat, tmap)\n\n\nImporting the spatial data\n\nchildcare_sf <- st_read(\"data/child-care-services-geojson.geojson\") %>% st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/In-class_Ex/In-class_Ex04/data/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/In-class_Ex/In-class_Ex04/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf <- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/In-class_Ex/In-class_Ex04/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nConverting sf data frames to sp’s Spatial class\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\n\n\nConverting the Spatial class into generic sp format\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\n\n\nConverting the generic sp format into spatstat’s ppp format\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\n\n\nHandling duplicate object\n\nchildcare_ppp_jit <- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\nplot(childcare_ppp)\n\n\n\n\n\ntmap_mode('view') +\n  tm_shape(childcare) +\n  tm_dots(alpha = 0.5,\n          size = 0.01) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\n\nCreating owin object\n\nsg_owin <- as(sg_sp, \"owin\")\n\n\nplot(sg_owin)\n\n\n\n\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\n\nComputing kernel density estimation using automatic bandwidth selection method\n\nkde_childcareSG_bw <- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\nbw <- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\nRescalling KDE values\n\nchildcareSG_ppp.km <- rescale(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG.bw <- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In class exercise 5",
    "section": "",
    "text": "#Gettin started\n\npacman::p_load(tidyverse, tmap, sf, sfdep)\n\n#Importing data\n\nstudyArea <- st_read(dsn = 'data',\n                    layer = 'study_area') %>%\n  st_transform(crs = 3829)\n\nReading layer `study_area' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/In-class_Ex/In-class_Ex05/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 7 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 121.4836 ymin: 25.00776 xmax: 121.592 ymax: 25.09288\nGeodetic CRS:  TWD97\n\n\n\nstores <- st_read(dsn = 'data',\n                    layer = 'stores') %>%\n  st_transform(crs = 3829)\n\nReading layer `stores' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/In-class_Ex/In-class_Ex05/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1409 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 121.4902 ymin: 25.01257 xmax: 121.5874 ymax: 25.08557\nGeodetic CRS:  TWD97\n\n\n#Plotting of maps\n\ntmap_mode('view')\ntm_shape(studyArea) +\n  tm_polygons() +\n  tm_shape(stores) +\n    tm_dots(col = 'Name',\n           size = 0.01,\n           border.col = 'black',\n           border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(12,16))\n\n\n\n\n\n\n#Local Colocation Quotients (LCLQ)\n\nnb <- include_self(\n  st_knn(st_geometry(stores), 6))\n\nwt <- st_kernel_weights(nb, stores, 'gaussian',\n                         adaptive = TRUE)\n\nFamilyMart <- stores %>%\n  filter(Name == 'Family Mart')\n  \nA <- FamilyMart$Name\n\nSevenEleven <- stores %>%\n  filter(Name == '7-Eleven')\n\nB <- SevenEleven$Name\n\nLCLQ <- local_colocation(A, B, nb, wt, 49)\n\nLCLQ_stores <- cbind(stores, LCLQ)\n\n\ntmap_mode(\"view\") \n\ntm_shape(studyArea) +   \n  tm_polygons() +\n  tm_shape(LCLQ_stores) + \n  tm_dots(col = \"X7.Eleven\", size = 0.01,border.col = \"black\", border.lwd = 0.5) + \n  tm_view(set.zoom.limits = c(12,16))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/data/study_area.html",
    "href": "In-class_Ex/In-class_Ex05/data/study_area.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/data/stores.html",
    "href": "In-class_Ex/In-class_Ex05/data/stores.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     \n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In Class Exercise 2: Geospatial Data Wrangling",
    "section": "",
    "text": "Water is an important resource to mankind. Clean and accessible water is critical to human health. It provides a healthy environment, a sustainable economy, reduces poverty and ensures peace and security. Yet over 40% of the global population does not have access to sufficient clean water. By 2025, 1.8 billion people will be living in countries or regions with absolute water scarcity, according to UN-Water. The lack of water poses a major threat to several sectors, including food security. Agriculture uses about 70% of the world’s accessible freshwater.\nDeveloping countries are most affected by water shortages and poor water quality. Up to 80% of illnesses in the developing world are linked to inadequate water and sanitation. Despite technological advancement, providing clean water to the rural community is still a major development issues in many countries globally, especially countries in the Africa continent.\nTo address the issue of providing clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository, a cloud-based data library. What is so special of this project is that data are collected based on WPDx Data Standard.\n\n\nThe specific tasks of this take-home exercise are as follows:\n\nUsing appropriate sf method, import the shapefile into R and save it in a simple feature data frame format. Note that there are three Projected Coordinate Systems of Nigeria, they are: EPSG: 26391, 26392, and 26303. You can use any one of them.\nUsing appropriate tidyr and dplyr methods, derive the proportion of functional and non-functional water point at LGA level.\nCombining the geospatial and aspatial data frame into simple feature data frame.\nVisualising the distribution of water point by using appropriate analytical visualisation methods."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-aspatial-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-aspatial-data",
    "title": "In Class Exercise 2: Geospatial Data Wrangling",
    "section": "3.1 Importing Aspatial data",
    "text": "3.1 Importing Aspatial data\nUse filter to extract only “Nigeria”\n\n\nShow code\nwp_nga <- read_csv(file = \"data/aspatial/WPdx.csv\") |>\n  filter(`#clean_country_name` == \"Nigeria\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#checking-duplicate-name-and-amending-them",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#checking-duplicate-name-and-amending-them",
    "title": "In Class Exercise 2: Geospatial Data Wrangling",
    "section": "5.1 Checking duplicate name and amending them",
    "text": "5.1 Checking duplicate name and amending them\n\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN) == TRUE]\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\n\nCorrect the areas as they are located in different states\n\nNGA$ADM2_EN[94] <- \"Bassa, Kogi\"\nNGA$ADM2_EN[95] <- \"Bassa, Plateau\"\nNGA$ADM2_EN[304] <- \"Ifelodun, Kwara\"\nNGA$ADM2_EN[305] <- \"Ifelodun, Osun\"\nNGA$ADM2_EN[355] <- \"Irepodun, Kwara\"\nNGA$ADM2_EN[356] <- \"Irepodun, Osun\"\nNGA$ADM2_EN[519] <- \"Nasarawa, Kano\"\nNGA$ADM2_EN[520] <- \"Nasarawa, Nasarawa\"\nNGA$ADM2_EN[546] <- \"Obi, Benue\"\nNGA$ADM2_EN[547] <- \"Obi, Nasarawa\"\nNGA$ADM2_EN[693] <- \"Surulere, Lagos\"\nNGA$ADM2_EN[694] <- \"Surulere, Oyo\"\n\nRerun code to check\n\n\nShow code\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN) == TRUE]\n\n\ncharacter(0)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#extracting-water-point-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#extracting-water-point-data",
    "title": "In Class Exercise 2: Geospatial Data Wrangling",
    "section": "6.1 Extracting Water Point Data",
    "text": "6.1 Extracting Water Point Data\nFilter based on functional, non_functional and unknown respectively.\n\nwp_functional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\n\nwp_nonfunctional <- wp_sf_nga %>% \n  filter(status_clean %in% \n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\"))\n\n\nwp_unknown <- wp_sf_nga %>%\n  filter(status_clean %in% \"unknown\")\n\n\nfreq(data = wp_functional,\n     input = 'status_clean')\n\n\n\n\n                 status_clean frequency percentage cumulative_perc\n1                  Functional     47228      99.81           99.81\n2   Functional but not in use        86       0.18           99.99\n3 Functional but needs repair         4       0.01          100.00\n\n\n\nfreq(data = wp_nonfunctional,\n     input = 'status_clean')\n\n\n\n\n                      status_clean frequency percentage cumulative_perc\n1                   Non-Functional     30638      98.94           98.94\n2         Abandoned/Decommissioned       321       1.04           99.98\n3 Non-Functional due to dry season         7       0.02          100.00\n\n\n\nfreq(data = wp_unknown,\n     input = 'status_clean')\n\n\n\n\n  status_clean frequency percentage cumulative_perc\n1      unknown     10154        100             100"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#performing-point-in-polygon-count",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#performing-point-in-polygon-count",
    "title": "In Class Exercise 2: Geospatial Data Wrangling",
    "section": "6.2 Performing Point-in-Polygon Count",
    "text": "6.2 Performing Point-in-Polygon Count\n\nNGA_wp <- NGA %>%\n  mutate(`total_wp` = lengths(\n    st_intersects(NGA, wp_sf_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(NGA, wp_functional))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(NGA, wp_nonfunctional))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(NGA, wp_unknown)))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualing-attributes-by-using-statistical-graph",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualing-attributes-by-using-statistical-graph",
    "title": "In Class Exercise 2: Geospatial Data Wrangling",
    "section": "6.3 Visualing attributes by using statistical graph",
    "text": "6.3 Visualing attributes by using statistical graph\n\n\nShow code\nggplot(data = NGA_wp,\n       aes(x = total_wp)) +\n  geom_histogram(bins = 20, \n                 color = \"black\",\n                 fill =\"light blue\") +\n  geom_vline(aes(xintercept=mean(total_wp, na.rm=T)),\n             color = \"red\", linetype=\"dashed\", size = 0.8) +\n  xlab(\"No of water points\") +\n  ylab(\"No. of\\nLGAs\") +\n  theme(axis.title.y = element_text(angle = 0))\n\n\n\n\n\n\n\nShow code\nwrite_rds(NGA_wp, \"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In class exercise 7",
    "section": "",
    "text": "pacman::p_load(sf, sfdep, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#the-data",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#the-data",
    "title": "In class exercise 7",
    "section": "The data",
    "text": "The data\nFor the purpose of this in class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:\n\nHunan, a geospatial data set in the ESRI shapefile format, and\nHunan_2012, an attribute dataset in csv format\n\n\nImporting geospatial data: shapefile into R environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/In-class_Ex/In-class_Ex07/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nImport csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class. Readr will be loaded as part of tidyverse.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\nCombining both data frames using left join\nWe want the output in an sf dataframe hence, the left dataframe should be hunan, which has a sf format. We need to find a unique identifier, in this case it is by=“County”, where both data frames have a common field.\n\nhunan_GDPPC<-hunan |> \n  left_join(hunan2012, by=\"County\") |> \n  select(1:4, 7, 15) #selecting only the GDPPC column\n\n\n\nPlotting in a chloropleth map\n\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\",\n          style=\"quantile\",\n          palette=\"Blues\",\n          totle=\"GDPPC\")+\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title= \"Distribution of GDP per capita by district\", \n            main.title.position=\"center\",\n            main.title.size=1.2,\n            legend.height=0.45,\n            legend.width = 0.35,\n            frame=TRUE)+\n    tm_compass(type=\"8star\", size=2)+\n    tm_scale_bar()+\n    tm_grid(alpha=0.2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In class exercise 6",
    "section": "",
    "text": "#1 Load Data\n\npacman::p_load(sf, sfdep, tmap, tidyverse)\n\nLet’s start by importing Geospatial data\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/In-class_Ex/In-class_Ex06/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nNext, Aspatial data\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\nhunan_GDPPC <- left_join(hunan, hunan2012) %>%\n  select(1:4, 7,  15)\n\n#2 Visualising plot\n\ntmap_mode(\"plot\")\n\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title =  \"Distribution of GDP per capita by distribution\",\n  main.title.position = \"center\",\n  main.title.size = 0.9,\n  legend.height = 0.45,\n  legend.width = 0.35,\n  frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n\n\n\n\n#3 Computing using different Contiguity neighbour methods\nqueen method\n\ncn_queen <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         .before = 1)\n\nrook method\n\ncn_rook <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         queen = FALSE,\n         .before = 1)\n\n#4 Contiguity weights queen method\n\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb),\n         .before = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "title": "In Class Exercise 8",
    "section": "",
    "text": "pacman::p_load(olsrr, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)\n\nGeospatial data\n\nmpsz <- st_read(dsn = \"data/geospatial\",\n                layer =\"MP14_SUBZONE_WEB_PL\") %>%\n  st_transform(crs = 3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/In-class_Ex/In-class_Ex08/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nAspatial data\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\n\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs = 4326) %>%\n  st_transform(crs = 3414)\n\n\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "title": "In Class Exercise 9",
    "section": "",
    "text": "Loading the data!\n\npacman::p_load(sf, GWmodel, SpatialML, tidyverse, tmap, ggpubr, olsrr, devtools, tidymodels, rsample)\n\nPreparing data\n\nmdata <- read_rds(\"data/aspatial/mdata.rds\")\n\n\nset.seed(1234)\nresale_split <- initial_split(mdata, prop = 6.5/10)\n\ntrain_data <- training(resale_split)\ntest_data <- training(resale_split)\n\n\nwrite_rds(train_data, \"data/aspatial/train_data.rds\")\nwrite_rds(test_data, \"data/aspatial/test_data.rds\")\n\n\n#predictive model uses train data\n#predictive modelling not particular about f test, that is for exploring\n#residual standard error is more useful \n\nprice_mlr <- lm(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, data = train_data)\n\nsummary(price_mlr)\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + \n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + \n    PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              107601.073  10601.261  10.150  < 2e-16 ***\nfloor_area_sqm             2780.698     90.579  30.699  < 2e-16 ***\nstorey_order              14299.298    339.115  42.167  < 2e-16 ***\nremaining_lease_mths        344.490      4.592  75.027  < 2e-16 ***\nPROX_CBD                 -16930.196    201.254 -84.124  < 2e-16 ***\nPROX_ELDERLYCARE         -14441.025    994.867 -14.516  < 2e-16 ***\nPROX_HAWKER              -19265.648   1273.597 -15.127  < 2e-16 ***\nPROX_MRT                 -32564.272   1744.232 -18.670  < 2e-16 ***\nPROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\nPROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\nPROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\nWITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  < 2e-16 ***\nWITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  < 2e-16 ***\nWITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\nWITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61650 on 10320 degrees of freedom\nMultiple R-squared:  0.7373,    Adjusted R-squared:  0.737 \nF-statistic:  2069 on 14 and 10320 DF,  p-value: < 2.2e-16\n\n\n\n#important\n\ntrain_data_sp <- as_Spatial(train_data)\ntrain_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 10335 \nextent      : 11597.31, 42623.63, 28217.39, 48741.06  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,          PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       218000,             74,            1,                  555, 0.999393538715878, 1.98943787433087e-08, 0.0333358643817954, 0.0220407324774434, 0.0441643212802781, 0.0652540365486641,                0, 6.20621206270077e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1186888,            133,           17,                 1164,  19.6500691667807,     3.30163731686804,   2.86763031236184,   2.13060636038504,   2.41313695915468,   10.6223726149914, 2.27100643784442,    0.808332738794272,     1.57131703651196,                        7,                    20, ... \n\n\n\n#preparing coordinate data *important if not algo wont work\n#sf data frame is a list object, one is a attribute table, one is geo table\n#ranger dont understand sf format because we just did sampling so it is sf for now\n#can use _st_drop_geometry, but it's not good because we must keep it\n#hence, we must use the things below to extract the coordinates out\n\ncoords <- st_coordinates(mdata)\ncoords_train <- st_coordinates(train_data)\ncoords_test <- st_coordinates(test_data)\n\n\n#drop before using ranger\n\ntrain_data <- train_data %>%\n  st_drop_geometry()\n\n\nset.seed(1234)\nrf <- ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, data = train_data)\n\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       731404460 \nR squared (OOB):                  0.9493789 \n\n#MSE means means square error. Not the same as residual square error. RSE is the square root of MSE. Look at MSE to compare \n\n\nset.seed(1234)\n\ngwRF_adaptive <- grf(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n                     dframe = train_data,\n                     bw = 55,\n                     kernel = \"adaptive\",\n                     coords = coords_train)\n#use AIC predicted. AIC will be close to AICc if there are no bias\n# gwRF_adaptive$Global.Model$variable.importance\n\n\ntest_data <- cbind(test_data, coords_test) %>%\n  st_drop_geometry()\n\n\ngwRF_pred <- predict.grf(gwRF_adaptive, test_data, x.var.name = \"X\", y.var.name = \"Y\", local.w = 1, global.w = 0)\n\n\ngwRF_pred_df <- as.data.frame(gwRF_pred)\n\n\ngwRF_test_predict <- cbind(test_data, predict_grf_df)\n\n\nwrite_rds(test_predict, \"data/model/test_predict.rds\")\n\n\nggplot(data = test_predict,\n       aes(x = predict_grf,\n           y = resale_price)) +\n  geom_point()\n\n\nsqrt(mean((test_predict$resale_price - test_predict$predict_grf)^2))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "",
    "text": "Several things influence housing costs. Some of them have a worldwide scope, such the overall health of a nation’s economy or the level of inflation. Some may focus more on the properties themselves. You can further divide these characteristics into structural and geographic ones.\nGeographical Weighted Models were introduced for enhancing predictive model for housing resale prices as traditional price predictive models failed to take account the spatial correlation and heterogeneity in geographical aspects which caused inaccuracy and bias.\n\n\n\npacman::p_load('sf', 'tidyverse', 'tmap', 'spdep', 'onemapsgapi', 'units', 'matrixStats', 'readxl', 'jsonlite', 'olsrr', 'corrplot', 'ggpubr', 'GWmodel',\n'devtools', 'kableExtra', 'plotly', 'ggthemes', 'ranger', 'Metrics')\n\n\n\n\n\ndatasets <- data.frame(\n  Type=c(\"Aspatial\",\n         \"Geospatial\",\n         \n         \"Geospatial - Extracted\",\n         \"Geospatial - Extracted\",\n         \"Geospatial - Extracted\",\n         \"Geospatial - Extracted\",\n         \"Geospatial - Extracted\",\n         \"Geospatial - Extracted\",\n         \"Geospatial - Extracted\",\n         \n         \"Geospatial - Selfsourced\",\n         \"Geospatial - Selfsourced\",\n         \"Geospatial - Selfsourced\",\n         \"Geospatial - Selfsourced\",\n         \"Geospatial - Selfsourced\"),\n  \n  Name=c(\"Resale Flat Prices\",\n         \"Master Plan 2019 Subzone Boundary (Web)\",\n         \n         \"Childcare Services\",\n         \"Community Clubs\",\n         \"Eldercare Services\",\n         \"Hawker Centres\",\n         \"Kindergartens\",\n         \"Parks\",\n         \"Libraries\",\n         \n         \n         \"Bus Stop Locations Aug 2021\",\n         \"MRT & LRT Locations Aug 2021\",\n         \"Supermarkets\",\n         \"Shopping Mall SVY21 Coordinates\", \n         \"Primary School\"),\n  \n  Format=c(\".csv\", \n           \".shp\",\n           \n           \".shp\", \n           \".shp\", \n           \".shp\", \n           \".shp\",\n           \".shp\", \n           \".shp\",\n           \".shp\",\n           \n           \".shp\",\n           \".kml\",\n           \".shp\",\n           \".shp\",\n           \".csv\"),\n  \n  Source=c(\"[data.gov.sg](https://data.gov.sg/dataset/resale-flat-prices)\",\n           \"[data.gov.sg](https://data.gov.sg/dataset/master-plan-2014-subzone-boundary-web)\",\n           \n           \"[OneMap API](https://www.onemap.gov.sg/docs/)\",\n           \"[OneMap API](https://www.onemap.gov.sg/docs/)\",\n           \"[OneMap API](https://www.onemap.gov.sg/docs/)\",\n           \"[OneMap API](https://www.onemap.gov.sg/docs/)\",\n           \"[OneMap API](https://www.onemap.gov.sg/docs/)\",\n           \"[OneMap API](https://www.onemap.gov.sg/docs/)\",\n           \"[OneMap API](https://www.onemap.gov.sg/docs/)\",\n           \n           \"[datamall.lta](https://datamall.lta.gov.sg/content/datamall/en/search_datasets.html?searchText=bus%20stop)\",\n           \"[data.gov](https://data.gov.sg/dataset/lta-mrt-station-exit)\",\n           \"[Onemap.gov](https://www.onemap.gov.sg/main/v2/essentialamenities)\",\n           \"[Valery Lim's Github](https://github.com/ValaryLim/Mall-Coordinates-Web-Scraper/blob/master/mall_coordinates_updated.csv)\",\n           \"[data.gov](https://data.gov.sg/dataset/school-directory-and-information)\")\n  )\n\nlibrary(knitr)\nlibrary(kableExtra)\nkable(datasets, caption=\"Datasets Used\") %>%\n  kable_material(\"hover\", latex_options = \"scale_down\")\n\n\n\nDatasets Used\n \n  \n    Type \n    Name \n    Format \n    Source \n  \n \n\n  \n    Aspatial \n    Resale Flat Prices \n    .csv \n    [data.gov.sg](https://data.gov.sg/dataset/resale-flat-prices) \n  \n  \n    Geospatial \n    Master Plan 2019 Subzone Boundary (Web) \n    .shp \n    [data.gov.sg](https://data.gov.sg/dataset/master-plan-2014-subzone-boundary-web) \n  \n  \n    Geospatial - Extracted \n    Childcare Services \n    .shp \n    [OneMap API](https://www.onemap.gov.sg/docs/) \n  \n  \n    Geospatial - Extracted \n    Community Clubs \n    .shp \n    [OneMap API](https://www.onemap.gov.sg/docs/) \n  \n  \n    Geospatial - Extracted \n    Eldercare Services \n    .shp \n    [OneMap API](https://www.onemap.gov.sg/docs/) \n  \n  \n    Geospatial - Extracted \n    Hawker Centres \n    .shp \n    [OneMap API](https://www.onemap.gov.sg/docs/) \n  \n  \n    Geospatial - Extracted \n    Kindergartens \n    .shp \n    [OneMap API](https://www.onemap.gov.sg/docs/) \n  \n  \n    Geospatial - Extracted \n    Parks \n    .shp \n    [OneMap API](https://www.onemap.gov.sg/docs/) \n  \n  \n    Geospatial - Extracted \n    Libraries \n    .shp \n    [OneMap API](https://www.onemap.gov.sg/docs/) \n  \n  \n    Geospatial - Selfsourced \n    Bus Stop Locations Aug 2021 \n    .shp \n    [datamall.lta](https://datamall.lta.gov.sg/content/datamall/en/search_datasets.html?searchText=bus%20stop) \n  \n  \n    Geospatial - Selfsourced \n    MRT & LRT Locations Aug 2021 \n    .kml \n    [data.gov](https://data.gov.sg/dataset/lta-mrt-station-exit) \n  \n  \n    Geospatial - Selfsourced \n    Supermarkets \n    .shp \n    [Onemap.gov](https://www.onemap.gov.sg/main/v2/essentialamenities) \n  \n  \n    Geospatial - Selfsourced \n    Shopping Mall SVY21 Coordinates \n    .shp \n    [Valery Lim's Github](https://github.com/ValaryLim/Mall-Coordinates-Web-Scraper/blob/master/mall_coordinates_updated.csv) \n  \n  \n    Geospatial - Selfsourced \n    Primary School \n    .csv \n    [data.gov](https://data.gov.sg/dataset/school-directory-and-information)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/data/geospatial/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex09/data/geospatial/MPSZ-2019.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#aspatial-data",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "2.1 Aspatial data",
    "text": "2.1 Aspatial data\nLoading Resale Data\n\nLoading DataViewing Data\n\n\n\nresale <- read_csv(\"data/aspatial/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv\")\n\n\n\n\nglimpse(resale)\n\nRows: 148,680\nColumns: 11\n$ month               <chr> \"2017-01\", \"2017-01\", \"2017-01\", \"2017-01\", \"2017-…\n$ town                <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO …\n$ flat_type           <chr> \"2 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", …\n$ block               <chr> \"406\", \"108\", \"602\", \"465\", \"601\", \"150\", \"447\", \"…\n$ street_name         <chr> \"ANG MO KIO AVE 10\", \"ANG MO KIO AVE 4\", \"ANG MO K…\n$ storey_range        <chr> \"10 TO 12\", \"01 TO 03\", \"01 TO 03\", \"04 TO 06\", \"0…\n$ floor_area_sqm      <dbl> 44, 67, 67, 68, 67, 68, 68, 67, 68, 67, 68, 67, 67…\n$ flat_model          <chr> \"Improved\", \"New Generation\", \"New Generation\", \"N…\n$ lease_commence_date <dbl> 1979, 1978, 1980, 1980, 1980, 1981, 1979, 1976, 19…\n$ remaining_lease     <chr> \"61 years 04 months\", \"60 years 07 months\", \"62 ye…\n$ resale_price        <dbl> 232000, 250000, 262000, 265000, 265000, 275000, 28…\n\n\n\n\n\nOn a personal note, I am currently staying in a 3 room flat at Bedok, and my family is planning to move soon. Hence, I have decided to scope it down to 3 room flats so that I can roughly gauge how much my family can resell the house! It will be interesting to look at how various geographical factors affect resale prices :-)\nAs such , we will be looking at 3 room flats, within January of 2021 to February of 2023, which will be separated again later on. This is done by using filter() on flat_type and month.\n\nresale_sub <-  resale %>%\n  filter(flat_type == \"3 ROOM\",\n         month >= \"2021-01\" & month <= \"2023-02\")\n\nTo double confirm that we extracted what we really want, we will be using unique() to view what we extracted. As seen below, we have extracted the correct range for the dates, and the flat_type of 3 Room.\n\nChecking range for monthChecking flat typeViewing resale_sub\n\n\n\nunique(resale_sub$month)\n\n [1] \"2021-01\" \"2021-02\" \"2021-03\" \"2021-04\" \"2021-05\" \"2021-06\" \"2021-07\"\n [8] \"2021-08\" \"2021-09\" \"2021-10\" \"2021-11\" \"2021-12\" \"2022-01\" \"2022-02\"\n[15] \"2022-03\" \"2022-04\" \"2022-05\" \"2022-06\" \"2022-07\" \"2022-08\" \"2022-09\"\n[22] \"2022-10\" \"2022-11\" \"2022-12\" \"2023-01\" \"2023-02\"\n\n\n\n\n\nunique(resale_sub$flat_type)\n\n[1] \"3 ROOM\"\n\n\n\n\n\nglimpse(resale_sub)\n\nRows: 13,780\nColumns: 11\n$ month               <chr> \"2021-01\", \"2021-01\", \"2021-01\", \"2021-01\", \"2021-…\n$ town                <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO …\n$ flat_type           <chr> \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", …\n$ block               <chr> \"331\", \"534\", \"561\", \"170\", \"463\", \"542\", \"170\", \"…\n$ street_name         <chr> \"ANG MO KIO AVE 1\", \"ANG MO KIO AVE 10\", \"ANG MO K…\n$ storey_range        <chr> \"04 TO 06\", \"04 TO 06\", \"01 TO 03\", \"07 TO 09\", \"0…\n$ floor_area_sqm      <dbl> 68, 68, 68, 60, 68, 68, 60, 73, 67, 67, 68, 68, 73…\n$ flat_model          <chr> \"New Generation\", \"New Generation\", \"New Generatio…\n$ lease_commence_date <dbl> 1981, 1980, 1980, 1986, 1980, 1981, 1986, 1976, 19…\n$ remaining_lease     <chr> \"59 years\", \"58 years 02 months\", \"58 years 01 mon…\n$ resale_price        <dbl> 260000, 265000, 265000, 268000, 268000, 270000, 27…\n\n\n\n\n\n\n2.1.2 Aspatial Wrangling\nAs we can see from the resale_sub, the variable remaining lease and lease commence date essentially provides the same information. We will only be including remaining lease, as it directly tells us the remaining year. Most importantly, this will help us to ensure that the variables are not perfectly collinear during our regression later!\n\nresale_sub <- resale_sub %>%\n  select(-lease_commence_date)\n\nAdditionally, after looking at the resale_sub variables, we notice that remaining lease is <chr>. We would want it to be numeric, as it will be beneficial for us later on. We will have to first split the months and years in the variable remaining_lease.\n\nCode ChunkGlimpse\n\n\n\nresale_sub <- resale_sub %>%\nmutate(remaining_lease_yr = as.integer(str_sub(remaining_lease, 0, 2))) %>%\n  mutate(remaining_lease_mth = as.integer(str_sub(remaining_lease, 9, 11)))\n\n\n\n\nglimpse(resale_sub)\n\nRows: 13,780\nColumns: 12\n$ month               <chr> \"2021-01\", \"2021-01\", \"2021-01\", \"2021-01\", \"2021-…\n$ town                <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO …\n$ flat_type           <chr> \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", …\n$ block               <chr> \"331\", \"534\", \"561\", \"170\", \"463\", \"542\", \"170\", \"…\n$ street_name         <chr> \"ANG MO KIO AVE 1\", \"ANG MO KIO AVE 10\", \"ANG MO K…\n$ storey_range        <chr> \"04 TO 06\", \"04 TO 06\", \"01 TO 03\", \"07 TO 09\", \"0…\n$ floor_area_sqm      <dbl> 68, 68, 68, 60, 68, 68, 60, 73, 67, 67, 68, 68, 73…\n$ flat_model          <chr> \"New Generation\", \"New Generation\", \"New Generatio…\n$ remaining_lease     <chr> \"59 years\", \"58 years 02 months\", \"58 years 01 mon…\n$ resale_price        <dbl> 260000, 265000, 265000, 268000, 268000, 270000, 27…\n$ remaining_lease_yr  <int> 59, 58, 58, 64, 58, 59, 64, 54, 56, 55, 59, 58, 55…\n$ remaining_lease_mth <int> NA, 2, 1, 2, 2, 1, NA, 4, 10, 4, 1, 8, 7, 9, 4, 5,…\n\n\n\n\n\nFrom above, we notice that there are NA values for remaining lease month. We will replace it with 0 by identifying it with is.na()\n\nresale_sub$remaining_lease_mth[is.na(resale_sub$remaining_lease_mth)] <- 0\n\nOur main goal here is to convert remaining lease months into years, and add them together under remaining_lease_year. we will first divide the remaining lease month variable by 12.\n\nresale_sub$remaining_lease_mth <- resale_sub$remaining_lease_mth/12\n\nThen, we will combine them together under the new variable remaining lease year.\n\nresale_sub <- resale_sub %>%\nmutate(resale_sub, remaining_lease_year = rowSums(resale_sub[, c(\"remaining_lease_yr\", \"remaining_lease_mth\")]))\n\nBy referencing to our favorite senior, Megan, she advised that we replace “SAINT” with “ST”, as onemap spells it that way in the variable street_name, which will be a bit confusing. We can change that by using the code chunk below\n\nresale_sub$street_name <- gsub(\"ST\\\\.\", \"SAINT\", resale_sub$street_name)\n\nSimilarly, by referencing Megan’s work, we notice that there are no coordinates provided in the resale data. we will have to use a geocoding function as shown below.\nThe steps are as follows:\n\nCombine the block and street name into an address\nPass the address as the searchVal in our query\nSend the query to OneMapSG search Note: Since we don’t need all the address details, we can set getAddrDetails as ‘N’\nConvert response (JSON object) to text\nSaving the response in text form as a data frame\nretaining the latitude and longitude for our output\n\n\nlibrary(httr)\nlibrary(rjson)\ngeocode <- function(block, streetname) {\n  base_url <- \"https://developers.onemap.sg/commonapi/search\"\n  address <- paste(block, streetname, sep = \" \")\n  query <- list(\"searchVal\" = address, \n                \"returnGeom\" = \"Y\",\n                \"getAddrDetails\" = \"N\",\n                \"pageNum\" = \"1\")\n  \n  res <- GET(base_url, query = query)\n  restext<-content(res, as=\"text\")\n  \n  output <- fromJSON(restext)  %>% \n    as.data.frame %>%\n    select(results.LATITUDE, results.LONGITUDE)\n\n  return(output)\n}\n\nAfter creating the function, we will have to make sure that the iterations are able to run through the whole resale data to ensure that every entry gets a coordinate. As such, we will be creating a loop\n\nresale_sub$LATITUDE <- 0\nresale_sub$LONGITUDE <- 0\n\nfor (i in 1:nrow(resale_sub)){\n  temp_output <- geocode(resale_sub[i, 4], resale_sub[i, 5])\n  \n  resale_sub$LATITUDE[i] <- temp_output$results.LATITUDE\n  resale_sub$LONGITUDE[i] <- temp_output$results.LONGITUDE\n}\n\nLet us save it into a RDS object\n\nsaveRDS(resale_sub, file=\"resale_sub\", compress=FALSE)\n\nWe will then assign the RDS object to resale_sub\n\nresale_sub <- readRDS(\"resale_sub\")\n\n\n\n2.1.3 Creating ordinal arrangement for floor level\nWe will create an ordinal column for the floor level for the purpose of our analysis later on! We will first use unique() to identify all of the values from storey_range\n\nunique(resale_sub$storey_range)\n\n [1] \"04 TO 06\" \"01 TO 03\" \"07 TO 09\" \"10 TO 12\" \"13 TO 15\" \"28 TO 30\"\n [7] \"19 TO 21\" \"16 TO 18\" \"25 TO 27\" \"22 TO 24\" \"34 TO 36\" \"40 TO 42\"\n[13] \"31 TO 33\" \"37 TO 39\" \"46 TO 48\" \"43 TO 45\"\n\n\nWe will then write it down into a vector, and assign it to levels. After that, we will assign story_ordinal by using seq_along() and changing story_ordinal into numeric using as.numeric().\n\nlevels <- c(\"01 TO 03\", \"04 TO 06\", \"07 TO 09\", \"10 TO 12\", \"13 TO 15\", \"16 TO 18\", \"19 TO 21\", \"22 TO 24\", \"25 TO 27\", \"28 TO 30\", \"31 TO 33\", \"34 TO 36\", \"37 TO 39\", \"40 TO 42\", \"43 TO 45\", \"46 TO 48\", \"49 TO 51\") \n\nstory_ordinal <- seq_along(levels)\n\nresale_sub$Story_Ordinal <- story_ordinal[match(resale_sub$storey_range, levels)]  \n\nlevels(resale_sub$Story_Ordinal) <- levels\n\nresale_sub <- resale_sub |> \n  mutate(Story_Ordinal=as.numeric(Story_Ordinal))\n\n\n\n2.1.4 Mutating remaining columns\nWe noticed that month is still <chr>, which is able to be changed by as.Date. By referencing to this website, %Y denotes the year with century, %m for month, and %d for day.\n\nresale_sub <- resale_sub %>% \n  mutate(month = as.Date(paste(month, \"-01\"), format =\"%Y-%m-%d\"))\n\n\n\n2.1.5 Checking for duplicates\nFinally, let us check for duplicates. We are good to go!\n\nsum(is.na(resale_sub$LATITUDE))\n\n[1] 0\n\nsum(is.na(resale_sub$LONGITUDE))\n\n[1] 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html",
    "title": "Hands on exercise 10 - Modelling Geographical Accessibility",
    "section": "",
    "text": "Context\nThis hands-on exercise, we will be exploring on how to model geographical accessibility by using R’s geospatial analysis packages.\n\n\nPackages used\nThe R packages need for this exercise are as follows:\n\nSpatial data handling\n\nsf\n\nModelling geographical accessibility\n\nspatialAcc\n\nAttribute data handling\n\ntidyverse, especially readr and dplyr\n\nthematic mapping\n\ntmap\n\nStatistical graphic\n\nggplot2\n\nStatistical analysis\n\nggstatsplot\n\n\n\n\nLoading packages\n\npacman::p_load(tmap, SpatialAcc, sf, ggstatsplot, reshape2, tidyverse)\n\n\n\nLoading data\n##Geospatial datas\n\nmpsz <- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_NO_SEA_PL\")\n\nReading layer `MP14_SUBZONE_NO_SEA_PL' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Hands-on_Ex/Hands-on_Ex10/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nhexagons <- st_read(dsn = \"data/geospatial\", layer = \"hexagons\") \n\nReading layer `hexagons' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Hands-on_Ex/Hands-on_Ex10/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3125 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21506.33 xmax: 50010.26 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n\n\n\neldercare <- st_read(dsn = \"data/geospatial\", layer = \"ELDERCARE\") \n\nReading layer `ELDERCARE' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Hands-on_Ex/Hands-on_Ex10/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 120 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM\n\n\nUpdating CRS for geospatial data\n\nmpsz <- st_transform(mpsz, 3414)\neldercare <- st_transform(eldercare, 3414)\nhexagons <- st_transform(hexagons, 3414)\n\nVerify the CRS\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nFor the purpose of this practice, we will be setting capacity and demand to 100 as we do not know the actual number. The code chunks below will be used to exclude those redundant fields.\n\neldercare <- eldercare %>%\n  select(fid, ADDRESSPOS) %>%\n  mutate(capacity = 100)\n\n\nhexagons <- hexagons %>%\n  select(fid) %>%\n  mutate(demand = 100)\n\n##Aspatial data\n\nODMatrix <- read_csv(\"data/aspatial/OD_Matrix.csv\", skip = 0)\n\n\nview(ODMatrix)\n\nChanging matrix using pivot_wider\n\ndistmat <- ODMatrix %>%\n  select(origin_id, destination_id, total_cost) %>%\n  pivot_wider(names_from = destination_id, values_from = total_cost) %>%\n  select(c(-c('origin_id')))\n\nChanging measurement to km from m\n\ndistmat_km <- as.matrix(distmat/1000)\n\n\n\nModelling and Visualising Accessibility using Hansen Method\n\nacc_Hansen <- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 2, \n                            family = \"Hansen\"))\n\nAllocate accHansen to acc_Hansen, as there is only one column, it should not be an issue using this short cut\n\ncolnames(acc_Hansen) <- \"accHansen\"\n\nConverting to tibble format\n\nacc_Hansen <- as_tibble(acc_Hansen)\n\n\nacc_Hansen <- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 0.5, \n                            family = \"Hansen\"))\n\ncolnames(acc_Hansen) <- \"accHansen\"\nacc_Hansen <- as_tibble(acc_Hansen)\nhexagon_Hansen <- bind_cols(hexagons, acc_Hansen)\n\n#Visualising Hansen’s accessibility\nExtracting sf\n\nmapex <- st_bbox(hexagons)\n\nlet us visualise the hansen using tmap\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_Hansen,\n         bbox = mapex) + \n  tm_fill(col = \"accHansen\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: Hansen method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\n\n\nStatistical visualisation\n\nhexagon_Hansen <- st_join(hexagon_Hansen, mpsz, \n                          join = st_intersects)\n\nlet us plot boxplot\n\nggplot(data=hexagon_Hansen, \n       aes(y = log(accHansen), \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)\n\n\n\n\n\n\nModelling and Visualising Accessibility using KD2SFCA Method\n\nacc_KD2SFCA <- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            d0 = 50,\n                            power = 2, \n                            family = \"KD2SFCA\"))\n\ncolnames(acc_KD2SFCA) <- \"accKD2SFCA\"\nacc_KD2SFCA <- as_tibble(acc_KD2SFCA)\nhexagon_KD2SFCA <- bind_cols(hexagons, acc_KD2SFCA)\n\nvisualising KD2SFCA\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_KD2SFCA,\n         bbox = mapex) + \n  tm_fill(col = \"accKD2SFCA\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: KD2SFCA method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\nLet us compare the distribution of KD2CFA accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into hexagon_KD2SFCA simple feature data frame by using the code chunk below.\n\nhexagon_KD2SFCA <- st_join(hexagon_KD2SFCA, mpsz, \n                          join = st_intersects)\n\nSimilarly, let us plota boxplot\n\nggplot(data=hexagon_KD2SFCA, \n       aes(y = accKD2SFCA, \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)\n\n\n\n\n\n\nModelling and Visualising Accessibility using Spatial Accessibility Measure (SAM) Method\n\nacc_SAM <- data.frame(ac(hexagons$demand,\n                         eldercare$capacity,\n                         distmat_km, \n                         d0 = 50,\n                         power = 2, \n                         family = \"SAM\"))\n\ncolnames(acc_SAM) <- \"accSAM\"\nacc_SAM <- as_tibble(acc_SAM)\nhexagon_SAM <- bind_cols(hexagons, acc_SAM)\n\nVisualising SAM\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_SAM,\n         bbox = mapex) + \n  tm_fill(col = \"accSAM\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: SAM method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 3),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\nStatistical visualisation\n\nhexagon_SAM <- st_join(hexagon_SAM, mpsz, \n                       join = st_intersects)\n\nPlotting the distribution by using boxplot graphical method\n\nggplot(data=hexagon_SAM, \n       aes(y = accSAM, \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/data/geospatial/ELDERCARE.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/data/geospatial/ELDERCARE.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>  ELDERCARE  ENG dataset\n\nELDERCARE\n\n                 0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/data/geospatial/hexagons.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/data/geospatial/hexagons.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n                 0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html",
    "title": "In-class Exercise 10: Modelling Geographical Accessibility",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on how to model geographical accessibility by using R’s geospatial analysis packages.\n\n\n\n\nFour data sets will be used in this hands-on exercise, they are:\n\nMP14_SUBZONE_NO_SEA_PL: URA Master Plan 2014 subzone boundary GIS data. This data set is downloaded from data.gov.sg.\nhexagons: A 250m radius hexagons GIS data. This data set was created by using st_make_grid() of sf package. It is in ESRI shapefile format.\nELDERCARE: GIS data showing location of eldercare service. This data is downloaded from data.gov.sg. There are two versions. One in ESRI shapefile format. The other one in Google kml file format. For the purpose of this hands-on exercise, ESRI shapefile format is provided.\nOD_Matrix: a distance matrix in csv format. There are six fields in the data file. They are:\n\norigin_id: the unique id values of the origin (i.e. fid of hexagon data set.),\ndestination_id: the unique id values of the destination (i.e. fid of ELDERCARE data set.),\nentry_cost: the perpendicular distance between the origins and the nearest road),\nnetwork_cost: the actual network distance from the origin and destination,\nexit_cost: the perpendicular distance between the destination and the nearest road), and\ntotal_cost: the summation of entry_cost, network_cost and exit_cost.\n\n\nAll the values of the cost related fields are in metres.\n\nNote: Except MP14_SUBZONE_NO_SEA_PL data set, the other three data set are specially prepared by Prof. Kam for teaching and research purpose. Please obtain formal approval from Prof. Kam if you want to use them for other courses or usage.\n\n\n\nThe R packages need for this exercise are as follows:\n\nSpatial data handling\n\nsf\n\nModelling geographical accessibility\n\nspatialAcc\n\nAttribute data handling\n\ntidyverse, especially readr and dplyr\n\nthematic mapping\n\ntmap\n\nStaistical graphic\n\nggplot2\n\nStatistical analysis\n\nggstatsplot\n\n\n\npacman::p_load(tmap, SpatialAcc, sf, \n               ggstatsplot, reshape2,\n               tidyverse)\n\n\n\n\n\n\nThree geospatial data will be imported from the data/geospatial sub-folder. They are MP14_SUBZONE_NO_SEA_PL, hexagons and ELDERCARE.\nThe code chunk below is used to import these three data sets shapefile by using st_read() of sf packages.\n\nmpsz <- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_NO_SEA_PL\")\n\nReading layer `MP14_SUBZONE_NO_SEA_PL' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/In-class_Ex/In-class_Ex10/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nhexagons <- st_read(dsn = \"data/geospatial\", layer = \"hexagons\") \n\nReading layer `hexagons' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/In-class_Ex/In-class_Ex10/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3125 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21506.33 xmax: 50010.26 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n\neldercare <- st_read(dsn = \"data/geospatial\", layer = \"ELDERCARE\") \n\nReading layer `ELDERCARE' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/In-class_Ex/In-class_Ex10/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 120 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM\n\n\nThe report above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is multipolygon. it is also important to note that mpsz simple feature object does not have EPSG information.\n\n\n\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\n\nmpsz <- st_transform(mpsz, 3414)\neldercare <- st_transform(eldercare, 3414)\nhexagons <- st_transform(hexagons, 3414)\n\nAfter transforming the projection metadata, you can verify the projection of the newly transformed mpsz_svy21 by using st_crs() of sf package.\nThe code chunk below will be used to varify the newly transformed mpsz_svy21.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nThere are many redundant fields in the data tables of both eldercare and hexagons. The code chunks below will be used to exclude those redundant fields. At the same time, a new field called demand and a new field called capacity will be added into the data table of hexagons and eldercare sf data frame respectively. Both fields are derive using mutate() of dplyr package.\n\neldercare <- eldercare |> \n  select(fid, ADDRESSPOS) |> \n  rename(destination_id = fid, postal_code = ADDRESSPOS) |> \n  mutate(capacity = 100)\n\n\nhexagons <- hexagons |> \n  select(fid) |> \n  rename(origin_id = fid) |> \n  mutate(demand = 100)\n\nNotice that for the purpose of this hands-on exercise, a constant value of 100 is used. In practice, actual demand of the hexagon and capacity of the eldercare centre should be used.\n\n\n\n\n\n\nThe code chunk below uses read_cvs() of readr package to import OD_Matrix.csv into RStudio. The imported object is a tibble data.frame called ODMatrix.\n\nODMatrix <- read_csv(\"data/aspatial/OD_Matrix.csv\", skip = 0)\n\n\n\n\n\ndistmat <- ODMatrix %>%\n  select(origin_id, destination_id, total_cost) %>%\n  spread(destination_id, total_cost)%>%\n  select(c(-c('origin_id')))\n\nNote that we can use “pivot_wider()” instead of “spread()”, in the code chunk below\n\ndistmat <- ODMatrix %>%\n  select(origin_id, destination_id, total_cost) %>%\n  pivot_wider(names_from=destination_id, values_from=total_cost) |> \n  select(c(-c('origin_id')))\n\nCurrently, the distance is measured in metre because SVY21 projected coordinate system is used. The code chunk below will be used to convert the unit f measurement from metre to kilometre.\n\ndistmat_km <- as.matrix(distmat/1000)\n\n\n\n\n\n\neldercare_coord<- st_coordinates(eldercare)\nhexagon_coord<- st_coordinates(hexagons)\n\n\nEucMatrix<-SpatialAcc::distance(hexagon_coord,\n                                eldercare_coord,\n                                type=\"euclidean\")\n\n\n\n\n\n\nNow, we ready to compute Hansen’s accessibility by using ac() of SpatialAcc package. Before getting started, you are encourage to read the arguments of the function at least once in order to ensure that the required inputs are available.\nThe code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_Handsen.\n\nacc_Hansen <- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            d0 = 50,\n                            power = 2, \n                            family = \"Hansen\"))\n\n\ncolnames(acc_Hansen) <- \"accHansen\"\n\nNext, we will convert the data table into tibble format by using the code chunk below.\n\nacc_Hansen <- tbl_df(acc_Hansen)\n\nLastly, bind_cols() of dplyr will be used to join the acc_Hansen tibble data frame with the hexagons simple feature data frame. The output is called hexagon_Hansen.\n\nhexagon_Hansen <- bind_cols(hexagons, acc_Hansen)\n\nNotice that hexagon_Hansen is a simple feature data frame and not a typical tibble data frame.\nActually, the steps above can be perform by using a single code chunk as shown below.\n\nacc_Hansen <- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 0.5, \n                            family = \"Hansen\"))\n\ncolnames(acc_Hansen) <- \"accHansen\"\nacc_Hansen <- tbl_df(acc_Hansen)\nhexagon_Hansen <- bind_cols(hexagons, acc_Hansen)\n\n\n\n\n\n\n\nFirstly, we will extract the extend of hexagons simple feature data frame by by using st_bbox() of sf package.\n\nmapex <- st_bbox(hexagons)\n\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_Hansen,\n         bbox = mapex) + \n  tm_fill(col = \"accHansen\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: Hansen method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\n\n\n\nIn this section, we are going to compare the distribution of Hansen’s accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into haxegon_Hansen simple feature data frame by using the code chunk below.\n\nhexagon_Hansen <- st_join(hexagon_Hansen, mpsz, \n                          join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_Hansen, \n       aes(y = log(accHansen), \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)\n\n\n\n\n\n\n\n\n\n\nIn this section, you are going to repeat most of the steps you had learned in previous section to perform the analysis. However, some of the codes will be combined into one code chunk.\nThe code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_KD2SFCA. Notice that KD2SFCA is used for family argument.\n\nacc_KD2SFCA <- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            d0 = 50,\n                            power = 2, \n                            family = \"KD2SFCA\"))\n\ncolnames(acc_KD2SFCA) <- \"accKD2SFCA\"\nacc_KD2SFCA <- tbl_df(acc_KD2SFCA)\nhexagon_KD2SFCA <- bind_cols(hexagons, acc_KD2SFCA)\n\n\n\n\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore. Notice that mapex is reused for bbox argument.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_KD2SFCA,\n         bbox = mapex) + \n  tm_fill(col = \"accKD2SFCA\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: KD2SFCA method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\n\n\n\nNow, we are going to compare the distribution of KD2CFA accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into hexagon_KD2SFCA simple feature data frame by using the code chunk below.\n\nhexagon_KD2SFCA <- st_join(hexagon_KD2SFCA, mpsz, \n                          join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_KD2SFCA, \n       aes(y = accKD2SFCA, \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)\n\n\n\n\n\n\n\n\n\n\nIn this section, you are going to repeat most of the steps you had learned in previous section to perform the analysis. However, some of the codes will be combined into one code chunk.\nThe code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_SAM. Notice that SAM is used for family argument.\n\nacc_SAM <- data.frame(ac(hexagons$demand,\n                         eldercare$capacity,\n                         distmat_km, \n                         d0 = 50,\n                         power = 2, \n                         family = \"SAM\"))\n\ncolnames(acc_SAM) <- \"accSAM\"\nacc_SAM <- tbl_df(acc_SAM)\nhexagon_SAM <- bind_cols(hexagons, acc_SAM)\n\n\n\n\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore. Notice that mapex is reused for bbox argument.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_SAM,\n         bbox = mapex) + \n  tm_fill(col = \"accSAM\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: SAM method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 3),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\n\n\n\nNow, we are going to compare the distribution of SAM accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into hexagon_SAM simple feature data frame by using the code chunk below.\n\nhexagon_SAM <- st_join(hexagon_SAM, mpsz, \n                       join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_SAM, \n       aes(y = accSAM, \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/data/geospatial/ELDERCARE.html",
    "href": "In-class_Ex/In-class_Ex10/data/geospatial/ELDERCARE.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>  ELDERCARE  ENG dataset\n\nELDERCARE\n\n                 0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/data/geospatial/hexagons.html",
    "href": "In-class_Ex/In-class_Ex10/data/geospatial/hexagons.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n                 0 0     false"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#geospatial-data",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Geospatial data",
    "text": "Geospatial data\nAs mentioned above, we will be extracting geospatial data from Onemap. the codes used below will require the onemapsgapi package, which is already loaded in 1.1. I will break down the steps to extract data from Onemap as simple as possible!\n\nFirst, create an account for Onemap\nFill up your details in this link (with the details sent to your email)\nReady to go after following the code chunks below!\n\nDo note that this is purely for reference, you will have to type in your own email and password to load your token!\nType this command into the console, with your own email and password\n\nrun_token <- get_token(\"email\", \"password\")\n\nNext, since I love food, I will be giving an example to extract hawker data from Onemap, using this code chunk.\n\nthemes <- search_themes(run_token, \"hawkercentre\")\n\nWe will use the following function to extract data from Onemap. Lets assign it into hawker.\n\nhawkercentre <- get_theme(run_token, \"hawkercentre\")\n\nAnd of course, our favorite part, ensuring that our spatial data have the correct ESPG CRS, which is 3414. We will also need to transform it into sf using st_as_sf(). Since we will be dealing with various extracted data, we do not want to keep extracting it each time we run or render the page. Hence, we will be using st_write() to write the sf object to file or database!\n\nhawkercentre_sf <- st_as_sf(hawkercentre, coords = c(\"Lng\", \"Lat\"), crs = 4326) %>%\nst_transform(crs = 3414)\n\nst_write(obj = hawkercentre_sf,\n         dsn = \"data/geospatial/extracted\",\n         layer = \"hawkercentre\",\n         driver = \"ESRI Shapefile\")\n\nWe can just repeat the steps above for the following variables. For the scope of this assignment, we will be extracting the following:\n\nchildcare\ncommunity clubs\nelder care\nkindergartens\nlibraries\nparks\n\nI have already extracted the data beforehand, so let us proceed!\n(Note that we have already extracted hawker centers!)\nFor reference, i will be putting the code below to extract the data from onemap\n\nChildcareCommunity clubsElder careKindergartensLibrariesParks\n\n\n\nchildcare <- get_theme(token,\"childcare\")\nchildcare_sf <- st_as_sf(childcare, coords = c(\"Lng\", \"Lat\"), crs = 4326) %>%\nst_transform(crs = 3414)\n\nst_write(obj = childcare_sf,\n         dsn = \"data/geospatial/extracted\",\n         layer = \"childcare\",\n         driver = \"ESRI Shapefile\")\n\n\n\n\ncommunityclubs<- get_theme(token,\"communityclubs\")\ncommunityclubs_sf <- st_as_sf(childcare, coords = c(\"Lng\", \"Lat\"), crs = 4326) %>%\nst_transform(crs = 3414)\n\nst_write(obj = communityclubs_sf,\n         dsn = \"data/geospatial/extracted\",\n         layer = \"communityclubs\",\n         driver = \"ESRI Shapefile\")\n\n\n\n\neldercare <- get_theme(token,\"eldercare\")\neldercare_sf <- st_as_sf(eldercare, coords=c(\"Lng\", \"Lat\"), crs = 4326) %>%\nst_transform(crs = 3414)\n\nst_write(obj = eldercare_sf,\n         dsn = \"data/geospatial/extracted\",\n         layer = \"eldercare\",\n         driver = \"ESRI Shapefile\")\n\n\n\n\nkindergartens <- get_theme(token,\"kindergartens\")\nkindergartens_sf <- st_as_sf(kindergartens, coords=c(\"Lng\", \"Lat\"), crs= 4326) %>%\nst_transform(crs = 3414)\n\nst_write(obj = kindergartens_sf,\n         dsn = \"data/geospatial/extracted\",\n         layer = \"kindergartens\",\n         driver = \"ESRI Shapefile\")\n\n\n\n\nlibrary <- get_theme(token,\"libraries\")\nlibrary_sf <- st_as_sf(library, coords=c(\"Lng\", \"Lat\"), crs = 4326) %>%\nst_transform(crs = 3414)\n\nst_write(obj = library_sf,\n         dsn = \"data/geospatial/extracted\",\n         layer = \"libraries\",\n         driver = \"ESRI Shapefile\")\n\n\n\n\nparks <- get_theme(token,\"nationalparks\")\nparks_sf <- st_as_sf(parks, coords=c(\"Lng\", \"Lat\"), crs = 4326) %>%\nst_transform(crs = 3414)\n\nst_write(obj = parks_sf,\n         dsn = \"data/geospatial/extracted\",\n         layer = \"parks\",\n         driver = \"ESRI Shapefile\")\n\n\n\n\n\n2.2.1 Reading Geospatial Data\n\nOnemap (Extracted)BasemapSelf-Sourced\n\n\n\nhawkercentre_sf <- st_read(dsn = \"data/geospatial/extracted\", layer = \"hawkercentre\")\n\nReading layer `hawkercentre' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/extracted' \n  using driver `ESRI Shapefile'\nSimple feature collection with 125 features and 18 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 12874.19 ymin: 28355.97 xmax: 45241.4 ymax: 47850.43\nProjected CRS: SVY21 / Singapore TM\n\n\n\neldercare_sf <- st_read(dsn = \"data/geospatial/extracted\", layer = \"eldercare\")\n\nReading layer `eldercare' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/extracted' \n  using driver `ESRI Shapefile'\nSimple feature collection with 133 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcare_sf <- st_read(dsn = \"data/geospatial/extracted\", layer = \"childcare\")\n\nReading layer `childcare' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/extracted' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1925 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nProjected CRS: SVY21 / Singapore TM\n\n\n\ncommunityclubs_sf <- st_read(dsn = \"data/geospatial/extracted\", layer = \"communityclubs\")\n\nReading layer `communityclubs' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/extracted' \n  using driver `ESRI Shapefile'\nSimple feature collection with 125 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 12308.4 ymin: 28593.37 xmax: 42008.87 ymax: 48958.52\nProjected CRS: SVY21 / Singapore TM\n\n\n\nkindergartens_sf <- st_read(dsn = \"data/geospatial/extracted\", layer = \"kindergartens\")\n\nReading layer `kindergartens' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/extracted' \n  using driver `ESRI Shapefile'\nSimple feature collection with 448 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 11909.7 ymin: 25596.33 xmax: 43395.47 ymax: 48562.06\nProjected CRS: SVY21 / Singapore TM\n\n\n\nlibrary_sf <- st_read(dsn = \"data/geospatial/extracted\", layer = \"libraries\")\n\nReading layer `libraries' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/extracted' \n  using driver `ESRI Shapefile'\nSimple feature collection with 31 features and 13 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 13665.24 ymin: 27383.57 xmax: 40922.89 ymax: 47759.75\nProjected CRS: SVY21 / Singapore TM\n\n\n\nparks_sf <- st_read(dsn = \"data/geospatial/extracted\", layer = \"nationalparks\")\n\nReading layer `nationalparks' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/extracted' \n  using driver `ESRI Shapefile'\nSimple feature collection with 421 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 12374.75 ymin: 21917.81 xmax: 52533.09 ymax: 49296.46\nProjected CRS: SVY21 / Singapore TM\n\n\n\n\n\nmpsz_sf <- st_read(dsn = \"data/geospatial/map\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/map' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\nbusstop_sf <- st_read(dsn = \"data/geospatial/sourced\", layer = \"BusStop\")\n\nReading layer `BusStop' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/sourced' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5159 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\ngoodprisch_sf <- st_read(dsn = \"data/geospatial/sourced\", layer = \"goodprimarysch\")\n\nReading layer `goodprimarysch' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/sourced' \n  using driver `ESRI Shapefile'\nSimple feature collection with 9 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 103.7611 ymin: 1.305285 xmax: 103.937 ymax: 1.34968\nGeodetic CRS:  WGS 84\n\n\n\nmrt_sf <- st_read(dsn = \"data/geospatial/sourced\", layer = \"mrt\")\n\nReading layer `mrt' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/sourced' \n  using driver `ESRI Shapefile'\nSimple feature collection with 474 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 103.6368 ymin: 1.264972 xmax: 103.9893 ymax: 1.449157\nGeodetic CRS:  WGS 84\n\n\n\nprisch_sf <- st_read(dsn = \"data/geospatial/sourced\", layer = \"primarysch\")\n\nReading layer `primarysch' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/sourced' \n  using driver `ESRI Shapefile'\nSimple feature collection with 183 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 103.6878 ymin: 1.274958 xmax: 103.9628 ymax: 1.456608\nGeodetic CRS:  WGS 84\n\n\n\nshoppingmall_sf <- st_read(dsn = \"data/geospatial/sourced\", layer = \"shoppingmall\")\n\nReading layer `shoppingmall' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/sourced' \n  using driver `ESRI Shapefile'\nSimple feature collection with 184 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 103.6784 ymin: 1.263797 xmax: 103.9897 ymax: 1.448227\nGeodetic CRS:  WGS 84\n\n\n\nsupermarket_sf <- st_read(dsn = \"data/geospatial/sourced\", layer = \"SUPERMARKETS\")\n\nReading layer `SUPERMARKETS' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/sourced' \n  using driver `ESRI Shapefile'\nSimple feature collection with 526 features and 8 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 4901.188 ymin: 25529.08 xmax: 46948.22 ymax: 49233.6\nProjected CRS: SVY21\n\n\n\n\n\n\n\n2.2.2 Converting Self-sourced data\nAs we all know, we have yet to change our out-sourced data to the correct crs, which is 3414. Let us change it below using st_transform()! Do note that we do not need to do this all the time, especially when the data is already in the correct CRS. But in this case, all of the data are not.\n\nbusstop_sf <- busstop_sf %>%\n  st_transform(3414)\n\n\ngoodprisch_sf <- goodprisch_sf %>%\n  st_transform(3414)\n\n\nmrt_sf <- mrt_sf %>%\n  st_transform(3414)\n\n\nprisch_sf <- prisch_sf %>%\n  st_transform(3414)\n\n\nshoppingmall_sf <- shoppingmall_sf %>%\n  st_transform(3414)\n\n\nsupermarket_sf <- supermarket_sf %>%\n  st_transform(3414)\n\n\n\n2.2.3 Checking for invalid geometries\nWe will be checking invalid geometries using the length(), which() and st_is_valid() functions.\n\nOnemap (Extracted)BasemapSelf-Sourced\n\n\n\nlength(which(st_is_valid(hawkercentre_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(communityclubs_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(eldercare_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(childcare_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(kindergartens_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(library_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(parks_sf) == FALSE))\n\n[1] 0\n\n\n\n\n\nlength(which(st_is_valid(mpsz_sf) == FALSE))\n\n[1] 9\n\n\n\n\n\nlength(which(st_is_valid(busstop_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(goodprisch_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(mrt_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(prisch_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(shoppingmall_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(supermarket_sf) == FALSE))\n\n[1] 0\n\n\n\n\n\nAlright, that aside, we notice that the basemap have a few invalid geometries. This can be corrected using st_make_valid()\n\nmpsz_sf <- st_make_valid(mpsz_sf)\n\n\n\n2.3.4 Selecting name column\nAs we only need the name and geometry column, we will use the select() function.\n\nOnemap (Extracted)Self-sourced\n\n\n\nhawkercentre_sf <- hawkercentre_sf %>%\n  select(1)\n\n\ncommunityclubs_sf <- communityclubs_sf %>%\n  select(1)\n\n\neldercare_sf <- eldercare_sf %>%\n  select(1)\n\n\nchildcare_sf <- childcare_sf %>%\n  select(1)\n\n\nkindergartens_sf <- kindergartens_sf %>%\n  select(1)\n\n\nlibrary_sf <- library_sf %>%\n  select(1)\n\n\nparks_sf <- parks_sf %>%\n  select(1)\n\n\n\n\nbusstop_sf <- busstop_sf %>%\n  select(1)\n\n\ngoodprisch_sf <- goodprisch_sf %>%\n  select(1)\n\n\nmrt_sf <- mrt_sf %>%\n  select(1)\n\n\nprisch_sf <- prisch_sf %>%\n  select(1)\n\n\nshoppingmall_sf <- shoppingmall_sf %>%\n  select(1)\n\n\nsupermarket_sf <- supermarket_sf %>%\n  select(1)\n\n\n\n\n\n\n2.3.5 Checking for missing values\nWhat is more scary than missing geometries? Missing values, of course! That is a huge no no. Let us check missing values with is.na().\n\nOnemap (Extracted)BasemapSelf-Sourced\n\n\n\nhawkercentre_sf[rowSums(is.na(hawkercentre_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)\n\n\n\ncommunityclubs_sf[rowSums(is.na(communityclubs_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)\n\n\n\neldercare_sf[rowSums(is.na(eldercare_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)\n\n\n\nchildcare_sf[rowSums(is.na(childcare_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)\n\n\n\nkindergartens_sf[rowSums(is.na(kindergartens_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)\n\n\n\nlibrary_sf[rowSums(is.na(library_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)\n\n\n\nparks_sf[rowSums(is.na(parks_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)\n\n\n\n\n\nmpsz_sf[rowSums(is.na(mpsz_sf))!=0,]\n\nSimple feature collection with 0 features and 15 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21\n [1] OBJECTID   SUBZONE_NO SUBZONE_N  SUBZONE_C  CA_IND     PLN_AREA_N\n [7] PLN_AREA_C REGION_N   REGION_C   INC_CRC    FMEL_UPD_D X_ADDR    \n[13] Y_ADDR     SHAPE_Leng SHAPE_Area geometry  \n<0 rows> (or 0-length row.names)\n\n\n\n\n\nbusstop_sf[rowSums(is.na(busstop_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] BUS_STOP_N geometry  \n<0 rows> (or 0-length row.names)\n\n\n\ngoodprisch_sf[rowSums(is.na(goodprisch_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] schl_nm  geometry\n<0 rows> (or 0-length row.names)\n\n\n\nmrt_sf[rowSums(is.na(mrt_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] Name     geometry\n<0 rows> (or 0-length row.names)\n\n\n\nprisch_sf[rowSums(is.na(prisch_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] schl_nm  geometry\n<0 rows> (or 0-length row.names)\n\n\n\nshoppingmall_sf[rowSums(is.na(shoppingmall_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] name     geometry\n<0 rows> (or 0-length row.names)\n\n\n\nsupermarket_sf[rowSums(is.na(supermarket_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] LIC_NAME geometry\n<0 rows> (or 0-length row.names)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#reading-geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#reading-geospatial-data",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "2.2.1 Reading Geospatial Data",
    "text": "2.2.1 Reading Geospatial Data\n\nOnemap (Extracted)BasemapSelf-Sourced\n\n\n\nhawkercentre_sf <- st_read(dsn = \"data/geospatial/extracted\", layer = \"hawkercentre\")\n\nReading layer `hawkercentre' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/extracted' \n  using driver `ESRI Shapefile'\nSimple feature collection with 125 features and 18 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 12874.19 ymin: 28355.97 xmax: 45241.4 ymax: 47850.43\nProjected CRS: SVY21 / Singapore TM\n\n\n\neldercare_sf <- st_read(dsn = \"data/geospatial/extracted\", layer = \"eldercare\")\n\nReading layer `eldercare' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/extracted' \n  using driver `ESRI Shapefile'\nSimple feature collection with 133 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcare_sf <- st_read(dsn = \"data/geospatial/extracted\", layer = \"childcare\")\n\nReading layer `childcare' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/extracted' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1925 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nProjected CRS: SVY21 / Singapore TM\n\n\n\ncommunityclubs_sf <- st_read(dsn = \"data/geospatial/extracted\", layer = \"communityclubs\")\n\nReading layer `communityclubs' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/extracted' \n  using driver `ESRI Shapefile'\nSimple feature collection with 125 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 12308.4 ymin: 28593.37 xmax: 42008.87 ymax: 48958.52\nProjected CRS: SVY21 / Singapore TM\n\n\n\nkindergartens_sf <- st_read(dsn = \"data/geospatial/extracted\", layer = \"kindergartens\")\n\nReading layer `kindergartens' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/extracted' \n  using driver `ESRI Shapefile'\nSimple feature collection with 448 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 11909.7 ymin: 25596.33 xmax: 43395.47 ymax: 48562.06\nProjected CRS: SVY21 / Singapore TM\n\n\n\nlibrary_sf <- st_read(dsn = \"data/geospatial/extracted\", layer = \"libraries\")\n\nReading layer `libraries' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/extracted' \n  using driver `ESRI Shapefile'\nSimple feature collection with 31 features and 13 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 13665.24 ymin: 27383.57 xmax: 40922.89 ymax: 47759.75\nProjected CRS: SVY21 / Singapore TM\n\n\n\nparks_sf <- st_read(dsn = \"data/geospatial/extracted\", layer = \"nationalparks\")\n\nReading layer `nationalparks' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/extracted' \n  using driver `ESRI Shapefile'\nSimple feature collection with 421 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 12374.75 ymin: 21917.81 xmax: 52533.09 ymax: 49296.46\nProjected CRS: SVY21 / Singapore TM\n\n\n\n\n\nmpsz_sf <- st_read(dsn = \"data/geospatial/map\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/map' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\nbusstop_sf <- st_read(dsn = \"data/geospatial/sourced\", layer = \"BusStop\")\n\nReading layer `BusStop' from data source \n  `/Users/keredpoh/Desktop/keredpoh/IS415-GAA/Take-home_Ex/Take-home_Ex03/data/geospatial/sourced' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5159 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/data/geospatial/map/MPSZ-2019.html",
    "href": "Take-home_Ex/Take-home_Ex03/data/geospatial/map/MPSZ-2019.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#onemap-extracted-1",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#onemap-extracted-1",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Onemap (Extracted)",
    "text": "Onemap (Extracted)\n\nlength(which(st_is_valid(hawkercentre_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(communityclubs_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(eldercare_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(childcare_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(kindergartens_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(library_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(parks_sf) == FALSE))\n\n[1] 0"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#basemap-1",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#basemap-1",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Basemap",
    "text": "Basemap\n\nlength(which(st_is_valid(mpsz_sf) == FALSE))\n\n[1] 9"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#self-sourced-1",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#self-sourced-1",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Self-Sourced",
    "text": "Self-Sourced\n\nlength(which(st_is_valid(busstop_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(goodprisch_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(mrt_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(prisch_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(shoppingmall_sf) == FALSE))\n\n[1] 0\n\n\n\nlength(which(st_is_valid(supermarket_sf) == FALSE))\n\n[1] 0"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#onemap-extracted-2",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#onemap-extracted-2",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Onemap (Extracted)",
    "text": "Onemap (Extracted)\n\nhawkercentre_sf <- hawkercentre_sf %>%\n  select(1)\n\n\ncommunityclubs_sf <- communityclubs_sf %>%\n  select(1)\n\n\neldercare_sf <- eldercare_sf %>%\n  select(1)\n\n\nchildcare_sf <- childcare_sf %>%\n  select(1)\n\n\nkindergartens_sf <- kindergartens_sf %>%\n  select(1)\n\n\nlibrary_sf <- library_sf %>%\n  select(1)\n\n\nparks_sf <- parks_sf %>%\n  select(1)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#self-sourced-2",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#self-sourced-2",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Self-sourced",
    "text": "Self-sourced\n\nbusstop_sf <- busstop_sf %>%\n  select(1)\n\n\ngoodprisch_sf <- goodprisch_sf %>%\n  select(1)\n\n\nmrt_sf <- mrt_sf %>%\n  select(1)\n\n\nprisch_sf <- prisch_sf %>%\n  select(1)\n\n\nshoppingmall_sf <- shoppingmall_sf %>%\n  select(1)\n\n\nsupermarket_sf <- supermarket_sf %>%\n  select(1)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#onemap-extracted-3",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#onemap-extracted-3",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Onemap (Extracted)",
    "text": "Onemap (Extracted)\n\nhawkercentre_sf[rowSums(is.na(hawkercentre_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)\n\n\n\ncommunityclubs_sf[rowSums(is.na(communityclubs_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)\n\n\n\neldercare_sf[rowSums(is.na(eldercare_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)\n\n\n\nchildcare_sf[rowSums(is.na(childcare_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)\n\n\n\nkindergartens_sf[rowSums(is.na(kindergartens_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)\n\n\n\nlibrary_sf[rowSums(is.na(library_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)\n\n\n\nparks_sf[rowSums(is.na(parks_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#basemap-2",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#basemap-2",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Basemap",
    "text": "Basemap\n\nmpsz_sf[rowSums(is.na(mpsz_sf))!=0,]\n\nSimple feature collection with 0 features and 15 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21\n [1] OBJECTID   SUBZONE_NO SUBZONE_N  SUBZONE_C  CA_IND     PLN_AREA_N\n [7] PLN_AREA_C REGION_N   REGION_C   INC_CRC    FMEL_UPD_D X_ADDR    \n[13] Y_ADDR     SHAPE_Leng SHAPE_Area geometry  \n<0 rows> (or 0-length row.names)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#self-sourced-3",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#self-sourced-3",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Self-Sourced",
    "text": "Self-Sourced\n\nbusstop_sf[rowSums(is.na(busstop_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] BUS_STOP_N geometry  \n<0 rows> (or 0-length row.names)\n\n\n\ngoodprisch_sf[rowSums(is.na(goodprisch_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] schl_nm  geometry\n<0 rows> (or 0-length row.names)\n\n\n\nmrt_sf[rowSums(is.na(mrt_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] Name     geometry\n<0 rows> (or 0-length row.names)\n\n\n\nprisch_sf[rowSums(is.na(prisch_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] schl_nm  geometry\n<0 rows> (or 0-length row.names)\n\n\n\nshoppingmall_sf[rowSums(is.na(shoppingmall_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] name     geometry\n<0 rows> (or 0-length row.names)\n\n\n\nsupermarket_sf[rowSums(is.na(supermarket_sf))!=0,]\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] LIC_NAME geometry\n<0 rows> (or 0-length row.names)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#hawker-centers",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#hawker-centers",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Hawker centers",
    "text": "Hawker centers\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons(alpha = 0.3) +\ntm_shape(hawkercentre_sf) +\n  tm_dots(col = \"blue\", size = 0.04)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#community-clubs-1",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#community-clubs-1",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Community clubs",
    "text": "Community clubs\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons(alpha = 0.3) +\ntm_shape(communityclubs_sf) +\n  tm_dots(col = \"blue\", size = 0.04)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#elderly-care",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#elderly-care",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Elderly care",
    "text": "Elderly care\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons(alpha = 0.3) +\ntm_shape(eldercare_sf) +\n  tm_dots(col = \"purple\", size = 0.04)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#childcare-1",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#childcare-1",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Childcare",
    "text": "Childcare\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons(alpha = 0.3) +\ntm_shape(childcare_sf) +\n  tm_dots(col =\"red\", size = 0.04)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#kindergarten",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#kindergarten",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Kindergarten",
    "text": "Kindergarten\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons(alpha = 0.3) +\ntm_shape(kindergartens_sf) +\n  tm_dots(col = \"red\", size = 0.04)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#library",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#library",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Library",
    "text": "Library\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons(alpha = 0.3) +\ntm_shape(library_sf) +\n  tm_dots(col = \"blue\", size = 0.04)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#parks-1",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#parks-1",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Parks",
    "text": "Parks\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons(alpha = 0.3) +\ntm_shape(parks_sf) +\n  tm_dots(col = \"green\", size = 0.04)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#bus-stop",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#bus-stop",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Bus stop",
    "text": "Bus stop\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons(alpha = 0.3) +\ntm_shape(busstop_sf) +\n  tm_dots(col = \"blue\", size = 0.04)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#good-primary-school",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#good-primary-school",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Good primary school",
    "text": "Good primary school\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons(alpha = 0.3) +\ntm_shape(goodprisch_sf) +\n  tm_dots(col = \"red\", size = 0.04)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#mrt",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#mrt",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Mrt",
    "text": "Mrt\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons(alpha = 0.3) +\ntm_shape(mrt_sf) +\n  tm_dots(col = \"blue\", size = 0.04)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#primary-school",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#primary-school",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Primary school",
    "text": "Primary school\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons(alpha = 0.3) +\ntm_shape(prisch_sf) +\n  tm_dots(col = \"red\", size = 0.04)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#shopping-mall",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#shopping-mall",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Shopping mall",
    "text": "Shopping mall\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons(alpha = 0.3) +\ntm_shape(shoppingmall_sf) +\n  tm_dots(col = \"blue\", size = 0.04)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#supermarket",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#supermarket",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Supermarket",
    "text": "Supermarket\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons(alpha = 0.3) +\ntm_shape(supermarket_sf) +\n  tm_dots(col = \"blue\", size = 0.04)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#cbd-location",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#cbd-location",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "4.1 CBD location",
    "text": "4.1 CBD location\nWe will be taking reference from this website, to get the latitude and longitude of downtown core. SImilarly, we will convert it into the correct CRS, which is 3414.\n\nlat <- 1.287953\nlng <- 103.851784\n\ncbd_sf <- data.frame(lat, lng) %>%\n  st_as_sf(coords = c(\"lng\", \"lat\"), crs = 4326) %>%\n  st_transform(crs = 3414)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#converting-resale-data-into-sf",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#converting-resale-data-into-sf",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "4.2 Converting resale data into sf",
    "text": "4.2 Converting resale data into sf\nNotice that our resale data, resale_sub do not have any CRS.\n\nst_crs(resale_sub)\n\nCoordinate Reference System: NA\n\n\nIn that case, we will be assigning CRS using st_as_sf to convert it into a sf object, while inserting CRS 3414 using st_transform.\n\nresale_sub <- st_as_sf(resale_sub, coords = c(\"LONGITUDE\", \"LATITUDE\"), crs = 4326) %>%\n  st_transform(crs = 3414)\n\nLet us do a check. Looking good!\n\nst_crs(resale_sub)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#proximity-distance-calculation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#proximity-distance-calculation",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "4.3 Proximity distance calculation",
    "text": "4.3 Proximity distance calculation\nEarlier, we were just discussing about how locational factors will help us view the proximity from one location to the other. By referencing to our favourite senior, Megan again, we will be calculating as such using st_distance() to get the shortest distance, together with rowMins().\n\nproximity <- function(df1, df2, varname) {\n  dist_matrix <- st_distance(df1, df2) |> \n    drop_units()\n  df1[,varname] <- rowMins(dist_matrix)\n  return(df1)\n}\n\nWe will then input all the proximity into all of our data, using the newly created proximity() function.\n\nresale_sub <-\n  proximity(resale_sub, cbd_sf, \"PROX_CBD\") %>%\n  proximity(., communityclubs_sf, \"PROX_COMMUNITYCLUBS\") %>%\n  proximity(., childcare_sf, \"PROX_CHILDCARE\") %>%\n  proximity(., kindergartens_sf, \"PROX_KINDERGARTEN\") %>%\n  proximity(., eldercare_sf, \"PROX_ELDERCARE\") %>%\n  proximity(., hawkercentre_sf, \"PROX_HAWKER\") %>%\n  proximity(., busstop_sf, \"PROX_BUSSTOP\") %>%\n  proximity(., mrt_sf, \"PROX_MRT\") %>%\n  proximity(., library_sf, \"PROX_LIBRARY\") %>%\n  proximity(., parks_sf, \"PROX_PARK\") %>%\n  proximity(., goodprisch_sf, \"PROX_GOODPRISCH\") %>%\n  proximity(., shoppingmall_sf, \"PROX_MALL\") %>%\n  proximity(., supermarket_sf, \"PROX_SPRMKT\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#facility-count-within-radius-calculation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#facility-count-within-radius-calculation",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "4.4 Facility count within radius calculation",
    "text": "4.4 Facility count within radius calculation\nAs the saying goes, size is not everything. Knowing the distance between one point to the other is simply not enough. Hence, we will use st_distance() and rowSums() to find the particular facility within the radius!\n\nnum_radius <- function(df1, df2, varname, radius) {\n  dist_matrix <- st_distance(df1, df2) %>%\n    drop_units() %>%\n    as.data.frame()\n  df1[,varname] <- rowSums(dist_matrix <= radius)\n  return(df1)\n}\n\nFor the scope of our assignment, we are required to set:\n\nNumbers of kindergartens within 350m\nNumbers of childcare centres within 350m\nNumbers of bus stop within 350m\nNumbers of primary school within 1km\n\nLet us do that then!\n\nresale_sub <- \n  num_radius(resale_sub, kindergartens_sf, \"NUM_KINDERGARTEN\", 350) %>%\n  num_radius(., childcare_sf, \"NUM_CHILDCARE\", 350) %>%\n  num_radius(., busstop_sf, \"NUM_BUSSTOP\", 350) %>%\n  num_radius(., prisch_sf, \"NUM_PRIMARYSCH\", 1000)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#saving-as-rds-file",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#saving-as-rds-file",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "4.5 Saving as RDS file",
    "text": "4.5 Saving as RDS file\nWith that, let us save the updated resale_sub as RDS so that we can use it later on!\n\nsaveRDS(resale_sub, \"data/final/resale_sub.rds\")\n\nAnd assign it back into resale_sub!\n\nresale_sub <- read_rds(\"data/final/resale_sub.rds\")\n\nLet us glimpse resale_sub now. Looking good!\n\nglimpse(resale_sub)\n\nRows: 13,780\nColumns: 32\n$ month                <date> 2021-01-01, 2021-01-01, 2021-01-01, 2021-01-01, …\n$ town                 <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO…\n$ flat_type            <chr> \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\",…\n$ block                <chr> \"331\", \"534\", \"561\", \"170\", \"463\", \"542\", \"170\", …\n$ street_name          <chr> \"ANG MO KIO AVE 1\", \"ANG MO KIO AVE 10\", \"ANG MO …\n$ storey_range         <chr> \"04 TO 06\", \"04 TO 06\", \"01 TO 03\", \"07 TO 09\", \"…\n$ floor_area_sqm       <dbl> 68, 68, 68, 60, 68, 68, 60, 73, 67, 67, 68, 68, 7…\n$ flat_model           <chr> \"New Generation\", \"New Generation\", \"New Generati…\n$ remaining_lease      <chr> \"59 years\", \"58 years 02 months\", \"58 years 01 mo…\n$ resale_price         <dbl> 260000, 265000, 265000, 268000, 268000, 270000, 2…\n$ remaining_lease_yr   <int> 59, 58, 58, 64, 58, 59, 64, 54, 56, 55, 59, 58, 5…\n$ remaining_lease_mth  <dbl> 0.00000000, 0.16666667, 0.08333333, 0.16666667, 0…\n$ remaining_lease_year <dbl> 59.00000, 58.16667, 58.08333, 64.16667, 58.16667,…\n$ Story_Ordinal        <dbl> 2, 2, 1, 3, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 4, 3, 4…\n$ geometry             <POINT [m]> POINT (29941.75 38240.88), POINT (30320.3 3…\n$ PROX_CBD             <dbl> 8200.838, 9524.798, 9161.157, 9666.904, 8757.889,…\n$ PROX_COMMUNITYCLUBS  <dbl> 326.61835, 570.35903, 931.51879, 171.26726, 612.7…\n$ PROX_CHILDCARE       <dbl> 1.096366e-03, 1.303650e+02, 1.326133e+02, 7.67633…\n$ PROX_KINDERGARTEN    <dbl> 296.49085, 130.36502, 162.86335, 123.23507, 133.4…\n$ PROX_ELDERCARE       <dbl> 412.40614, 1008.60569, 683.47390, 429.68375, 284.…\n$ PROX_HAWKER          <dbl> 356.0483, 146.7193, 307.8475, 314.3604, 190.8302,…\n$ PROX_BUSSTOP         <dbl> 52.08994, 81.73559, 49.50312, 105.66510, 123.5681…\n$ PROX_MRT             <dbl> 818.2893, 668.5038, 889.4626, 1260.4751, 884.9691…\n$ PROX_LIBRARY         <dbl> 1372.5693, 959.1003, 1443.1690, 1021.9212, 1583.6…\n$ PROX_PARK            <dbl> 358.0379, 554.3379, 817.5539, 303.1924, 461.9375,…\n$ PROX_GOODPRISCH      <dbl> 5095.852, 6102.352, 5563.911, 5954.445, 5238.499,…\n$ PROX_MALL            <dbl> 826.9469, 829.6281, 1012.7966, 1439.9090, 877.514…\n$ PROX_SPRMKT          <dbl> 436.96170265, 159.23907382, 166.00546756, 341.303…\n$ NUM_KINDERGARTEN     <dbl> 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1…\n$ NUM_CHILDCARE        <dbl> 2, 3, 5, 4, 6, 3, 4, 3, 3, 3, 2, 3, 3, 4, 3, 4, 4…\n$ NUM_BUSSTOP          <dbl> 7, 11, 8, 3, 6, 9, 3, 4, 6, 4, 6, 9, 9, 5, 4, 8, …\n$ NUM_PRIMARYSCH       <dbl> 2, 2, 2, 2, 3, 1, 2, 1, 3, 1, 1, 1, 2, 3, 1, 2, 1…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualising-correlation-matrix",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualising-correlation-matrix",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "5.1 Visualising correlation matrix",
    "text": "5.1 Visualising correlation matrix\nRecall that we have already removed lease_commence_date earlier on to prevent perfect multi-colinearity. However, we should visualise the matrix to ensure that no variables are co-linear. Note that we have dropped resale_price, as that is the dependent variable.\n\nresale_corm <- resale_sub %>% \n  st_drop_geometry() %>% \n  select_if(is.numeric) %>% \n  select(-resale_price)\ncorrplot::corrplot(cor(resale_corm), \n                   diag = FALSE, \n                   order = \"AOE\",\n                   tl.pos = \"td\", \n                   tl.cex = 0.4, \n                   method = \"number\", \n                   type = \"upper\")\n\n\n\n\nOh my! looks like we forgot that we combined remaining_lease_year from remaining_lease_yr. This shows that we cannot be complacent. Lucky for us, we found it out before anything! Let us remove it using select().\n\nresale_sub <- resale_sub %>%\n  select(-remaining_lease_yr, -remaining_lease_mth)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#splitting-into-training-and-testing-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#splitting-into-training-and-testing-data",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "5.2 Splitting into training and testing data",
    "text": "5.2 Splitting into training and testing data\nFor the purpose on this assignment, we will be splitting the data into:\n\nTesting data, ranging from January 2023 to February 2023\nTraining data, from January 2021 to December 2022\n\n\ntest_data <- resale_sub %>% \n  filter(month >= \"2023-01-01\" & month <= \"2023-02-28\")\n\ntrain_data <- resale_sub %>%\n  filter(month >= \"2021-01-01\" & month <= \"2022-12-31\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#multi-linear-regression-non-spatial",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#multi-linear-regression-non-spatial",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "5.3 Multi-linear regression (non-spatial)",
    "text": "5.3 Multi-linear regression (non-spatial)\nLet us build a multi-linear regression now. The beauty of building a regression is that we can choose what to add and what to not add, as long as it is justified. We will not be adding flat model, as we narrowed the scope to 3 room flats. Geometry will not be useful as well. remaining_lease will be omitted as well, as we have remaining_lease_year.\n\nGlimpse test_dataRegressionSummarySaving as RDSReading RDS\n\n\n\nglimpse(test_data)\n\nRows: 1,172\nColumns: 30\n$ month                <date> 2023-01-01, 2023-01-01, 2023-01-01, 2023-01-01, …\n$ town                 <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO…\n$ flat_type            <chr> \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\",…\n$ block                <chr> \"225\", \"225\", \"310C\", \"319\", \"319\", \"220\", \"457\",…\n$ street_name          <chr> \"ANG MO KIO AVE 1\", \"ANG MO KIO AVE 1\", \"ANG MO K…\n$ storey_range         <chr> \"04 TO 06\", \"07 TO 09\", \"25 TO 27\", \"04 TO 06\", \"…\n$ floor_area_sqm       <dbl> 67, 67, 70, 73, 73, 67, 89, 68, 75, 74, 75, 67, 7…\n$ flat_model           <chr> \"New Generation\", \"New Generation\", \"Model A\", \"N…\n$ remaining_lease      <chr> \"54 years 01 month\", \"54 years 01 month\", \"88 yea…\n$ resale_price         <dbl> 380000, 380000, 635000, 365000, 418000, 380000, 4…\n$ remaining_lease_year <dbl> 54.08333, 54.08333, 88.75000, 53.33333, 53.33333,…\n$ Story_Ordinal        <dbl> 2, 3, 9, 2, 3, 2, 3, 2, 2, 1, 1, 2, 3, 3, 2, 4, 2…\n$ geometry             <POINT [m]> POINT (28537.68 38825.23), POINT (28537.68 …\n$ PROX_CBD             <dbl> 8914.494, 8914.494, 8511.594, 8545.724, 8545.724,…\n$ PROX_COMMUNITYCLUBS  <dbl> 287.0599, 287.0599, 481.9450, 720.7452, 720.7452,…\n$ PROX_CHILDCARE       <dbl> 1.857691e+02, 1.857691e+02, 1.151054e+02, 1.17446…\n$ PROX_KINDERGARTEN    <dbl> 1.951542e+02, 1.951542e+02, 3.319666e+02, 2.43231…\n$ PROX_ELDERCARE       <dbl> 404.35866, 404.35866, 254.95445, 58.09058, 58.090…\n$ PROX_HAWKER          <dbl> 137.8719, 137.8719, 382.8329, 147.7741, 147.7741,…\n$ PROX_BUSSTOP         <dbl> 166.43714, 166.43714, 28.02879, 180.21394, 180.21…\n$ PROX_MRT             <dbl> 1266.0217, 1266.0217, 731.4223, 526.3600, 526.360…\n$ PROX_LIBRARY         <dbl> 1162.8752, 1162.8752, 1128.3688, 1088.8972, 1088.…\n$ PROX_PARK            <dbl> 320.9723, 320.9723, 500.4366, 443.2952, 443.2952,…\n$ PROX_GOODPRISCH      <dbl> 5391.555, 5391.555, 5183.752, 5301.687, 5301.687,…\n$ PROX_MALL            <dbl> 1165.8961, 1165.8961, 649.6052, 470.6596, 470.659…\n$ PROX_SPRMKT          <dbl> 157.75712, 157.75712, 314.48012, 63.03934, 63.039…\n$ NUM_KINDERGARTEN     <dbl> 2, 2, 1, 2, 2, 0, 1, 2, 1, 2, 2, 0, 2, 2, 1, 1, 1…\n$ NUM_CHILDCARE        <dbl> 4, 4, 5, 6, 6, 1, 3, 5, 4, 6, 7, 1, 5, 5, 4, 4, 4…\n$ NUM_BUSSTOP          <dbl> 6, 6, 4, 4, 4, 5, 4, 10, 4, 5, 5, 4, 6, 10, 7, 5,…\n$ NUM_PRIMARYSCH       <dbl> 2, 2, 2, 4, 4, 1, 2, 1, 3, 3, 3, 3, 3, 1, 1, 3, 1…\n\n\n\n\n\nmulti_lr <- lm(resale_price~ Story_Ordinal + remaining_lease_year + floor_area_sqm + PROX_CBD + PROX_ELDERCARE + PROX_HAWKER + PROX_PARK + PROX_LIBRARY + PROX_COMMUNITYCLUBS + PROX_BUSSTOP + PROX_MALL + PROX_SPRMKT + PROX_GOODPRISCH + PROX_MRT + NUM_CHILDCARE + NUM_KINDERGARTEN + NUM_PRIMARYSCH + month, data = train_data)\n\n\n\n\nsummary(multi_lr)\n\n\nCall:\nlm(formula = resale_price ~ Story_Ordinal + remaining_lease_year + \n    floor_area_sqm + PROX_CBD + PROX_ELDERCARE + PROX_HAWKER + \n    PROX_PARK + PROX_LIBRARY + PROX_COMMUNITYCLUBS + PROX_BUSSTOP + \n    PROX_MALL + PROX_SPRMKT + PROX_GOODPRISCH + PROX_MRT + NUM_CHILDCARE + \n    NUM_KINDERGARTEN + NUM_PRIMARYSCH + month, data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-189219  -26995   -3391   21886  472311 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          -2.209e+06  3.663e+04 -60.304  < 2e-16 ***\nStory_Ordinal         9.851e+03  2.421e+02  40.697  < 2e-16 ***\nremaining_lease_year  3.790e+03  3.433e+01 110.394  < 2e-16 ***\nfloor_area_sqm        5.094e+03  6.348e+01  80.235  < 2e-16 ***\nPROX_CBD             -7.016e+00  1.445e-01 -48.558  < 2e-16 ***\nPROX_ELDERCARE       -4.222e+00  8.173e-01  -5.166 2.42e-07 ***\nPROX_HAWKER          -9.331e+00  1.139e+00  -8.190 2.87e-16 ***\nPROX_PARK            -9.948e+00  1.248e+00  -7.973 1.68e-15 ***\nPROX_LIBRARY         -4.553e+00  8.818e-01  -5.163 2.46e-07 ***\nPROX_COMMUNITYCLUBS  -1.211e+01  1.638e+00  -7.389 1.57e-13 ***\nPROX_BUSSTOP         -1.187e+01  7.245e+00  -1.639    0.101    \nPROX_MALL            -1.900e+01  1.204e+00 -15.786  < 2e-16 ***\nPROX_SPRMKT           2.526e+01  2.351e+00  10.745  < 2e-16 ***\nPROX_GOODPRISCH      -2.147e+00  1.682e-01 -12.762  < 2e-16 ***\nPROX_MRT             -1.177e+01  1.169e+00 -10.063  < 2e-16 ***\nNUM_CHILDCARE        -1.821e+03  2.520e+02  -7.223 5.37e-13 ***\nNUM_KINDERGARTEN      6.897e+03  5.481e+02  12.583  < 2e-16 ***\nNUM_PRIMARYSCH       -4.088e+03  3.392e+02 -12.052  < 2e-16 ***\nmonth                 1.101e+02  1.912e+00  57.586  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 44900 on 12589 degrees of freedom\nMultiple R-squared:  0.7351,    Adjusted R-squared:  0.7348 \nF-statistic:  1941 on 18 and 12589 DF,  p-value: < 2.2e-16\n\n\n\n\n\nwrite_rds(multi_lr, \"data/regmodels/multi_lr.rds\")\n\n\n\n\nmulti_reg <- read_rds(\"data/regmodels/multi_lr.rds\")\nmulti_reg\n\n\nCall:\nlm(formula = resale_price ~ Story_Ordinal + remaining_lease_year + \n    floor_area_sqm + PROX_CBD + PROX_ELDERCARE + PROX_HAWKER + \n    PROX_PARK + PROX_LIBRARY + PROX_COMMUNITYCLUBS + PROX_BUSSTOP + \n    PROX_MALL + PROX_SPRMKT + PROX_GOODPRISCH + PROX_MRT + NUM_CHILDCARE + \n    NUM_KINDERGARTEN + NUM_PRIMARYSCH + month, data = train_data)\n\nCoefficients:\n         (Intercept)         Story_Ordinal  remaining_lease_year  \n          -2.209e+06             9.851e+03             3.790e+03  \n      floor_area_sqm              PROX_CBD        PROX_ELDERCARE  \n           5.094e+03            -7.016e+00            -4.222e+00  \n         PROX_HAWKER             PROX_PARK          PROX_LIBRARY  \n          -9.331e+00            -9.948e+00            -4.553e+00  \n PROX_COMMUNITYCLUBS          PROX_BUSSTOP             PROX_MALL  \n          -1.211e+01            -1.187e+01            -1.900e+01  \n         PROX_SPRMKT       PROX_GOODPRISCH              PROX_MRT  \n           2.526e+01            -2.147e+00            -1.177e+01  \n       NUM_CHILDCARE      NUM_KINDERGARTEN        NUM_PRIMARYSCH  \n          -1.821e+03             6.897e+03            -4.088e+03  \n               month  \n           1.101e+02"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#gwr-predictive-method",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#gwr-predictive-method",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "5.4 GWR predictive method",
    "text": "5.4 GWR predictive method\nWe will convert sf into sp, so that it can be useful in predicting resale prices of 3 room HDB flats. We will convert using as_Spatial()\n\ntrain_data_sp <- as_Spatial(train_data)\ntrain_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 12608 \nextent      : 11597.97, 45192.3, 28097.64, 48622.47  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 29\nnames       : month,       town, flat_type, block,    street_name, storey_range, floor_area_sqm, flat_model,    remaining_lease, resale_price, remaining_lease_year, Story_Ordinal,         PROX_CBD,  PROX_COMMUNITYCLUBS,       PROX_CHILDCARE, ... \nmin values  : 18628, ANG MO KIO,    3 ROOM,     1, ALJUNIED AVE 2,     01 TO 03,             51,       DBSS,  43 years 01 month,        2e+05,     43.0833333333333,             1, 721.958623503081, 0.000559347187634686, 8.52942410735876e-05, ... \nmax values  : 19327,     YISHUN,    3 ROOM,    99,  YUAN CHING RD,     46 TO 48,            241,    Terrace, 97 years 05 months,      1268000,     97.4166666666667,            16, 19650.0691667807,     3877.80844185295,     2952.47979062617, ..."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#computing-adaptive-bandwidth",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#computing-adaptive-bandwidth",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "5.5 Computing adaptive bandwidth",
    "text": "5.5 Computing adaptive bandwidth\nSimilarly, after computing the bandwidth, we will use write_rds() and read_rds for efficiency!\n\nAdaptive bandwidthWrite RDSRead RDS\n\n\n\nbw_adaptive <- bw.gwr(resale_price~ Story_Ordinal + remaining_lease_year + floor_area_sqm + PROX_CBD + PROX_ELDERCARE + PROX_HAWKER + PROX_PARK + PROX_LIBRARY + PROX_COMMUNITYCLUBS + PROX_BUSSTOP + PROX_MALL + PROX_SPRMKT + PROX_GOODPRISCH + PROX_MRT + NUM_CHILDCARE + NUM_KINDERGARTEN + NUM_PRIMARYSCH + month, data  = train_data_sp,\n                  approach = \"CV\",\n                  kernel = \"gaussian\",\n                  adaptive = TRUE,\n                  longlat = FALSE)\n\n\n\n\nwrite_rds(bw_adaptive, \"data/regmodels/bw_adaptive.rds\")\n\n\n\n\nbw_adaptive <- read_rds(\"data/regmodels/bw_adaptive.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#constructing-adaptive-bandwidth-gwr",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#constructing-adaptive-bandwidth-gwr",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "Constructing adaptive bandwidth GWR",
    "text": "Constructing adaptive bandwidth GWR\nSimilarly to above, we will use write_rds() to save, and read_rds() to read the adaptive gwr\n\nAdaptive GWRWrite RDSRead RDS\n\n\n\ngwr_adaptive <- gwr.basic(resale_price~ Story_Ordinal + remaining_lease_year + floor_area_sqm + PROX_CBD + PROX_ELDERCARE + PROX_HAWKER + PROX_PARK + PROX_LIBRARY + PROX_COMMUNITYCLUBS + PROX_BUSSTOP + PROX_MALL + PROX_SPRMKT + PROX_GOODPRISCH + PROX_MRT + NUM_CHILDCARE + NUM_KINDERGARTEN + NUM_PRIMARYSCH + month,\n                data = train_data_sp,\n                          bw = bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive = TRUE,\n                          longlat = FALSE)\n\n\n\n\nwrite_rds(gwr_adaptive, \"data/regmodels/gwr_adaptive.rds\")\n\n\n\n\ngwr_adaptive <- read_rds(\"data/regmodels/gwr_adaptive.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extracting-coordinates",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extracting-coordinates",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "5.6 Extracting Coordinates",
    "text": "5.6 Extracting Coordinates\nWith reference to the previous in class exercise, we were taught that we need to use st_coordinates to extract the x & y coordinates of the dataset. We will be using write_rds(), and read_rds() again.\n\nCode chunkWrite RDSRead RDS\n\n\n\ncoords <- st_coordinates(resale_sub)\ncoords_training <- st_coordinates(train_data)\ncoords_testing <- st_coordinates(test_data)\n\n\n\n\nwrite_rds(coords_training, \"data/regmodels/coords_training.rds\" )\nwrite_rds(coords_testing, \"data/regmodels/coords_testing.rds\")\n\n\n\n\ncoords_training <- read_rds(\"data/regmodels/coords_training.rds\")\ncoords_testing <- read_rds(\"data/regmodels/coords_testing.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#dropping-geometry-field",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#dropping-geometry-field",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "5.7 Dropping geometry field",
    "text": "5.7 Dropping geometry field\nWe will do so by using st_drop_geometry()\n\nCode chunkWrite RDSRead RDS\n\n\n\ntrain_data <- st_drop_geometry(train_data)\n\n\n\n\nwrite_rds(train_data, \"data/regmodels/train_data.rds\")\n\n\n\n\ntrain_data <- read_rds(\"data/regmodels/train_data.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#random-forest-model",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#random-forest-model",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "5.8 Random forest model",
    "text": "5.8 Random forest model\nWe use set.seed() to ensure that the same value gets generated in our random forest model. Not so random now, is it?\n\nCode chunkWrite RDSRead RDSResults\n\n\n\nset.seed(1234) \n\nforest <- ranger(resale_price~ Story_Ordinal + remaining_lease_year + floor_area_sqm + PROX_CBD + PROX_ELDERCARE + PROX_HAWKER + PROX_PARK + PROX_LIBRARY + PROX_COMMUNITYCLUBS + PROX_BUSSTOP + PROX_MALL + PROX_SPRMKT + PROX_GOODPRISCH + PROX_MRT + NUM_CHILDCARE + NUM_KINDERGARTEN + NUM_PRIMARYSCH + month, data = train_data)\n\n\n\n\nwrite_rds(forest, \"data/regmodels/forest.rds\")\n\n\n\n\nforest <- read_rds(\"data/regmodels/forest.rds\")\n\n\n\n\nprint(forest)\n\nRanger result\n\nCall:\n ranger(resale_price ~ Story_Ordinal + remaining_lease_year +      floor_area_sqm + PROX_CBD + PROX_ELDERCARE + PROX_HAWKER +      PROX_PARK + PROX_LIBRARY + PROX_COMMUNITYCLUBS + PROX_BUSSTOP +      PROX_MALL + PROX_SPRMKT + PROX_GOODPRISCH + PROX_MRT + NUM_CHILDCARE +      NUM_KINDERGARTEN + NUM_PRIMARYSCH + month, data = train_data) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      12608 \nNumber of independent variables:  18 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       511184749 \nR squared (OOB):                  0.9327335"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#calibrating-geographic-random-forest-using-grf",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#calibrating-geographic-random-forest-using-grf",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "5.9 Calibrating geographic random forest using GRF",
    "text": "5.9 Calibrating geographic random forest using GRF\nFor this assignment, will be using 30 trees!\nAdaptive bandwidth\n\nbw_grf_adaptive <- grf.bw(formula = resale_price~ Story_Ordinal + remaining_lease_year + floor_area_sqm + PROX_CBD + PROX_ELDERCARE + PROX_HAWKER + PROX_PARK + PROX_LIBRARY + PROX_COMMUNITYCLUBS + PROX_BUSSTOP + PROX_MALL + PROX_SPRMKT + PROX_GOODPRISCH + PROX_MRT + NUM_CHILDCARE + NUM_KINDERGARTEN + NUM_PRIMARYSCH + month,\n            dataset = train_data, \n            kernel = \"adaptive\", \n            coords = coords_training, \n            trees = 30)\n\n\n\nwrite_rds(bw_grf_adaptive, \"data/regmodels/bw_grf_adaptive.rds\")\n\nWe will be assigning 638, which is the highest R2 score to bw_grf_adaptive before running our grf\n\nbw_grf_adaptive <- 638"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#calibrating-geographical-random-forest-model",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#calibrating-geographical-random-forest-model",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "5.10 Calibrating Geographical Random Forest Model",
    "text": "5.10 Calibrating Geographical Random Forest Model\nWe will be using grf() to calibrate a model to predict HDB resale price.\n\nWrite RDSRead RDS\n\n\n\nwrite_rds(gwRF_adaptive, \"data/regmodels/gwRF_adaptive.rds\")\n\n\n\n\ngwRF_adaptive <- read_rds(\"data/regmodels/gwRF_adaptive.rds\")\n\n\n\n\nHere are the snippets of the output gwRF for better visualisation!"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#dropping-geometry-for-test-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#dropping-geometry-for-test-data",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "6.1 Dropping geometry for test data",
    "text": "6.1 Dropping geometry for test data\n\nCode chunkWrite RDSRead RDS\n\n\n\ntest_data <- cbind(test_data, coords_testing) %>%\n  st_drop_geometry()\n\n\n\n\nwrite_rds(test_data, \"data/regmodels/test_data.rds\")\n\n\n\n\ntest_data <- read_rds(\"data/regmodels/test_data.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#predicting-with-test-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#predicting-with-test-data",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "6.2 Predicting with test data",
    "text": "6.2 Predicting with test data\nWe will use predict.grf() to predict the resale value by using the test data and gwRF_adaptive model calibrated above!\n\nCode chunkWrite RDS\n\n\n\ngwRF_pred <- predict.grf(gwRF_adaptive, \n                           test_data, \n                           x.var.name = \"X\",\n                           y.var.name = \"Y\", \n                           local.w = 1,\n                           global.w = 0)\n\n\n\n\nGRF_pred <- write_rds(gwRF_pred, \"data/regmodels/gwRF_pred.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#conversion-of-predicting-output-into-data-frame",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#conversion-of-predicting-output-into-data-frame",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "6.3 Conversion of predicting output into data frame",
    "text": "6.3 Conversion of predicting output into data frame\nWe will convert the output using as.data.frame()\n\nGRF_pred <- read_rds(\"data/regmodels/gwRF_pred.rds\")\nGRF_pred_df <- as.data.frame(GRF_pred)\n\nNext, we will be binding the predicted output into the test data using cbind()\n\nCbindWrite RDSRead RDS\n\n\n\ntest_data_p <- cbind(test_data, GRF_pred_df)\n\n\n\n\nwrite_rds(test_data_p, \"data/regmodels/test_data_p.rds\")\n\n\n\n\ntest_data_p <- read_rds(\"data/regmodels/test_data_p.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#calculating-root-mean-square-error",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#calculating-root-mean-square-error",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "6.4 Calculating root mean square error",
    "text": "6.4 Calculating root mean square error\nrsme() will help us measure how far the predicted values are from the observed values in a regression analysis\n\nrmse(test_data_p$resale_price, \n     test_data_p$GRF_pred)\n\n[1] 26458.07"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualising-the-predicted-values",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualising-the-predicted-values",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "6.5 Visualising the predicted values",
    "text": "6.5 Visualising the predicted values\nLet us visualise it on a scatterplot, where we plot actual resale price against predicted resale price\n\nggplot(data = test_data_p,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#ols-vs-geographical-weighted-methods",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#ols-vs-geographical-weighted-methods",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "7.1 OLS vs Geographical weighted methods",
    "text": "7.1 OLS vs Geographical weighted methods\nThe main difference between OLS and GWR is that OLS produces a single set of coefficients that are applicable across the entire data set, while GWR produces a set of coefficients that vary across space, which also means that the strength and direction of the relationship between the dependent variable and independent variables can change depending on the location of the observation, which can be more useful in understanding resale prices of HDB, especially if we are using the model for prediction! Let us prove this below.\n\nOLS (non spatial)Geographical Random Forest Model\n\n\n\nmulti_reg_df <- predict(multi_reg, test_data)\nmulti_reg_test<- cbind(test_data, multi_reg_df)\n\nrmse(multi_reg_test$resale_price, \n     multi_reg_test$multi_reg_df)\n\n[1] 45573.09\n\n\n\nggplot(data = multi_reg_test,\n       aes(x = multi_reg_df,\n           y = resale_price)) +\n  geom_point() +\n  geom_abline(col = \"Red\")\n\n\n\n\n\n\n\nrmse(test_data_p$resale_price, \n     test_data_p$GRF_pred)\n\n[1] 26458.07\n\n\n\nggplot(data = test_data_p,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point() +\n  geom_abline(col = \"Red\")\n\n\n\n\n\n\n\nFrom the scatter plots and the mean square error between both models, we can tell that the OSL aims to minimise residual sum of squares, as the regression line is fitted in that manner. Geographical Random Forest Model on the other hand, aims to reduce mean squared error, which is further supported by the value as computed above.\nHence, we therefore conclude that the Geographical Random Forest Model is better as a basis of predictive model, as compared to Non-spatial OLS."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#possible-improvements",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#possible-improvements",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods",
    "section": "7.2 Possible Improvements",
    "text": "7.2 Possible Improvements\n\nIf we recall, we ignored the variable flat_type as we assumed it to be 3 room throughout. In real life scenarios, that is not the case as different flat types do in fact have different default layout, which may affect the resale prices of the house. This could be done by potentially creating a binary variable with each of the different variables in flat type.\nIt was also obvious that there were outliers on the scatterplot. These outliers are the real life scenarios of HDB resale prices appearing out in the news where people are selling and buying houses for 1 million dollars. But hey, what can I say? if there is a demand, there will definitely be a supply. Removing those outlier can certainly help the overall model to improve.\nLastly, with a stronger device, we could potentially create more trees generated in the gwRF model!"
  }
]